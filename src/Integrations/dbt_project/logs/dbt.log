

============================== 2022-12-15 13:49:04.265637 | 0eedb6f0-1bf0-4651-b529-64dc861dc39a ==============================
[0m13:49:04.265661 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:49:04.266028 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:49:04.266112 [debug] [MainThread]: Tracking: tracking
[0m13:49:04.274528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c0520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c0490>]}
[0m13:49:04.281597 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
[0m13:49:04.281770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b06cd0>]}
[0m13:49:04.296172 [debug] [MainThread]: Parsing macros/etc.sql
[0m13:49:04.297388 [debug] [MainThread]: Parsing macros/catalog.sql
[0m13:49:04.301122 [debug] [MainThread]: Parsing macros/adapters.sql
[0m13:49:04.312091 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m13:49:04.313286 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m13:49:04.314673 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m13:49:04.318524 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m13:49:04.319834 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m13:49:04.328726 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m13:49:04.329492 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:49:04.329657 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:49:04.329945 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m13:49:04.330433 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:49:04.330592 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:49:04.330854 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:49:04.331146 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:49:04.331612 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:49:04.332184 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:49:04.332405 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:49:04.332635 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:49:04.332879 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:49:04.333119 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:49:04.333309 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:49:04.334407 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:49:04.334706 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:49:04.335118 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:49:04.335407 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:49:04.336682 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m13:49:04.338543 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m13:49:04.341439 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m13:49:04.342267 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m13:49:04.350524 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m13:49:04.371398 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m13:49:04.378293 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m13:49:04.380636 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m13:49:04.381490 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m13:49:04.382343 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m13:49:04.386379 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m13:49:04.395035 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m13:49:04.395759 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m13:49:04.399054 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m13:49:04.404347 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m13:49:04.413724 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m13:49:04.416509 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m13:49:04.418166 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m13:49:04.421003 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m13:49:04.421626 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m13:49:04.423265 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m13:49:04.424321 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m13:49:04.427871 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m13:49:04.437968 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m13:49:04.438660 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m13:49:04.439826 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m13:49:04.440553 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m13:49:04.440961 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m13:49:04.441324 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m13:49:04.441629 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m13:49:04.442274 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m13:49:04.444832 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m13:49:04.449569 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:49:04.450038 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m13:49:04.450649 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m13:49:04.451118 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m13:49:04.451563 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:49:04.452164 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:49:04.452531 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:49:04.453030 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:49:04.453617 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:49:04.454785 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:49:04.455368 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:49:04.455865 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:49:04.456350 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m13:49:04.456817 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m13:49:04.457524 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:49:04.458073 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m13:49:04.458528 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m13:49:04.461863 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:49:04.462366 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:49:04.462807 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m13:49:04.463656 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:49:04.464756 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:49:04.465230 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:49:04.465943 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:49:04.466429 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m13:49:04.467432 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m13:49:04.468996 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m13:49:04.470500 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m13:49:04.478146 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m13:49:04.479084 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:49:04.485769 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m13:49:04.487905 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m13:49:04.491488 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m13:49:04.496409 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m13:49:04.499470 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m13:49:04.632334 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:49:04.638783 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:49:04.675685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bf40d0>]}
[0m13:49:04.679649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c0490>]}
[0m13:49:04.679791 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:49:04.679906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c6beb0>]}
[0m13:49:04.680546 [info ] [MainThread]: 
[0m13:49:04.680837 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:49:04.681262 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:49:04.681329 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:05.277262 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:49:05.277677 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:49:05.719535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076634c0>]}
[0m13:49:05.720459 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:05.720619 [info ] [MainThread]: 
[0m13:49:05.725705 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:49:05.725945 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:49:05.726374 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:49:05.726493 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:49:05.726591 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:49:05.728728 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:49:05.729184 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:05.729256 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:49:05.751584 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:49:05.752020 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:49:05.752769 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:49:08.376253 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:e7a624c9-e0ed-41e4-bca5-f4f0b3540905:EU&page=queryresults
[0m13:49:08.395819 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:08.396514 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d36f10>]}
[0m13:49:08.396898 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.67s]
[0m13:49:08.397283 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:49:08.397847 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:49:08.398074 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:49:08.398633 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:49:08.398751 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:49:08.398866 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:49:08.401726 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:49:08.402423 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:08.402520 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:49:08.453005 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:49:08.453403 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:49:08.454120 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:49:09.449447 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:58a80504-f137-4da8-8139-2df11b8cef0e:EU&page=queryresults
[0m13:49:09.450604 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:09.451010 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eedb6f0-1bf0-4651-b529-64dc861dc39a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110975f70>]}
[0m13:49:09.451245 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 1.05s]
[0m13:49:09.451477 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:49:09.452132 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:49:09.452418 [info ] [MainThread]: 
[0m13:49:09.452525 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.77 seconds (4.77s).
[0m13:49:09.452627 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:09.452677 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:49:09.458798 [info ] [MainThread]: 
[0m13:49:09.458935 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:09.459055 [info ] [MainThread]: 
[0m13:49:09.459150 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:49:09.459287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dea520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108d6970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110979190>]}
[0m13:49:09.459401 [debug] [MainThread]: Flushing usage events


============================== 2022-12-15 13:53:13.976797 | 59dc682a-1f01-4c69-9344-c5608923192c ==============================
[0m13:53:13.976829 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:53:13.977214 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m13:53:13.977295 [debug] [MainThread]: Tracking: tracking
[0m13:53:13.985136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108812370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108812580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088124f0>]}
[0m13:53:14.015284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:53:14.015433 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:53:14.018758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59dc682a-1f01-4c69-9344-c5608923192c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089b9fa0>]}
[0m13:53:14.023369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59dc682a-1f01-4c69-9344-c5608923192c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088cd040>]}
[0m13:53:14.023573 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:53:14.023733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59dc682a-1f01-4c69-9344-c5608923192c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088cd070>]}
[0m13:53:14.024548 [info ] [MainThread]: 
[0m13:53:14.024918 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:53:14.025387 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:53:14.025475 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:14.442603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59dc682a-1f01-4c69-9344-c5608923192c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088124c0>]}
[0m13:53:14.443974 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:53:14.444375 [info ] [MainThread]: 
[0m13:53:14.447547 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:53:14.447886 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:53:14.448002 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:53:14.448097 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:53:14.450924 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:53:14.451509 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.451673 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:53:14.451825 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.452465 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:53:14.453022 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:53:14.453540 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:53:14.453685 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:53:14.453817 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:53:14.456412 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:53:14.456895 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.457001 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:53:14.457090 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.457499 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:53:14.457618 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:53:14.457920 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m13:53:14.458128 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:53:14.458357 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:53:14.470219 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m13:53:14.470748 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.470869 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:53:14.470968 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.471409 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:53:14.471532 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:53:14.471910 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:53:14.472015 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:53:14.472097 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:53:14.476207 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:53:14.476556 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.476655 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:53:14.476741 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.477109 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:53:14.477217 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:53:14.477539 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:53:14.477619 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:53:14.477693 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:53:14.480580 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:53:14.480813 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.480883 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:53:14.480945 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.481213 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:53:14.481298 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:53:14.481554 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:53:14.481613 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:53:14.481668 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:53:14.484422 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:53:14.484655 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.484737 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:53:14.484810 [debug] [Thread-1  ]: finished collecting timing info
[0m13:53:14.485119 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:53:14.485561 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:53:14.485645 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m13:53:14.490807 [info ] [MainThread]: Done.
[0m13:53:14.492499 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m13:53:14.492590 [info ] [MainThread]: Building catalog
[0m13:53:14.492871 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:53:15.028930 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m13:53:15.049835 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:53:15.051593 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m13:53:17.427765 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:35793103-9271-47e5-b200-ca0fd2f7bc0f:EU&page=queryresults
[0m13:53:17.447471 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m13:53:17.447817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108812370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ad6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ad6100>]}
[0m13:53:17.448050 [debug] [MainThread]: Flushing usage events
[0m13:53:17.980522 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m13:53:17.980702 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2022-12-22 13:22:21.384921 | 25665511-3428-482c-9cec-436f7ecc8a26 ==============================
[0m13:22:21.384959 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:22:21.385496 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:22:21.385586 [debug] [MainThread]: Tracking: tracking
[0m13:22:21.395068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162a640>]}
[0m13:22:21.431790 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:22:21.432030 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/whatever.yml
[0m13:22:21.445167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e6e80>]}
[0m13:22:21.449834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111796e80>]}
[0m13:22:21.449987 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:22:21.450197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111796e50>]}
[0m13:22:21.451058 [info ] [MainThread]: 
[0m13:22:21.451392 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:22:21.451884 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:22:21.452039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:22:22.136371 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:22:22.136699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:22:22.568757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078dc5b0>]}
[0m13:22:22.569317 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:22:22.569518 [info ] [MainThread]: 
[0m13:22:22.576711 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:22:22.577163 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:22:22.577909 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:22:22.578083 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:22:22.578273 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:22:22.582394 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:22:22.583289 [debug] [Thread-1  ]: finished collecting timing info
[0m13:22:22.583454 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:22:22.621203 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:22:22.621684 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:22:22.622491 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:22:25.218147 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:02814b11-36b0-41c1-95c0-02e227d3040e:EU&page=queryresults
[0m13:22:25.231606 [debug] [Thread-1  ]: finished collecting timing info
[0m13:22:25.232185 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118cebb0>]}
[0m13:22:25.232476 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.65s]
[0m13:22:25.232797 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:22:25.233258 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:22:25.233552 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:22:25.234066 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:22:25.234194 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:22:25.234290 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:22:25.236748 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:22:25.237215 [debug] [Thread-1  ]: finished collecting timing info
[0m13:22:25.237323 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:22:25.253012 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:22:25.253492 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:22:25.254403 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:22:26.123718 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:b1225d83-10a9-4adf-be2d-28590d959094:EU&page=queryresults
[0m13:22:26.126182 [debug] [Thread-1  ]: finished collecting timing info
[0m13:22:26.127131 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25665511-3428-482c-9cec-436f7ecc8a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126b1eb0>]}
[0m13:22:26.127675 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 0.89s]
[0m13:22:26.128171 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:22:26.130075 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:22:26.130768 [info ] [MainThread]: 
[0m13:22:26.131050 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.68 seconds (4.68s).
[0m13:22:26.131288 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:22:26.131422 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:22:26.141593 [info ] [MainThread]: 
[0m13:22:26.141824 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:22:26.142030 [info ] [MainThread]: 
[0m13:22:26.142201 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:22:26.142424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117af700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117af460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118bee20>]}
[0m13:22:26.142603 [debug] [MainThread]: Flushing usage events


============================== 2022-12-27 16:40:18.305003 | 7e6321a1-72bd-433c-930b-c11d4f424af1 ==============================
[0m16:40:18.305045 [info ] [MainThread]: Running with dbt=1.3.1
[0m16:40:18.305641 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m16:40:18.305726 [debug] [MainThread]: Tracking: tracking
[0m16:40:18.316134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a12a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a12a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a12a6d0>]}
[0m16:40:18.354610 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:40:18.354746 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:40:18.358114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e6321a1-72bd-433c-930b-c11d4f424af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2b50d0>]}
[0m16:40:18.362377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e6321a1-72bd-433c-930b-c11d4f424af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d93d0>]}
[0m16:40:18.362590 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:40:18.362734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e6321a1-72bd-433c-930b-c11d4f424af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d9460>]}
[0m16:40:18.363587 [info ] [MainThread]: 
[0m16:40:18.363947 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:40:18.364418 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m16:40:18.364548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:19.297706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e6321a1-72bd-433c-930b-c11d4f424af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a147250>]}
[0m16:40:19.298367 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:40:19.298588 [info ] [MainThread]: 
[0m16:40:19.304293 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m16:40:19.304938 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m16:40:19.305092 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m16:40:19.305239 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m16:40:19.308288 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m16:40:19.309185 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.309367 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m16:40:19.309517 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.310153 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m16:40:19.310738 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m16:40:19.311338 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m16:40:19.311527 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m16:40:19.311637 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m16:40:19.314373 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m16:40:19.314867 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.314985 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m16:40:19.315090 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.315557 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m16:40:19.315696 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:40:19.316211 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:40:19.316408 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:40:19.316539 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:40:19.328107 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:40:19.329396 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.329552 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:40:19.329651 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.330111 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:40:19.330223 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m16:40:19.330560 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m16:40:19.330648 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m16:40:19.330721 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m16:40:19.335697 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m16:40:19.336074 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.336189 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m16:40:19.336278 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.336660 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m16:40:19.336771 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m16:40:19.337147 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m16:40:19.337272 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m16:40:19.337363 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m16:40:19.340396 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m16:40:19.340775 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.340863 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m16:40:19.340938 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.341263 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m16:40:19.341359 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m16:40:19.341655 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:40:19.341739 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m16:40:19.341808 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m16:40:19.344439 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:40:19.344690 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.344773 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m16:40:19.344847 [debug] [Thread-1  ]: finished collecting timing info
[0m16:40:19.345165 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m16:40:19.345642 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:40:19.345758 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m16:40:19.350853 [info ] [MainThread]: Done.
[0m16:40:19.352353 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m16:40:19.352447 [info ] [MainThread]: Building catalog
[0m16:40:19.352743 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:40:20.206188 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m16:40:20.221775 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:40:20.223083 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m16:40:22.842617 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:98b1ebaa-780d-470c-a8cc-24ea0b569f5f:EU&page=queryresults
[0m16:40:22.851643 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m16:40:22.851967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a12a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3fcd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3fceb0>]}
[0m16:40:22.852167 [debug] [MainThread]: Flushing usage events
[0m16:40:28.303570 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:40:28.303973 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2022-12-28 05:21:11.657262 | 98d9e831-934b-46ca-8035-000fc578752e ==============================
[0m05:21:11.657284 [info ] [MainThread]: Running with dbt=1.3.1
[0m05:21:11.657780 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m05:21:11.657893 [debug] [MainThread]: Tracking: tracking
[0m05:21:11.670165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b134c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b136d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b13640>]}
[0m05:21:11.693370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b43220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c80640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c80820>]}
[0m05:21:11.693559 [debug] [MainThread]: Flushing usage events
[0m05:21:11.701628 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m05:21:11.701768 [error] [MainThread]: Encountered an error:
Compilation Error
  The yml property file at models/whatever.yml is invalid because the yml property file models/whatever.yml is missing a version tag. Please consult the documentation for more information on yml property file syntax:
  
  https://docs.getdbt.com/reference/configs-and-properties


============================== 2022-12-28 05:55:37.160530 | c36c0c9b-2501-4f0d-8dce-27774f1c469b ==============================
[0m05:55:37.160558 [info ] [MainThread]: Running with dbt=1.3.1
[0m05:55:37.161042 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m05:55:37.161271 [debug] [MainThread]: Tracking: tracking
[0m05:55:37.169860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a94c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a9640>]}
[0m05:55:37.205274 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
[0m05:55:37.205581 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m05:55:37.214494 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:55:37.243155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c36c0c9b-2501-4f0d-8dce-27774f1c469b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11029d0d0>]}
[0m05:55:37.248272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c36c0c9b-2501-4f0d-8dce-27774f1c469b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102625b0>]}
[0m05:55:37.248455 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m05:55:37.248587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c36c0c9b-2501-4f0d-8dce-27774f1c469b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110262610>]}
[0m05:55:37.249325 [info ] [MainThread]: 
[0m05:55:37.249645 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:55:37.250081 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m05:55:37.250189 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:05:06.759335 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:05:06.759530 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was properly closed.
[0m06:05:06.759688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021d9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021dac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102115e0>]}
[0m06:05:06.759843 [debug] [MainThread]: Flushing usage events
[0m06:05:06.762439 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m06:05:06.762574 [error] [MainThread]: Encountered an error:
Deadline of 600.0s exceeded while calling target function, last exception: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))
[0m06:05:06.802396 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py", line 953, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/auth/transport/requests.py", line 193, in __call__
    response = self.session.request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/requests/adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/retry.py", line 191, in retry_target
    return target()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/cloud/_http/__init__.py", line 482, in api_request
    response = self._make_request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/cloud/_http/__init__.py", line 341, in _make_request
    return self._do_request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/cloud/_http/__init__.py", line 379, in _do_request
    return self.http.request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/auth/transport/requests.py", line 545, in request
    self.credentials.before_request(auth_request, method, url, request_headers)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/auth/credentials.py", line 134, in before_request
    self.refresh(request)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/oauth2/service_account.py", line 429, in refresh
    access_token, expiry, _ = _client.jwt_grant(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/oauth2/_client.py", line 289, in jwt_grant
    response_data = _token_endpoint_request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/oauth2/_client.py", line 250, in _token_endpoint_request
    response_status_ok, response_data, retryable_error = _token_endpoint_request_no_throw(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/oauth2/_client.py", line 199, in _token_endpoint_request_no_throw
    request_succeeded, response_data, retryable_error = _perform_request()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/oauth2/_client.py", line 175, in _perform_request
    response = request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/auth/transport/requests.py", line 199, in __call__
    six.raise_from(new_exc, caught_exc)
  File "<string>", line 3, in raise_from
google.auth.exceptions.TransportError: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/main.py", line 135, in main
    results, succeeded = handle_and_check(args)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/main.py", line 198, in handle_and_check
    task, res = run_from_args(parsed)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/main.py", line 245, in run_from_args
    results = task.run()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/task/generate.py", line 210, in run
    compile_results = CompileTask.run(self)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/task/runnable.py", line 472, in run
    result = self.execute_with_hooks(selected_uids)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/task/runnable.py", line 434, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/task/runnable.py", line 421, in before_run
    self.populate_adapter_cache(adapter)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/task/runnable.py", line 409, in populate_adapter_cache
    adapter.set_relations_cache(self.manifest)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 437, in set_relations_cache
    self._relations_cache_for_schemas(manifest, required_schemas)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 414, in _relations_cache_for_schemas
    for relation in future.result():
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 438, in result
    return self.__get_result()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 390, in __get_result
    raise self._exception
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/utils.py", line 480, in connected
    return func(*args, **kwargs)
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/adapters/bigquery/impl.py", line 276, in list_relations_without_caching
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/dbt/adapters/bigquery/impl.py", line 276, in <listcomp>
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/page_iterator.py", line 208, in _items_iter
    for page in self._page_iter(increment=False):
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/page_iterator.py", line 244, in _page_iter
    page = self._next_page()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/page_iterator.py", line 373, in _next_page
    response = self._get_next_page_response()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/page_iterator.py", line 432, in _get_next_page_response
    return self.api_request(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/cloud/bigquery/client.py", line 1525, in api_request
    return self._call_api(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/retry.py", line 349, in retry_wrapped_func
    return retry_target(
  File "/Users/mitra/Documents/GitHub/environment/lib/python3.9/site-packages/google/api_core/retry.py", line 207, in retry_target
    raise exceptions.RetryError(
google.api_core.exceptions.RetryError: Deadline of 600.0s exceeded while calling target function, last exception: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1102215b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))



============================== 2022-12-28 06:26:25.500269 | 265d0d97-af5c-4e1c-8c23-d6dfbfa1f141 ==============================
[0m06:26:25.500295 [info ] [MainThread]: Running with dbt=1.3.1
[0m06:26:25.500971 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m06:26:25.501103 [debug] [MainThread]: Tracking: tracking
[0m06:26:25.518127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e99d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e99f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e99e80>]}
[0m06:26:25.560280 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m06:26:25.560592 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m06:26:25.568244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111107190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111131b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111425e0>]}
[0m06:26:25.568434 [debug] [MainThread]: Flushing usage events
[0m06:26:25.580088 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m06:26:25.580230 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid sources config given in models/example/schema.yml @ sources: {'name': 'some_source', 'table': [{'name': 'some_table'}]} - at path []: Additional properties are not allowed ('table' was unexpected)


============================== 2022-12-28 06:27:02.653184 | c93b965c-1e68-409d-aa45-12c76b771b2e ==============================
[0m06:27:02.653205 [info ] [MainThread]: Running with dbt=1.3.1
[0m06:27:02.653832 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m06:27:02.653945 [debug] [MainThread]: Tracking: tracking
[0m06:27:02.666420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d68490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d686a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d68610>]}
[0m06:27:02.705891 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m06:27:02.706175 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m06:27:02.725768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c93b965c-1e68-409d-aa45-12c76b771b2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114070ee0>]}
[0m06:27:02.730921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c93b965c-1e68-409d-aa45-12c76b771b2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114001ee0>]}
[0m06:27:02.731091 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m06:27:02.731228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c93b965c-1e68-409d-aa45-12c76b771b2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114001e50>]}
[0m06:27:02.732034 [info ] [MainThread]: 
[0m06:27:02.732403 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m06:27:02.732879 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m06:27:02.733003 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:33:50.307588 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:33:50.307913 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was left open.
[0m06:33:50.308022 [debug] [MainThread]: Flushing usage events
[0m06:33:50.311984 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m06:33:50.312138 [info ] [MainThread]: ctrl-c


============================== 2022-12-28 06:57:11.495724 | 4eba4d6e-6746-4b52-930b-0516b8d2da2e ==============================
[0m06:57:11.495749 [info ] [MainThread]: Running with dbt=1.3.1
[0m06:57:11.496402 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m06:57:11.496498 [debug] [MainThread]: Tracking: tracking
[0m06:57:11.507511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0ea0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0ea2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0ea220>]}
[0m06:57:11.543059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:57:11.543204 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:57:11.546512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4eba4d6e-6746-4b52-930b-0516b8d2da2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2780d0>]}
[0m06:57:11.551612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4eba4d6e-6746-4b52-930b-0516b8d2da2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1ae520>]}
[0m06:57:11.551761 [info ] [MainThread]: Found 2 models, 5 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m06:57:11.551882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4eba4d6e-6746-4b52-930b-0516b8d2da2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1ae5b0>]}
[0m06:57:11.552634 [info ] [MainThread]: 
[0m06:57:11.552947 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m06:57:11.553417 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m06:57:11.553558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:58:12.684674 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:58:12.684951 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was left open.
[0m06:58:12.685103 [debug] [MainThread]: Flushing usage events
[0m06:58:12.689888 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m06:58:12.690185 [info ] [MainThread]: ctrl-c


============================== 2022-12-28 06:58:18.130914 | 45b0f85e-9d44-4aec-bf89-e68401070bcc ==============================
[0m06:58:18.130935 [info ] [MainThread]: Running with dbt=1.3.1
[0m06:58:18.131358 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m06:58:18.131465 [debug] [MainThread]: Tracking: tracking
[0m06:58:18.138800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130d2670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130d2880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130d27f0>]}
[0m06:58:18.169732 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m06:58:18.170060 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.some_source.some_table
[0m06:58:18.170130 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m06:58:18.179532 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m06:58:18.190350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11336eca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113368340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113368fa0>]}
[0m06:58:18.190520 [debug] [MainThread]: Flushing usage events
[0m06:58:18.196322 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m06:58:18.196440 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid models config given in models/example/schema.yml @ models: {'name': 'my_first_dbt_model', 'meta': [{'data_contract': 'my_first_contract'}], 'tests': [{'unique': {'column_name': "id || '-'"}}], 'description': 'A starter dbt model', 'columns': [{'name': 'id', 'description': 'The primary key for this table', 'tests': ['unique', 'not_null']}], 'original_file_path': 'models/example/schema.yml', 'yaml_key': 'models', 'package_name': 'dbt_project'} - at path ['meta']: [{'data_contract': 'my_first_contract'}] is not of type 'object'


============================== 2023-01-03 11:03:11.160340 | f34a9995-5ce6-4390-9b74-85116610d047 ==============================
[0m11:03:11.160400 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:03:11.161070 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:03:11.161157 [debug] [MainThread]: Tracking: tracking
[0m11:03:11.173610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11999bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11999bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11999bf40>]}
[0m11:03:11.213016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:03:11.213394 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.some_source.some_table
[0m11:03:11.213481 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m11:03:11.222577 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m11:03:11.250425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bb30d0>]}
[0m11:03:11.255405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b7d520>]}
[0m11:03:11.255584 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:03:11.255711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b30cd0>]}
[0m11:03:11.256395 [info ] [MainThread]: 
[0m11:03:11.256729 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:03:11.257213 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m11:03:11.257398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:13.390199 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m11:03:13.390453 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:03:15.223961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b78c70>]}
[0m11:03:15.224671 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:03:15.224896 [info ] [MainThread]: 
[0m11:03:15.229562 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m11:03:15.229833 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m11:03:15.230329 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m11:03:15.230479 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m11:03:15.230635 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m11:03:15.233287 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m11:03:15.234290 [debug] [Thread-1  ]: finished collecting timing info
[0m11:03:15.234466 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m11:03:15.262868 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m11:03:15.263975 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:03:15.264896 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m11:03:19.703903 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:0b7f1a03-90c5-4bfc-be86-dccebfb0f375:EU&page=queryresults
[0m11:03:19.726278 [debug] [Thread-1  ]: finished collecting timing info
[0m11:03:19.726910 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119c75e80>]}
[0m11:03:19.727229 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.50s]
[0m11:03:19.727576 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m11:03:19.728205 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m11:03:19.728439 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m11:03:19.729105 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m11:03:19.729233 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m11:03:19.729344 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m11:03:19.731949 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m11:03:19.733943 [debug] [Thread-1  ]: finished collecting timing info
[0m11:03:19.734130 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m11:03:19.759784 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m11:03:19.760382 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:03:19.761271 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m11:03:22.547857 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:e34dbf1d-11ef-4337-8db9-fe80d871d3d8:EU&page=queryresults
[0m11:03:22.549079 [debug] [Thread-1  ]: finished collecting timing info
[0m11:03:22.549492 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f34a9995-5ce6-4390-9b74-85116610d047', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1283255e0>]}
[0m11:03:22.549700 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.82s]
[0m11:03:22.549931 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m11:03:22.550756 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:03:22.551020 [info ] [MainThread]: 
[0m11:03:22.551133 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.29 seconds (11.29s).
[0m11:03:22.551233 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:03:22.551287 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m11:03:22.559096 [info ] [MainThread]: 
[0m11:03:22.559374 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:03:22.559612 [info ] [MainThread]: 
[0m11:03:22.559800 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:03:22.560060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b043a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b1c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b2c160>]}
[0m11:03:22.560277 [debug] [MainThread]: Flushing usage events


============================== 2023-01-03 11:07:35.982176 | 5e14a6e1-603e-421b-b8de-50bdff96a204 ==============================
[0m11:07:35.982201 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:07:35.982808 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:07:35.982896 [debug] [MainThread]: Tracking: tracking
[0m11:07:35.992350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106baa4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106baa700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106baa670>]}
[0m11:07:36.023660 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:07:36.024012 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m11:07:36.031540 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m11:07:36.060087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106da30d0>]}
[0m11:07:36.064610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d612b0>]}
[0m11:07:36.064851 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:07:36.065014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d0f340>]}
[0m11:07:36.065849 [info ] [MainThread]: 
[0m11:07:36.066285 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:07:36.066934 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m11:07:36.067140 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:07:37.973349 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m11:07:37.973734 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:07:39.795972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10585c580>]}
[0m11:07:39.796410 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:07:39.796702 [info ] [MainThread]: 
[0m11:07:39.800504 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m11:07:39.800839 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m11:07:39.801478 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m11:07:39.801626 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m11:07:39.801767 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m11:07:39.805027 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m11:07:39.805662 [debug] [Thread-1  ]: finished collecting timing info
[0m11:07:39.805818 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m11:07:39.820273 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:41.644320 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m11:07:41.644772 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m11:07:44.175675 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:649b5f06-fa4c-4117-bbc9-883b6b9d78e2:EU&page=queryresults
[0m11:07:44.207535 [debug] [Thread-1  ]: finished collecting timing info
[0m11:07:44.207906 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d22940>]}
[0m11:07:44.208173 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.41s]
[0m11:07:44.208625 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m11:07:44.209533 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m11:07:44.210007 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m11:07:44.210640 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m11:07:44.210833 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m11:07:44.210947 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m11:07:44.213016 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m11:07:44.213373 [debug] [Thread-1  ]: finished collecting timing info
[0m11:07:44.213455 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m11:07:44.242641 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m11:07:44.243090 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:07:44.243975 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m11:07:47.021481 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:7e0e1a51-9f46-4bf4-a6f8-27a1e06705f9:EU&page=queryresults
[0m11:07:47.023343 [debug] [Thread-1  ]: finished collecting timing info
[0m11:07:47.023980 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e14a6e1-603e-421b-b8de-50bdff96a204', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d22ac0>]}
[0m11:07:47.024370 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.81s]
[0m11:07:47.024940 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m11:07:47.026661 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:07:47.027277 [info ] [MainThread]: 
[0m11:07:47.027567 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.96 seconds (10.96s).
[0m11:07:47.027809 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:07:47.027934 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m11:07:47.041096 [info ] [MainThread]: 
[0m11:07:47.041402 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:07:47.041644 [info ] [MainThread]: 
[0m11:07:47.041935 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:07:47.042364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fd3bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fdedc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8bfa0>]}
[0m11:07:47.042604 [debug] [MainThread]: Flushing usage events


============================== 2023-01-03 11:08:08.176363 | 62277e44-1160-4722-a075-83f7767e4385 ==============================
[0m11:08:08.176398 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:08:08.176864 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m11:08:08.176955 [debug] [MainThread]: Tracking: tracking
[0m11:08:08.185314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e121f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e12400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e12370>]}
[0m11:08:08.217141 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:08:08.217293 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:08:08.221110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62277e44-1160-4722-a075-83f7767e4385', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbbe50>]}
[0m11:08:08.225895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62277e44-1160-4722-a075-83f7767e4385', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f85b80>]}
[0m11:08:08.226067 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:08:08.226196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62277e44-1160-4722-a075-83f7767e4385', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ece040>]}
[0m11:08:08.226952 [info ] [MainThread]: 
[0m11:08:08.227292 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:08:08.227899 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m11:08:08.228086 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:08:10.069794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62277e44-1160-4722-a075-83f7767e4385', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e46460>]}
[0m11:08:10.070918 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:08:10.071287 [info ] [MainThread]: 
[0m11:08:10.075385 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:08:10.075674 [info ] [Thread-1  ]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m11:08:10.076461 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:08:10.076629 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:08:10.076782 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:08:10.091266 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:08:10.092280 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:10.092483 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:08:10.109254 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:08:10.109813 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:08:10.110827 [debug] [Thread-1  ]: On test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m11:08:13.338865 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:6e51b6d4-98da-48cb-b7ec-aeffc1a9acf7:EU&page=queryresults
[0m11:08:13.340594 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:13.341434 [error] [Thread-1  ]: 1 of 4 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 3.27s]
[0m11:08:13.342061 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:08:13.342310 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m11:08:13.342665 [info ] [Thread-1  ]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m11:08:13.343720 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m11:08:13.343940 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m11:08:13.344124 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m11:08:13.349931 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m11:08:13.351954 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:13.352146 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m11:08:13.354118 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m11:08:13.354451 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:08:13.355346 [debug] [Thread-1  ]: On test.dbt_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m11:08:16.068539 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:6b3a6a08-da50-4fad-ad56-dfd3d3a394c9:EU&page=queryresults
[0m11:08:16.069056 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:16.069574 [info ] [Thread-1  ]: 2 of 4 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 2.73s]
[0m11:08:16.069995 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m11:08:16.070152 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m11:08:16.070371 [info ] [Thread-1  ]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m11:08:16.070949 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m11:08:16.071080 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m11:08:16.071192 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m11:08:16.081406 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m11:08:16.082826 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:16.082973 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m11:08:16.087537 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m11:08:16.087889 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:08:16.088764 [debug] [Thread-1  ]: On test.dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m11:08:19.333775 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:83742769-7388-46a1-8fa9-3d89b1267d4a:EU&page=queryresults
[0m11:08:19.334402 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:19.335048 [info ] [Thread-1  ]: 3 of 4 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 3.26s]
[0m11:08:19.335473 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m11:08:19.335663 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m11:08:19.335967 [info ] [Thread-1  ]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m11:08:19.336794 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:08:19.336971 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m11:08:19.337254 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m11:08:19.348337 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:08:19.349372 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:19.349595 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m11:08:19.351809 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:08:19.352384 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:08:19.353718 [debug] [Thread-1  ]: On test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m11:08:22.687710 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:fc87a6df-57f1-4c3e-8d99-363991635cfa:EU&page=queryresults
[0m11:08:22.688315 [debug] [Thread-1  ]: finished collecting timing info
[0m11:08:22.688954 [info ] [Thread-1  ]: 4 of 4 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 3.35s]
[0m11:08:22.689376 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m11:08:22.690511 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:08:22.690861 [info ] [MainThread]: 
[0m11:08:22.691075 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 14.46 seconds (14.46s).
[0m11:08:22.691249 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:08:22.691317 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m11:08:22.703221 [info ] [MainThread]: 
[0m11:08:22.703523 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:08:22.703786 [info ] [MainThread]: 
[0m11:08:22.703986 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m11:08:22.704192 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m11:08:22.704386 [info ] [MainThread]: 
[0m11:08:22.704599 [info ] [MainThread]:   compiled Code at target/compiled/dbt_project/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m11:08:22.704784 [info ] [MainThread]: 
[0m11:08:22.704951 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m11:08:22.705195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbb070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f85910>]}
[0m11:08:22.705397 [debug] [MainThread]: Flushing usage events


============================== 2023-01-03 11:11:14.621617 | beff5596-3e3d-4811-a92c-731b9d33dd4f ==============================
[0m11:11:14.621636 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:11:14.622056 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:11:14.622149 [debug] [MainThread]: Tracking: tracking
[0m11:11:14.632571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110669190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106693a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110669310>]}
[0m11:11:14.656606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11062d730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c5280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c5250>]}
[0m11:11:14.656809 [debug] [MainThread]: Flushing usage events
[0m11:11:17.889687 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 3
    ------------------------------
    1  | version: 2
    2  | 
    3  |   - name: my_second_dbt_model
    4  |     description: "A starter dbt model"
    5  |     columns:
    6  |       - name: id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 3, column 9


============================== 2023-01-03 11:13:57.457389 | 6b8d159e-bec3-4de2-9a5c-f4311ea92984 ==============================
[0m11:13:57.457454 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:13:57.458063 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:13:57.458171 [debug] [MainThread]: Tracking: tracking
[0m11:13:57.466462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a71f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a7400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a7370>]}
[0m11:13:57.489871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105157040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053191f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105319280>]}
[0m11:13:57.490100 [debug] [MainThread]: Flushing usage events
[0m11:13:58.529748 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 3
    ------------------------------
    1  | version: 2
    2  | 
    3  |   - name: my_second_dbt_model
    4  |     description: "A starter dbt model"
    5  |     columns:
    6  |       - name: id
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 3, column 9


============================== 2023-01-03 11:14:05.466731 | fd88639a-fda3-4e51-92f9-1b3dbb959235 ==============================
[0m11:14:05.466784 [info ] [MainThread]: Running with dbt=1.3.1
[0m11:14:05.467249 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m11:14:05.467331 [debug] [MainThread]: Tracking: tracking
[0m11:14:05.475428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109e7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109e76a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109e7610>]}
[0m11:14:05.508931 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:14:05.509268 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m11:14:05.529415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bba0d0>]}
[0m11:14:05.533826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b57e20>]}
[0m11:14:05.534001 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m11:14:05.534143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b57f10>]}
[0m11:14:05.534880 [info ] [MainThread]: 
[0m11:14:05.535210 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:14:05.535793 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m11:14:05.536039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:14:07.707184 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m11:14:07.707805 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:14:09.496359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106911580>]}
[0m11:14:09.497870 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:14:09.498425 [info ] [MainThread]: 
[0m11:14:09.502542 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m11:14:09.502941 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m11:14:09.503694 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m11:14:09.503869 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m11:14:09.504034 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m11:14:09.513181 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m11:14:09.513737 [debug] [Thread-1  ]: finished collecting timing info
[0m11:14:09.513863 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m11:14:09.530340 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:14:11.356588 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m11:14:11.357158 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m11:14:14.181935 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:9d99d51f-8cf1-45a1-8c9b-bd6d9475b7f9:EU&page=queryresults
[0m11:14:14.196518 [debug] [Thread-1  ]: finished collecting timing info
[0m11:14:14.196982 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b57580>]}
[0m11:14:14.197209 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.69s]
[0m11:14:14.197456 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m11:14:14.197889 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m11:14:14.198172 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m11:14:14.198663 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m11:14:14.198768 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m11:14:14.198855 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m11:14:14.200953 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m11:14:14.201348 [debug] [Thread-1  ]: finished collecting timing info
[0m11:14:14.201439 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m11:14:14.215348 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m11:14:14.215796 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:14:14.216647 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m11:14:17.122989 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:4b594f86-5628-42cf-bc6e-bb267f2927f3:EU&page=queryresults
[0m11:14:17.124674 [debug] [Thread-1  ]: finished collecting timing info
[0m11:14:17.125219 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd88639a-fda3-4e51-92f9-1b3dbb959235', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11223e0d0>]}
[0m11:14:17.125491 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.93s]
[0m11:14:17.125781 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m11:14:17.126589 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m11:14:17.126917 [info ] [MainThread]: 
[0m11:14:17.127041 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.59 seconds (11.59s).
[0m11:14:17.127152 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:14:17.127223 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m11:14:17.135799 [info ] [MainThread]: 
[0m11:14:17.135996 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:14:17.136140 [info ] [MainThread]: 
[0m11:14:17.136249 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:14:17.136424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c875b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c874c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112221fa0>]}
[0m11:14:17.136631 [debug] [MainThread]: Flushing usage events


============================== 2023-01-07 17:01:28.747897 | aad2525e-c5b0-4fa6-9a02-41ccfca95eaf ==============================
[0m17:01:28.747935 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:01:28.748343 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:01:28.748422 [debug] [MainThread]: Tracking: tracking
[0m17:01:28.756641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d29220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d29430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d293a0>]}
[0m17:01:28.779103 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m17:01:28.779337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'aad2525e-c5b0-4fa6-9a02-41ccfca95eaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d140a0>]}
[0m17:01:28.789863 [debug] [MainThread]: Parsing macros/etc.sql
[0m17:01:28.791171 [debug] [MainThread]: Parsing macros/catalog.sql
[0m17:01:28.795129 [debug] [MainThread]: Parsing macros/adapters.sql
[0m17:01:28.806545 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m17:01:28.807867 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m17:01:28.809323 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m17:01:28.813453 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m17:01:28.814841 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m17:01:28.823884 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m17:01:28.824702 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m17:01:28.824876 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m17:01:28.825168 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m17:01:28.825672 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m17:01:28.825837 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m17:01:28.826126 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m17:01:28.826691 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m17:01:28.827247 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m17:01:28.827872 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m17:01:28.828121 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m17:01:28.828349 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m17:01:28.828598 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m17:01:28.828842 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m17:01:28.829048 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m17:01:28.829808 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m17:01:28.830054 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m17:01:28.830442 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m17:01:28.830714 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m17:01:28.831975 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m17:01:28.833875 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m17:01:28.834983 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m17:01:28.835782 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m17:01:28.844442 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m17:01:28.851970 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m17:01:28.858677 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m17:01:28.860970 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m17:01:28.861892 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m17:01:28.862756 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m17:01:28.866803 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m17:01:28.875569 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m17:01:28.876307 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m17:01:28.879590 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m17:01:28.884923 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m17:01:28.894452 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m17:01:28.897293 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m17:01:28.898975 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m17:01:28.901764 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m17:01:28.902378 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m17:01:28.904038 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m17:01:28.905112 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m17:01:28.908656 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m17:01:28.918944 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m17:01:28.919676 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m17:01:28.920865 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m17:01:28.921609 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m17:01:28.922021 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m17:01:28.922387 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m17:01:28.922695 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m17:01:28.923344 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m17:01:28.925917 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m17:01:28.930661 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m17:01:28.931105 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m17:01:28.931694 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m17:01:28.932149 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m17:01:28.932582 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m17:01:28.933162 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m17:01:28.933532 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m17:01:28.934011 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m17:01:28.934605 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m17:01:28.935747 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m17:01:28.936344 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m17:01:28.936839 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m17:01:28.937476 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m17:01:28.938040 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m17:01:28.938481 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m17:01:28.939002 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m17:01:28.939431 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m17:01:28.942683 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m17:01:28.943190 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m17:01:28.943618 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m17:01:28.944508 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m17:01:28.945602 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m17:01:28.946077 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m17:01:28.946795 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m17:01:28.947286 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m17:01:28.948278 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m17:01:28.949849 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m17:01:28.951210 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m17:01:28.959173 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m17:01:28.960168 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m17:01:28.967342 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m17:01:28.969546 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m17:01:28.973203 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m17:01:28.978191 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m17:01:28.981260 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m17:01:29.118603 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m17:01:29.124891 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m17:01:29.195877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aad2525e-c5b0-4fa6-9a02-41ccfca95eaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d6cd00>]}
[0m17:01:29.200410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aad2525e-c5b0-4fa6-9a02-41ccfca95eaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d6c8e0>]}
[0m17:01:29.200583 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:01:29.200703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aad2525e-c5b0-4fa6-9a02-41ccfca95eaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e812b0>]}
[0m17:01:29.201333 [info ] [MainThread]: 
[0m17:01:29.201661 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:01:29.202178 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:01:29.202312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:01:32.506982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aad2525e-c5b0-4fa6-9a02-41ccfca95eaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107deee80>]}
[0m17:01:32.507487 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:01:32.507677 [info ] [MainThread]: 
[0m17:01:32.511801 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:01:32.512567 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:01:32.512739 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:01:32.512884 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:01:32.516393 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:01:32.517004 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.517163 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:01:32.517309 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.517785 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:01:32.518373 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:01:32.519048 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:01:32.519183 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:01:32.519284 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:01:32.521918 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:01:32.522437 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.522574 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:01:32.522694 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.523222 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:01:32.523381 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:01:32.523937 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:01:32.524194 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:01:32.524315 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:01:32.535924 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:01:32.536770 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.536910 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:01:32.537020 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.537473 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:01:32.537600 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:01:32.537975 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:01:32.538064 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:01:32.538128 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:01:32.541841 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:01:32.542191 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.542266 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:01:32.542330 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.542606 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:01:32.542685 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:01:32.542942 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:01:32.543019 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:01:32.543082 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:01:32.545287 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:01:32.545584 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.545678 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:01:32.545764 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.546128 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:01:32.546232 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:01:32.546566 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:01:32.546661 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:01:32.546740 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:01:32.549451 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:01:32.549703 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.549785 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:01:32.549859 [debug] [Thread-1  ]: finished collecting timing info
[0m17:01:32.550168 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:01:32.550583 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:01:32.550662 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:01:32.556191 [info ] [MainThread]: Done.
[0m17:01:32.558107 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:01:32.558186 [info ] [MainThread]: Building catalog
[0m17:01:32.558417 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:01:35.944706 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:01:35.961992 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:01:35.963572 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:01:40.972748 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a044d002-5a66-4397-9649-732a6f6b427d:EU&page=queryresults
[0m17:01:40.988468 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:01:40.988820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d29220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f01910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f01370>]}
[0m17:01:40.989041 [debug] [MainThread]: Flushing usage events
[0m17:01:42.717359 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:01:42.717547 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:30:11.522982 | 528ef75c-b847-46b8-a28b-eebfb81eea56 ==============================
[0m17:30:11.523033 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:30:11.523462 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:30:11.523551 [debug] [MainThread]: Tracking: tracking
[0m17:30:11.530907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a12f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a2e160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a2e100>]}
[0m17:30:11.553664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109fa250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a830d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a83130>]}
[0m17:30:11.553856 [debug] [MainThread]: Flushing usage events
[0m17:30:14.722959 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 12
    ------------------------------
    9  |         start_date: "2021-07-11T12:00:00Z"
    10 |     tables: 
    11 |       -  name: "admins"
    12 |           description: "some markdown description"
    13 |           meta: 
    14 |             import_configs:
    15 |               import: "admins"
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 11, column 10
    did not find expected key
      in "<unicode string>", line 12, column 11


============================== 2023-01-07 17:30:59.901783 | 5f80a8c8-975b-48ad-bbf7-2fd755b4f043 ==============================
[0m17:30:59.901830 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:30:59.902336 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:30:59.902426 [debug] [MainThread]: Tracking: tracking
[0m17:30:59.911832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a259cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a259ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a259e50>]}
[0m17:30:59.935737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a268280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3bee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3bed60>]}
[0m17:30:59.935922 [debug] [MainThread]: Flushing usage events
[0m17:31:01.583145 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 12
    ------------------------------
    9  |         start_date: "2021-07-11T12:00:00Z"
    10 |     tables: 
    11 |       -  name: "admins"
    12 |           description: "some markdown description"
    13 |           meta: 
    14 |             import_configs:
    15 |               import: "admins"
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 11, column 10
    did not find expected key
      in "<unicode string>", line 12, column 11


============================== 2023-01-07 17:31:24.992317 | 9b535d9c-c74a-4ef6-985b-270ee7d4ffbe ==============================
[0m17:31:24.992344 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:31:24.992721 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:31:24.992811 [debug] [MainThread]: Tracking: tracking
[0m17:31:25.004272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e75e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e7550>]}
[0m17:31:25.027733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a1be80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b58580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b58430>]}
[0m17:31:25.027945 [debug] [MainThread]: Flushing usage events
[0m17:31:27.090571 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 8
    ------------------------------
    5  |     description: "some markdown description"
    6  |     tables: 
    7  |       -  name: "admins"
    8  |           description: "some markdown description"
    9  |           meta: 
    10 |             import_configs:
    11 |               import: "admins"
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 7, column 10
    did not find expected key
      in "<unicode string>", line 8, column 11


============================== 2023-01-07 17:31:40.725947 | 1da503ae-322f-4de8-9659-d802ee8f2ba9 ==============================
[0m17:31:40.725972 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:31:40.726380 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:31:40.726495 [debug] [MainThread]: Tracking: tracking
[0m17:31:40.736182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138ea370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138ea580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138ea4f0>]}
[0m17:31:40.758646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11391ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a58520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a583d0>]}
[0m17:31:40.758846 [debug] [MainThread]: Flushing usage events
[0m17:31:42.668406 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 8
    ------------------------------
    5  |     description: "some markdown description"
    6  |     tables: 
    7  |       -  name: "admins"
    8  |           description: "some markdown description"
    9  |            columns: 
    10 |              - name: "id"
    11 |                 description: "unique id"
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 7, column 10
    did not find expected key
      in "<unicode string>", line 8, column 11


============================== 2023-01-07 17:34:14.441992 | c10a2a97-bb18-4942-8bce-e25a3f2fb793 ==============================
[0m17:34:14.442019 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:34:14.442475 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:34:14.442560 [debug] [MainThread]: Tracking: tracking
[0m17:34:14.449950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11201cdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11201cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11201cf40>]}
[0m17:34:14.472554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10440e670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112192f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112192e50>]}
[0m17:34:14.472745 [debug] [MainThread]: Flushing usage events
[0m17:34:17.296020 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m17:34:17.296270 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 11
    ------------------------------
    8  |         description: "some markdown description"
    9  |         columns: 
    10 |              - name: "id"
    11 |                 description: "unique id"
    12 |                 tests:
    13 |                     - unique
    14 |                     - not_null
    
    Raw Error:
    ------------------------------
    while parsing a block mapping
      in "<unicode string>", line 10, column 16
    did not find expected key
      in "<unicode string>", line 11, column 17


============================== 2023-01-07 17:34:44.977482 | 0f9ff532-6800-4e50-91c9-9e38741e655f ==============================
[0m17:34:44.977518 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:34:44.978003 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:34:44.978097 [debug] [MainThread]: Tracking: tracking
[0m17:34:44.986874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a67280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a67490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a67400>]}
[0m17:34:45.017529 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:34:45.017830 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m17:34:45.037287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f9ff532-6800-4e50-91c9-9e38741e655f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c21e50>]}
[0m17:34:45.041505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f9ff532-6800-4e50-91c9-9e38741e655f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bc4c40>]}
[0m17:34:45.041669 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m17:34:45.041815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f9ff532-6800-4e50-91c9-9e38741e655f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bc4d30>]}
[0m17:34:45.042563 [info ] [MainThread]: 
[0m17:34:45.042901 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:34:45.043382 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:34:45.043507 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:34:56.867199 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:34:56.867581 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was left open.
[0m17:34:56.867779 [debug] [MainThread]: Flushing usage events
[0m17:34:59.592774 [info ] [MainThread]: ctrl-c


============================== 2023-01-07 17:35:04.758825 | 77b7ee7f-3fbd-489f-a489-5b71fc587c58 ==============================
[0m17:35:04.758864 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:35:04.759252 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:35:04.759337 [debug] [MainThread]: Tracking: tracking
[0m17:35:04.767469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106327430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106327640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063275b0>]}
[0m17:35:04.799470 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:35:04.799608 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:35:04.802922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '77b7ee7f-3fbd-489f-a489-5b71fc587c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064bf0d0>]}
[0m17:35:04.807036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '77b7ee7f-3fbd-489f-a489-5b71fc587c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063f2b50>]}
[0m17:35:04.807183 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
[0m17:35:04.807309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77b7ee7f-3fbd-489f-a489-5b71fc587c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063f2b80>]}
[0m17:35:04.808105 [info ] [MainThread]: 
[0m17:35:04.808416 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:35:04.808852 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:35:04.808924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:35:08.855319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77b7ee7f-3fbd-489f-a489-5b71fc587c58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10633edf0>]}
[0m17:35:08.856759 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:35:08.857155 [info ] [MainThread]: 
[0m17:35:08.861665 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:35:08.862374 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:35:08.862560 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:35:08.862729 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:35:08.867293 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:35:08.868206 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.868370 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:35:08.868532 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.869151 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:35:08.869761 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:35:08.870394 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:35:08.870584 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:35:08.870721 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:35:08.873779 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:35:08.874328 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.874494 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:35:08.874622 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.875140 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:35:08.875303 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:35:08.875750 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:35:08.875952 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:35:08.876055 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:35:08.886566 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:35:08.886922 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.886996 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:35:08.887056 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.887324 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:35:08.887404 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:35:08.887615 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:35:08.887723 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:35:08.887811 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:35:08.892317 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:35:08.892678 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.892776 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:35:08.892861 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.893220 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:35:08.893339 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:35:08.893688 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:35:08.893796 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:35:08.893887 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:35:08.896648 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:35:08.896874 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.896950 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:35:08.897018 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.897308 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:35:08.897401 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:35:08.897667 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:35:08.897734 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:35:08.897796 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:35:08.900315 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:35:08.900565 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.900646 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:35:08.900720 [debug] [Thread-1  ]: finished collecting timing info
[0m17:35:08.901021 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:35:08.901482 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:35:08.901562 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:35:08.907028 [info ] [MainThread]: Done.
[0m17:35:08.907998 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:35:08.908083 [info ] [MainThread]: Building catalog
[0m17:35:08.908549 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:35:12.021340 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.jaffle_shop - schema does not exist
[0m17:35:12.021812 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.stripe - schema does not exist
[0m17:35:12.022839 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:35:12.039058 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:35:12.040237 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:35:25.294839 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:5738c8ef-583d-4459-9d63-f85479afd48e:EU&page=queryresults
[0m17:35:25.316388 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:35:25.316666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106327430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106537b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065370d0>]}
[0m17:35:25.316794 [debug] [MainThread]: Flushing usage events
[0m17:35:32.353194 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m17:35:32.353763 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:35:32.354094 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:36:22.594875 | c3bc10da-b4b1-40b9-a68c-ba802ea8dfb2 ==============================
[0m17:36:22.594907 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:36:22.595385 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:36:22.595486 [debug] [MainThread]: Tracking: tracking
[0m17:36:22.603460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dea280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dea490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dea400>]}
[0m17:36:22.633847 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:36:22.634147 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m17:36:22.653138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3bc10da-b4b1-40b9-a68c-ba802ea8dfb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fa70d0>]}
[0m17:36:22.657115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3bc10da-b4b1-40b9-a68c-ba802ea8dfb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f47dc0>]}
[0m17:36:22.657260 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
[0m17:36:22.657413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3bc10da-b4b1-40b9-a68c-ba802ea8dfb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f47f40>]}
[0m17:36:22.658168 [info ] [MainThread]: 
[0m17:36:22.658500 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:36:22.658990 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:36:22.659082 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:36:24.724473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3bc10da-b4b1-40b9-a68c-ba802ea8dfb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f47b50>]}
[0m17:36:24.727223 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:36:24.728044 [info ] [MainThread]: 
[0m17:36:24.731844 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:36:24.732344 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:36:24.732449 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:36:24.732545 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:36:24.736964 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:36:24.737419 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.737526 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:36:24.737626 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.738014 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:36:24.738372 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:36:24.738768 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:36:24.738870 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:36:24.738957 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:36:24.742684 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:36:24.743116 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.743234 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:36:24.743336 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.743796 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:36:24.743936 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:36:24.744302 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:36:24.744509 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:36:24.744822 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:36:24.757470 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:36:24.758110 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.758250 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:36:24.758354 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.758795 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:36:24.758919 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:36:24.759307 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:36:24.759400 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:36:24.759485 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:36:24.764452 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:36:24.764782 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.764874 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:36:24.764943 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.765238 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:36:24.765322 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:36:24.765561 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:36:24.765623 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:36:24.765681 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:36:24.768043 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:36:24.768346 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.768441 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:36:24.768522 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.768861 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:36:24.768969 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:36:24.769270 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:36:24.769349 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:36:24.769422 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:36:24.772202 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:36:24.772444 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.772528 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:36:24.772601 [debug] [Thread-1  ]: finished collecting timing info
[0m17:36:24.772912 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:36:24.773528 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:36:24.773638 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:36:24.778492 [info ] [MainThread]: Done.
[0m17:36:24.779458 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:36:24.779537 [info ] [MainThread]: Building catalog
[0m17:36:24.780021 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:36:27.001061 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.jaffle_shop - schema does not exist
[0m17:36:27.001231 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.stripe - schema does not exist
[0m17:36:27.001299 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m17:36:27.001715 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:36:27.018910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:36:27.020154 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:36:32.012849 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:b2f3059d-f232-4ffc-aba5-7e1f56e31ad0:EU&page=queryresults
[0m17:36:32.019953 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:36:32.020196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dea280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11204f340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11204f190>]}
[0m17:36:32.020330 [debug] [MainThread]: Flushing usage events
[0m17:36:33.678726 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:36:33.679335 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:37:23.253508 | 12b83fec-2203-4968-98b0-8c657229149c ==============================
[0m17:37:23.253543 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:37:23.254023 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:37:23.254110 [debug] [MainThread]: Tracking: tracking
[0m17:37:23.264732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113727430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113727640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137275b0>]}
[0m17:37:23.295944 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:37:23.296081 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:37:23.299436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '12b83fec-2203-4968-98b0-8c657229149c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a000d0>]}
[0m17:37:23.303678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '12b83fec-2203-4968-98b0-8c657229149c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113935d60>]}
[0m17:37:23.303820 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 4 sources, 0 exposures, 0 metrics
[0m17:37:23.303972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12b83fec-2203-4968-98b0-8c657229149c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113935df0>]}
[0m17:37:23.304751 [info ] [MainThread]: 
[0m17:37:23.305093 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:37:23.305555 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:37:23.305642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:37:25.298746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12b83fec-2203-4968-98b0-8c657229149c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11373e640>]}
[0m17:37:25.299855 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:37:25.300174 [info ] [MainThread]: 
[0m17:37:25.304522 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:37:25.305124 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:37:25.305276 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:37:25.305448 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:37:25.309802 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:37:25.310468 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.310626 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:37:25.310755 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.311279 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:37:25.311994 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:37:25.312942 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:37:25.313096 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:37:25.313208 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:37:25.316131 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:37:25.316619 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.316742 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:37:25.316843 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.317283 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:37:25.317417 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:37:25.317822 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:37:25.317995 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:37:25.318107 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:37:25.328291 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:37:25.328703 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.328802 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:37:25.328890 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.329264 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:37:25.329375 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:37:25.329718 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:37:25.329816 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:37:25.329900 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:37:25.334624 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:37:25.334928 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.335018 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:37:25.335098 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.335422 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:37:25.335520 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:37:25.335823 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:37:25.335898 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:37:25.335967 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:37:25.338658 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:37:25.338944 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.339018 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:37:25.339082 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.339353 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:37:25.339437 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:37:25.339684 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:37:25.339749 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:37:25.339808 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:37:25.342453 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:37:25.342737 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.342819 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:37:25.342892 [debug] [Thread-1  ]: finished collecting timing info
[0m17:37:25.343197 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:37:25.343628 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:37:25.343720 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:37:25.351447 [info ] [MainThread]: Done.
[0m17:37:25.352392 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:37:25.352471 [info ] [MainThread]: Building catalog
[0m17:37:25.353013 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:37:27.871440 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.jaffle_shop - schema does not exist
[0m17:37:27.871688 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.stripe - schema does not exist
[0m17:37:27.871795 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m17:37:27.872434 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:37:27.886628 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:37:27.887755 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:37:33.559750 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a2e91777-efe0-4e80-8c6b-b1974d6d1db9:EU&page=queryresults
[0m17:37:33.594111 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:37:33.594679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113727430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d1ac10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d1adf0>]}
[0m17:37:33.595014 [debug] [MainThread]: Flushing usage events
[0m17:37:35.185127 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:37:35.186039 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:39:38.622710 | 979719e9-c3f5-43cc-9b20-fd3bcbbdc504 ==============================
[0m17:39:38.622791 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:39:38.623335 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:39:38.623415 [debug] [MainThread]: Tracking: tracking
[0m17:39:38.631264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2f130>]}
[0m17:39:38.661459 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:39:38.661754 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.Intercom special.admins
[0m17:39:38.661824 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.stripe.payments
[0m17:39:38.661879 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.jaffle_shop.orders
[0m17:39:38.661929 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.jaffle_shop.customers
[0m17:39:38.661982 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m17:39:38.695256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '979719e9-c3f5-43cc-9b20-fd3bcbbdc504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a60d0>]}
[0m17:39:38.699737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '979719e9-c3f5-43cc-9b20-fd3bcbbdc504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072358e0>]}
[0m17:39:38.699885 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:39:38.700010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '979719e9-c3f5-43cc-9b20-fd3bcbbdc504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1bfa0>]}
[0m17:39:38.700779 [info ] [MainThread]: 
[0m17:39:38.701121 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:39:38.701586 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:39:38.701710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:39:40.951859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '979719e9-c3f5-43cc-9b20-fd3bcbbdc504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107235730>]}
[0m17:39:40.953123 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:39:40.953580 [info ] [MainThread]: 
[0m17:39:40.957231 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:39:40.957795 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:39:40.957935 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:39:40.958056 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:39:40.960911 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:39:40.961394 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.961514 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:39:40.961634 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.962105 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:39:40.962239 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:39:40.962782 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:39:40.963081 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:39:40.963228 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:39:40.973706 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:39:40.974196 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.974306 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:39:40.974399 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.974804 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:39:40.974922 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:39:40.975384 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:39:40.975556 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:39:40.975676 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:39:40.980792 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:39:40.981205 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.981304 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:39:40.981387 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.981739 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:39:40.981844 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:39:40.982192 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:39:40.982299 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:39:40.982384 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:39:40.984266 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:39:40.984565 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.984772 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:39:40.984870 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.985260 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:39:40.985365 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:39:40.985747 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:39:40.985930 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:39:40.986036 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:39:40.991079 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:39:40.991420 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.991510 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:39:40.991581 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.991893 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:39:40.992006 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:39:40.992283 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:39:40.992354 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:39:40.992419 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:39:40.996504 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:39:40.996830 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.996920 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:39:40.996990 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:40.997281 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:39:40.997369 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:39:40.997710 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:39:40.997833 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:39:40.997905 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:39:41.000507 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:39:41.000808 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:41.000882 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:39:41.000950 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:41.001253 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:39:41.001349 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:39:41.001638 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:39:41.001727 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:39:41.001792 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:39:41.004151 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:39:41.004437 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:41.004520 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:39:41.004587 [debug] [Thread-1  ]: finished collecting timing info
[0m17:39:41.004879 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:39:41.005330 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:39:41.005431 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:39:41.009591 [info ] [MainThread]: Done.
[0m17:39:41.010537 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:39:41.010622 [info ] [MainThread]: Building catalog
[0m17:39:41.010915 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:39:44.320872 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m17:39:44.322593 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:39:44.342023 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:39:44.343614 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:39:48.764208 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:e634e859-8337-4163-8843-5b304445315e:EU&page=queryresults
[0m17:39:48.781821 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:39:48.782210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1bf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071f9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071f97c0>]}
[0m17:39:48.782438 [debug] [MainThread]: Flushing usage events
[0m17:39:50.289282 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:39:50.289764 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:47:28.136179 | 39797a34-a26a-4233-98d5-9a6510db40a9 ==============================
[0m17:47:28.136200 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:47:28.136690 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:47:28.136778 [debug] [MainThread]: Tracking: tracking
[0m17:47:28.146109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac2a4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac2a700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac2a670>]}
[0m17:47:28.176415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:47:28.176745 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m17:47:28.181763 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'my_third_dbt_model' in the 'models' section of file 'models/example/schema.yml'
[0m17:47:28.193742 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_project.unique_my_third_dbt_model_id.e74b8a0386' (models/example/schema.yml) depends on a node named 'my_third_dbt_model' which was not found
[0m17:47:28.193915 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_project.not_null_my_third_dbt_model_id.08493b05aa' (models/example/schema.yml) depends on a node named 'my_third_dbt_model' which was not found
[0m17:47:28.204731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39797a34-a26a-4233-98d5-9a6510db40a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af65f40>]}
[0m17:47:28.209513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39797a34-a26a-4233-98d5-9a6510db40a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae8aeb0>]}
[0m17:47:28.209683 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:47:28.209822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39797a34-a26a-4233-98d5-9a6510db40a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae8af10>]}
[0m17:47:28.210783 [info ] [MainThread]: 
[0m17:47:28.211119 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:47:28.211554 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:47:28.211632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:47:36.301394 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:47:36.301886 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was left open.
[0m17:47:36.302074 [debug] [MainThread]: Flushing usage events
[0m17:47:36.313417 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m17:47:36.313742 [info ] [MainThread]: ctrl-c


============================== 2023-01-07 17:47:41.139517 | 5593a774-849a-49f2-9776-ad25b0619ace ==============================
[0m17:47:41.139563 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:47:41.139995 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:47:41.140091 [debug] [MainThread]: Tracking: tracking
[0m17:47:41.150053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088284f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108828700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108828670>]}
[0m17:47:41.183121 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:47:41.183278 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:47:41.186670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5593a774-849a-49f2-9776-ad25b0619ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10978bf10>]}
[0m17:47:41.190987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5593a774-849a-49f2-9776-ad25b0619ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109754d60>]}
[0m17:47:41.191139 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:47:41.191272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5593a774-849a-49f2-9776-ad25b0619ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969b070>]}
[0m17:47:41.192078 [info ] [MainThread]: 
[0m17:47:41.192411 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:47:41.192854 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:47:41.192937 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:49:07.652918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5593a774-849a-49f2-9776-ad25b0619ace', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10883ea90>]}
[0m17:49:07.654102 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:49:07.654475 [info ] [MainThread]: 
[0m17:49:07.659106 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:49:07.659705 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:49:07.659872 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:49:07.660024 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:49:07.664093 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:49:07.664857 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.664999 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:49:07.665156 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.665778 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:49:07.665952 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:07.666376 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:49:07.666604 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:07.666841 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:07.679216 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:49:07.679721 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.679837 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:07.679940 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.680369 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:07.680497 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:07.680889 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:49:07.681010 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:07.681104 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:07.686214 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:49:07.686585 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.686682 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:07.686769 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.687129 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:07.687240 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:49:07.687571 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:49:07.687652 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:49:07.687727 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:49:07.689621 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:49:07.689859 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.689945 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:49:07.690026 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.690455 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:49:07.690559 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:07.690917 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:49:07.691083 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:07.691166 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:07.696397 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:49:07.696654 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.696737 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:07.696847 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.697104 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:07.697181 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:07.697412 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:49:07.697473 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:07.697529 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:07.700524 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:49:07.700778 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.700847 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:07.700910 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.701170 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:07.701251 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:07.701477 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:49:07.701537 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:07.701591 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:07.703789 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:49:07.703989 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.704052 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:07.704114 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.704382 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:07.704464 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:07.704707 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:49:07.704765 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:07.704818 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:07.706918 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:49:07.707179 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.707258 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:07.707328 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:07.707619 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:07.708056 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:49:07.708145 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:49:07.712302 [info ] [MainThread]: Done.
[0m17:49:07.713182 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:49:07.713262 [info ] [MainThread]: Building catalog
[0m17:49:07.713581 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:49:11.372952 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m17:49:11.374457 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:49:11.393432 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:49:11.394867 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:49:18.681601 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:c56b09f1-9d81-4755-baad-1d7824c7b2d8:EU&page=queryresults
[0m17:49:18.693078 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:49:18.693397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e4d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e4ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e4e80>]}
[0m17:49:18.693591 [debug] [MainThread]: Flushing usage events
[0m17:49:21.175102 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:49:21.175487 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-07 17:49:52.295439 | fda5cb6c-cca0-406c-9019-0a819b95e26a ==============================
[0m17:49:52.295468 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:49:52.296074 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:49:52.296183 [debug] [MainThread]: Tracking: tracking
[0m17:49:52.310184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103aa160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103aa370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103aa2e0>]}
[0m17:49:52.343097 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:49:52.343254 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:49:52.346952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fda5cb6c-cca0-406c-9019-0a819b95e26a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106860d0>]}
[0m17:49:52.351770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fda5cb6c-cca0-406c-9019-0a819b95e26a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110487c70>]}
[0m17:49:52.351965 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:49:52.352103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fda5cb6c-cca0-406c-9019-0a819b95e26a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110487ca0>]}
[0m17:49:52.353052 [info ] [MainThread]: 
[0m17:49:52.353397 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:49:52.353828 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:49:52.353967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:49:56.155244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fda5cb6c-cca0-406c-9019-0a819b95e26a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d9400>]}
[0m17:49:56.156280 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:49:56.156584 [info ] [MainThread]: 
[0m17:49:56.161060 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:49:56.161866 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:49:56.162044 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:49:56.162205 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:49:56.166162 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:49:56.167010 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.167183 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:49:56.167329 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.167895 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:49:56.168054 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:56.168766 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:49:56.169166 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:56.169325 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:56.181345 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:49:56.181878 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.181992 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:56.182081 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.182487 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:49:56.182610 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:56.182948 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:49:56.183033 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:56.183110 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:56.188245 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:49:56.188599 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.188699 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:56.188784 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.189158 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:49:56.189268 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:49:56.189702 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:49:56.189856 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:49:56.189947 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:49:56.191888 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:49:56.192208 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.192296 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:49:56.192374 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.192717 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:49:56.192817 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:56.193143 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:49:56.193237 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:56.193377 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:56.196201 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:49:56.196500 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.196586 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:56.196660 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.197001 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:49:56.197100 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:56.197387 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:49:56.197460 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:56.197530 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:56.200144 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:49:56.200360 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.200435 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:56.200502 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.200796 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:49:56.200883 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:56.201136 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:49:56.201203 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:56.201267 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:56.207072 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:49:56.207403 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.207481 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:56.207549 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.207843 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:49:56.207935 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:56.208191 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:49:56.208257 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:56.208330 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:56.210663 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:49:56.210901 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.210974 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:56.211041 [debug] [Thread-1  ]: finished collecting timing info
[0m17:49:56.211318 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:49:56.211755 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:49:56.211830 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:49:56.216093 [info ] [MainThread]: Done.
[0m17:49:56.217053 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:49:56.217140 [info ] [MainThread]: Building catalog
[0m17:49:56.217436 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:50:03.834869 [debug] [MainThread]: Flushing usage events
[0m17:50:04.562723 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:50:04.563334 [info ] [MainThread]: ctrl-c


============================== 2023-01-07 17:50:07.866140 | d18adbf7-2a5b-4d2c-b179-04b2ca36cc9e ==============================
[0m17:50:07.866164 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:50:07.866579 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:50:07.866674 [debug] [MainThread]: Tracking: tracking
[0m17:50:07.874199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ac27160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ac27370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ac272e0>]}
[0m17:50:07.906284 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:50:07.906421 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:50:07.909915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ae030d0>]}
[0m17:50:07.914324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ad28c40>]}
[0m17:50:07.914478 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:50:07.914613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ad28c70>]}
[0m17:50:07.915395 [info ] [MainThread]: 
[0m17:50:07.915724 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:50:07.916207 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m17:50:07.916301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:50:23.162178 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:50:23.162952 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:50:26.292104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ac3edf0>]}
[0m17:50:26.293245 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:50:26.293633 [info ] [MainThread]: 
[0m17:50:26.298443 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:50:26.298763 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m17:50:26.299434 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:50:26.299602 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:50:26.299746 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:50:26.304111 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:50:26.305017 [debug] [Thread-1  ]: finished collecting timing info
[0m17:50:26.305185 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:50:26.337256 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m17:50:26.337699 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:50:26.338648 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:50:31.072350 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:21379327-6a9e-4183-84e9-cbaa016fb1a8:EU&page=queryresults
[0m17:50:31.083941 [debug] [Thread-1  ]: finished collecting timing info
[0m17:50:31.084332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aeef970>]}
[0m17:50:31.084553 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.79s]
[0m17:50:31.084791 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:50:31.085084 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:50:31.085277 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m17:50:31.085673 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:50:31.085762 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:50:31.085845 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:50:31.087766 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:50:31.088149 [debug] [Thread-1  ]: finished collecting timing info
[0m17:50:31.088239 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:50:31.111155 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m17:50:31.111733 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:50:31.112803 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m17:50:34.148520 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a4b853ea-0f95-4402-9694-1750fc709d15:EU&page=queryresults
[0m17:50:34.150325 [debug] [Thread-1  ]: finished collecting timing info
[0m17:50:34.151036 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd18adbf7-2a5b-4d2c-b179-04b2ca36cc9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bfc9b80>]}
[0m17:50:34.151507 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.07s]
[0m17:50:34.151953 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:50:34.153751 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:50:34.154467 [info ] [MainThread]: 
[0m17:50:34.154710 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 26.24 seconds (26.24s).
[0m17:50:34.154894 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:50:34.154990 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m17:50:34.173083 [info ] [MainThread]: 
[0m17:50:34.173337 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:50:34.173522 [info ] [MainThread]: 
[0m17:50:34.173688 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:50:34.173963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aede4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aeded60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aedeeb0>]}
[0m17:50:34.174145 [debug] [MainThread]: Flushing usage events


============================== 2023-01-07 17:51:15.556569 | e3f8e869-d607-4aa1-956e-72c1a40c9c8f ==============================
[0m17:51:15.556587 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:51:15.556998 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:51:15.557081 [debug] [MainThread]: Tracking: tracking
[0m17:51:15.566247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb6430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb6640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb65b0>]}
[0m17:51:15.598972 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:51:15.599325 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m17:51:15.613231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3f8e869-d607-4aa1-956e-72c1a40c9c8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050840d0>]}
[0m17:51:15.617497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3f8e869-d607-4aa1-956e-72c1a40c9c8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105034b80>]}
[0m17:51:15.617628 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:51:15.617755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3f8e869-d607-4aa1-956e-72c1a40c9c8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105034c70>]}
[0m17:51:15.618611 [info ] [MainThread]: 
[0m17:51:15.618930 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:51:15.619360 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:51:15.619431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:18.012309 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:51:18.012691 [debug] [MainThread]: Connection 'list_y42-playground-a0b345c7_dbt_playground' was properly closed.
[0m17:51:18.012805 [debug] [MainThread]: Flushing usage events
[0m17:51:19.917626 [info ] [MainThread]: ctrl-c


============================== 2023-01-07 17:51:25.078424 | 4e69dc1f-7a7a-4635-a2cf-13feb5de488e ==============================
[0m17:51:25.078442 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:51:25.078978 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m17:51:25.079156 [debug] [MainThread]: Tracking: tracking
[0m17:51:25.086910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142a1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142a370>]}
[0m17:51:25.117201 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:51:25.117347 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:51:25.120778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e69dc1f-7a7a-4635-a2cf-13feb5de488e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c00d0>]}
[0m17:51:25.124927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e69dc1f-7a7a-4635-a2cf-13feb5de488e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f2940>]}
[0m17:51:25.125073 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:51:25.125199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e69dc1f-7a7a-4635-a2cf-13feb5de488e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f2970>]}
[0m17:51:25.126043 [info ] [MainThread]: 
[0m17:51:25.126358 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:51:25.126817 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:51:25.126949 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:27.541265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e69dc1f-7a7a-4635-a2cf-13feb5de488e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111440460>]}
[0m17:51:27.542396 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:51:27.542784 [info ] [MainThread]: 
[0m17:51:27.547628 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:51:27.548337 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:51:27.548513 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:51:27.548686 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:51:27.552805 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:51:27.553577 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.553732 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:51:27.553877 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.554511 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:51:27.554684 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:51:27.555351 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:51:27.555599 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:51:27.555726 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:51:27.568748 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m17:51:27.569209 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.569328 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:51:27.569430 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.569891 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m17:51:27.570021 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:51:27.570352 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:51:27.570453 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:51:27.570543 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:51:27.575816 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m17:51:27.576422 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.576562 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:51:27.576663 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.577102 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m17:51:27.577225 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:51:27.577593 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:51:27.577683 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:51:27.577766 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:51:27.579869 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:51:27.580188 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.580262 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:51:27.580329 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.580630 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:51:27.580721 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:51:27.580953 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:51:27.581096 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:51:27.581180 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:51:27.583673 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:51:27.584245 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.584379 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:51:27.584453 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.584793 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:51:27.584883 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:51:27.585219 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:51:27.585338 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:51:27.585409 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:51:27.587789 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m17:51:27.588115 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.588198 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:51:27.588265 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.588557 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m17:51:27.588645 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:51:27.588906 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:51:27.588973 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:51:27.589031 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:51:27.594554 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m17:51:27.594909 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.594989 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:51:27.595057 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.595353 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m17:51:27.595437 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:51:27.595679 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:51:27.595742 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:51:27.595799 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:51:27.597920 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m17:51:27.598138 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.598205 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:51:27.598265 [debug] [Thread-1  ]: finished collecting timing info
[0m17:51:27.598503 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m17:51:27.598857 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:51:27.598936 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m17:51:27.602657 [info ] [MainThread]: Done.
[0m17:51:27.603528 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m17:51:27.603616 [info ] [MainThread]: Building catalog
[0m17:51:27.603919 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:51:30.183825 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m17:51:30.184764 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m17:51:30.203110 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:51:30.204368 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m17:51:35.811205 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:f589cd40-2f03-4a59-b74b-2cb825a98932:EU&page=queryresults
[0m17:51:35.833502 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m17:51:35.834012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142a1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f2640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114f2970>]}
[0m17:51:35.834303 [debug] [MainThread]: Flushing usage events
[0m17:51:37.140078 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m17:51:37.140455 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-09 15:35:40.072582 | 17e8ccbd-3814-4e1b-b92b-1811936b247a ==============================
[0m15:35:40.072599 [info ] [MainThread]: Running with dbt=1.3.1
[0m15:35:40.073234 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m15:35:40.073410 [debug] [MainThread]: Tracking: tracking
[0m15:35:40.087526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d5bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d72130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d720d0>]}
[0m15:35:40.130819 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:40.130968 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:40.134729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17e8ccbd-3814-4e1b-b92b-1811936b247a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f000d0>]}
[0m15:35:40.139939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17e8ccbd-3814-4e1b-b92b-1811936b247a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e35670>]}
[0m15:35:40.140164 [info ] [MainThread]: Found 2 models, 6 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m15:35:40.140326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17e8ccbd-3814-4e1b-b92b-1811936b247a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d5bf10>]}
[0m15:35:40.141257 [info ] [MainThread]: 
[0m15:35:40.141697 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:40.142290 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m15:35:40.142431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:42.195955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17e8ccbd-3814-4e1b-b92b-1811936b247a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d864f0>]}
[0m15:35:42.196979 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:35:42.197337 [info ] [MainThread]: 
[0m15:35:42.201129 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m15:35:42.201490 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m15:35:42.201573 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m15:35:42.201649 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m15:35:42.203395 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m15:35:42.203738 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.203815 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m15:35:42.203887 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.204182 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m15:35:42.204324 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:35:42.204691 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m15:35:42.204842 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:35:42.204907 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:35:42.212546 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m15:35:42.213437 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.213575 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:35:42.213652 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.214018 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:35:42.214111 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:35:42.214427 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m15:35:42.214513 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:35:42.214582 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:35:42.218688 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m15:35:42.219099 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.219181 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:35:42.219250 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.219602 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:35:42.219806 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m15:35:42.220144 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m15:35:42.220227 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m15:35:42.220295 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m15:35:42.221916 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m15:35:42.222250 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.222316 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m15:35:42.222375 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.222651 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m15:35:42.222730 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:35:42.223087 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:35:42.223314 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:35:42.223386 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:35:42.225905 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:35:42.226315 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.226394 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:35:42.226461 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.226782 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:35:42.226870 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:35:42.227265 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m15:35:42.227340 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:35:42.227399 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:35:42.229663 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m15:35:42.229938 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.230004 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:35:42.230064 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.230313 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:35:42.230395 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m15:35:42.230721 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m15:35:42.230847 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m15:35:42.230913 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m15:35:42.237791 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m15:35:42.238227 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.238309 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m15:35:42.238378 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.238699 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m15:35:42.238790 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m15:35:42.239155 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m15:35:42.239286 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m15:35:42.239357 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m15:35:42.242510 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m15:35:42.243003 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.243089 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m15:35:42.243159 [debug] [Thread-1  ]: finished collecting timing info
[0m15:35:42.243492 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m15:35:42.244046 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:42.244167 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m15:35:42.249154 [info ] [MainThread]: Done.
[0m15:35:42.251493 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m15:35:42.251624 [info ] [MainThread]: Building catalog
[0m15:35:42.251969 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:35:44.234474 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m15:35:44.235026 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m15:35:44.244642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:44.245483 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m15:35:49.151681 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:342e2803-6628-4937-8002-28f8bb06cfaa:EU&page=queryresults
[0m15:35:49.155470 [debug] [MainThread]: Flushing usage events
[0m15:35:50.063913 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m15:35:50.064189 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.
[0m15:35:50.064295 [info ] [MainThread]: ctrl-c


============================== 2023-01-09 15:36:02.057280 | 6bb0bfc0-34f1-4efe-98a7-680c39598e47 ==============================
[0m15:36:02.057309 [info ] [MainThread]: Running with dbt=1.3.1
[0m15:36:02.057797 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m15:36:02.057898 [debug] [MainThread]: Tracking: tracking
[0m15:36:02.066678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1bf40>]}
[0m15:36:02.100052 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:36:02.100455 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m15:36:02.110095 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m15:36:02.118239 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m15:36:02.142370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6bb0bfc0-34f1-4efe-98a7-680c39598e47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108da90d0>]}
[0m15:36:02.147419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6bb0bfc0-34f1-4efe-98a7-680c39598e47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d30910>]}
[0m15:36:02.147576 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m15:36:02.147731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bb0bfc0-34f1-4efe-98a7-680c39598e47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d44970>]}
[0m15:36:02.148733 [info ] [MainThread]: 
[0m15:36:02.149150 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:36:02.149684 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m15:36:02.149864 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:04.053900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bb0bfc0-34f1-4efe-98a7-680c39598e47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d20790>]}
[0m15:36:04.054348 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:36:04.054505 [info ] [MainThread]: 
[0m15:36:04.056505 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m15:36:04.056851 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m15:36:04.056944 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m15:36:04.057022 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m15:36:04.058890 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m15:36:04.059342 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.059431 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m15:36:04.059508 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.059844 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m15:36:04.059932 [debug] [Thread-1  ]: Began running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:36:04.060322 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m15:36:04.060523 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:36:04.060610 [debug] [Thread-1  ]: Compiling test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:36:04.068531 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32"
[0m15:36:04.069000 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.069146 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:36:04.069229 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.069583 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_not_null_Intercom special_admins_id.c8c18c0f32
[0m15:36:04.069700 [debug] [Thread-1  ]: Began running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:36:04.069987 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m15:36:04.070069 [debug] [Thread-1  ]: Began compiling node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:36:04.070133 [debug] [Thread-1  ]: Compiling test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:36:04.074541 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1"
[0m15:36:04.074925 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.075007 [debug] [Thread-1  ]: Began executing node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:36:04.075075 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.075397 [debug] [Thread-1  ]: Finished running node test.dbt_project.source_unique_Intercom special_admins_id.594e8511e1
[0m15:36:04.075491 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m15:36:04.075719 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m15:36:04.075876 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m15:36:04.075977 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m15:36:04.077719 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m15:36:04.078038 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.078111 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m15:36:04.078178 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.078449 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m15:36:04.078534 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:36:04.078910 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:36:04.078999 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:36:04.079063 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:36:04.083778 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m15:36:04.084104 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.084180 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:36:04.084245 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.084544 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m15:36:04.084626 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:36:04.084979 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m15:36:04.085108 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:36:04.085176 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:36:04.088619 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m15:36:04.088991 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.089066 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:36:04.089133 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:04.089416 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m15:36:04.089852 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:36:04.090002 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m15:36:04.094197 [info ] [MainThread]: Done.
[0m15:36:04.095228 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m15:36:04.095310 [info ] [MainThread]: Building catalog
[0m15:36:04.095664 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:36:06.098835 [debug] [MainThread]: BigQuery adapter: Skipping catalog for y42-playground-a0b345c7.Intercom special - schema does not exist
[0m15:36:06.099709 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m15:36:06.108458 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:06.109320 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m15:36:09.814732 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:ccbe3c65-25dc-4511-8177-09eba95d2486:EU&page=queryresults
[0m15:36:09.820766 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m15:36:09.820984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a1bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e99430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e99640>]}
[0m15:36:09.821110 [debug] [MainThread]: Flushing usage events
[0m15:36:10.718575 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m15:36:10.718825 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-09 15:36:28.565146 | 0f24ad3b-9f4c-47c0-b06e-db45cf5962c7 ==============================
[0m15:36:28.565182 [info ] [MainThread]: Running with dbt=1.3.1
[0m15:36:28.576072 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:36:28.576236 [debug] [MainThread]: Tracking: tracking
[0m15:36:28.587340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5682e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5684f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b568460>]}
[0m15:36:28.621069 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:36:28.621242 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:36:28.625198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6fe0d0>]}
[0m15:36:28.629726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b62b610>]}
[0m15:36:28.629957 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m15:36:28.630148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b62b640>]}
[0m15:36:28.630972 [info ] [MainThread]: 
[0m15:36:28.631334 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:36:28.631979 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m15:36:28.632165 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:30.635639 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m15:36:30.635856 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:36:31.984485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a11d550>]}
[0m15:36:31.984895 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:36:31.985030 [info ] [MainThread]: 
[0m15:36:31.986809 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m15:36:31.987017 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m15:36:31.987361 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m15:36:31.987442 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m15:36:31.987516 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m15:36:31.989386 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m15:36:31.989846 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:31.989944 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m15:36:32.013363 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m15:36:32.013791 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:36:32.014506 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m15:36:36.702155 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d9abbe36-83c5-4ad0-975a-ce6b5c830b28:EU&page=queryresults
[0m15:36:36.710914 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:36.711338 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b796f70>]}
[0m15:36:36.711524 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.72s]
[0m15:36:36.711728 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m15:36:36.712110 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m15:36:36.712363 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m15:36:36.712794 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m15:36:36.712900 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m15:36:36.712989 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m15:36:36.714734 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m15:36:36.715177 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:36.715274 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m15:36:36.728006 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m15:36:36.741070 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m15:36:36.742257 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m15:36:40.774198 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d9eb5410-f85d-4479-9867-b37aeec22fb1:EU&page=queryresults
[0m15:36:40.775133 [debug] [Thread-1  ]: finished collecting timing info
[0m15:36:40.775475 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f24ad3b-9f4c-47c0-b06e-db45cf5962c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba45550>]}
[0m15:36:40.775671 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 4.06s]
[0m15:36:40.775873 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m15:36:40.776741 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:36:40.777077 [info ] [MainThread]: 
[0m15:36:40.777199 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 12.15 seconds (12.15s).
[0m15:36:40.777304 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:36:40.777357 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m15:36:40.789161 [info ] [MainThread]: 
[0m15:36:40.789473 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:36:40.789728 [info ] [MainThread]: 
[0m15:36:40.789844 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:36:40.790015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b62b3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6fe4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba65ee0>]}
[0m15:36:40.790157 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 12:41:34.892900 | bdac8c23-bcfa-4c4c-854b-54d16904cf72 ==============================
[0m12:41:34.892921 [info ] [MainThread]: Running with dbt=1.3.1
[0m12:41:34.893537 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:41:34.893624 [debug] [MainThread]: Tracking: tracking
[0m12:41:34.904090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104aa1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104aa400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104aa370>]}
[0m12:41:34.941905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:34.942285 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.Intercom special.admins
[0m12:41:34.942356 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m12:41:34.951339 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m12:41:34.980870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106f60d0>]}
[0m12:41:34.985897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110648520>]}
[0m12:41:34.986046 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m12:41:34.986178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11062ca00>]}
[0m12:41:34.986885 [info ] [MainThread]: 
[0m12:41:34.987189 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m12:41:34.987708 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m12:41:34.987833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:37.284141 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m12:41:37.284528 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:39.075296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058dc580>]}
[0m12:41:39.076300 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:41:39.076548 [info ] [MainThread]: 
[0m12:41:39.082768 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m12:41:39.082981 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m12:41:39.083371 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m12:41:39.083513 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m12:41:39.083611 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m12:41:39.086483 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m12:41:39.087448 [debug] [Thread-1  ]: finished collecting timing info
[0m12:41:39.087587 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m12:41:39.118406 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m12:41:39.118947 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:41:39.119821 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m12:41:43.866453 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:7060b5e2-e8a6-4a8e-9e30-8d73f185f77f:EU&page=queryresults
[0m12:41:43.881316 [debug] [Thread-1  ]: finished collecting timing info
[0m12:41:43.881865 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110777e50>]}
[0m12:41:43.882165 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.80s]
[0m12:41:43.882493 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m12:41:43.883001 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m12:41:43.883218 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m12:41:43.883742 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m12:41:43.883860 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m12:41:43.883967 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m12:41:43.886524 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m12:41:43.887160 [debug] [Thread-1  ]: finished collecting timing info
[0m12:41:43.887285 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m12:41:43.913853 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m12:41:43.914323 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:41:43.915232 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m12:41:46.672477 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:8bc56b37-8726-4a46-a451-a664b7180597:EU&page=queryresults
[0m12:41:46.674245 [debug] [Thread-1  ]: finished collecting timing info
[0m12:41:46.674891 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdac8c23-bcfa-4c4c-854b-54d16904cf72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12011db50>]}
[0m12:41:46.675306 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.79s]
[0m12:41:46.675709 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m12:41:46.677003 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m12:41:46.677509 [info ] [MainThread]: 
[0m12:41:46.677715 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.69 seconds (11.69s).
[0m12:41:46.677893 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:46.677982 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m12:41:46.687106 [info ] [MainThread]: 
[0m12:41:46.687361 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:41:46.687568 [info ] [MainThread]: 
[0m12:41:46.687734 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:41:46.687972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11061b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104d51c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11062ecd0>]}
[0m12:41:46.688158 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 12:59:20.067047 | 85b80df8-2e86-4276-8bcc-2bb28ea2a7d4 ==============================
[0m12:59:20.067070 [info ] [MainThread]: Running with dbt=1.3.1
[0m12:59:20.067534 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m12:59:20.067617 [debug] [MainThread]: Tracking: tracking
[0m12:59:20.075564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a75e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a7550>]}
[0m12:59:20.098175 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:59:20.098398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '85b80df8-2e86-4276-8bcc-2bb28ea2a7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096c8ca0>]}
[0m12:59:20.109004 [debug] [MainThread]: Parsing macros/etc.sql
[0m12:59:20.110218 [debug] [MainThread]: Parsing macros/catalog.sql
[0m12:59:20.113948 [debug] [MainThread]: Parsing macros/adapters.sql
[0m12:59:20.125614 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m12:59:20.126933 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m12:59:20.128326 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m12:59:20.132355 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m12:59:20.133787 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m12:59:20.143574 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m12:59:20.144492 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m12:59:20.144691 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m12:59:20.145003 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m12:59:20.145509 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m12:59:20.145676 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m12:59:20.145950 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m12:59:20.146251 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m12:59:20.146724 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m12:59:20.147318 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m12:59:20.147552 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m12:59:20.147778 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m12:59:20.148021 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m12:59:20.148258 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m12:59:20.148453 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m12:59:20.149196 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m12:59:20.149441 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m12:59:20.149812 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m12:59:20.150110 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m12:59:20.151361 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m12:59:20.153204 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m12:59:20.154320 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m12:59:20.155376 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m12:59:20.163766 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m12:59:20.171662 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m12:59:20.178683 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m12:59:20.180977 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m12:59:20.181858 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m12:59:20.182759 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m12:59:20.186805 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m12:59:20.195942 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m12:59:20.196865 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m12:59:20.200512 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m12:59:20.206051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m12:59:20.215672 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m12:59:20.218462 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m12:59:20.220206 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m12:59:20.223051 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m12:59:20.223676 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m12:59:20.225384 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m12:59:20.226499 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m12:59:20.230082 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m12:59:20.240280 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m12:59:20.241059 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m12:59:20.242237 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m12:59:20.242973 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m12:59:20.243392 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m12:59:20.243764 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m12:59:20.244077 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m12:59:20.244737 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m12:59:20.247337 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m12:59:20.251638 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m12:59:20.252017 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m12:59:20.252612 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m12:59:20.253061 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m12:59:20.253500 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m12:59:20.254096 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m12:59:20.254464 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m12:59:20.254953 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m12:59:20.255536 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m12:59:20.256739 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m12:59:20.257344 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m12:59:20.257850 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m12:59:20.258341 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m12:59:20.258815 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m12:59:20.259235 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m12:59:20.259736 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m12:59:20.260155 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m12:59:20.263389 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m12:59:20.263878 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m12:59:20.264295 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m12:59:20.265134 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m12:59:20.266196 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m12:59:20.266669 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m12:59:20.267371 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m12:59:20.267854 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m12:59:20.268842 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m12:59:20.270415 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m12:59:20.271836 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m12:59:20.279553 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m12:59:20.280496 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m12:59:20.287612 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m12:59:20.289792 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m12:59:20.293474 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m12:59:20.298733 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m12:59:20.301871 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m12:59:20.451509 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.example

[0m12:59:20.454568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85b80df8-2e86-4276-8bcc-2bb28ea2a7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098180d0>]}
[0m12:59:20.458592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85b80df8-2e86-4276-8bcc-2bb28ea2a7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a7520>]}
[0m12:59:20.458797 [info ] [MainThread]: Found 0 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m12:59:20.458928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '85b80df8-2e86-4276-8bcc-2bb28ea2a7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109830cd0>]}
[0m12:59:20.459649 [info ] [MainThread]: 
[0m12:59:20.459854 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m12:59:20.463548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972d9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972d970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972deb0>]}
[0m12:59:20.463693 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:00:03.658634 | ff6955f5-3ec9-4337-89e9-1385a1cfb587 ==============================
[0m13:00:03.658659 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:00:03.659125 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:03.659216 [debug] [MainThread]: Tracking: tracking
[0m13:00:03.666905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122baf0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122baf2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122baf220>]}
[0m13:00:03.695203 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:00:03.695347 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:00:03.695447 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.example

[0m13:00:03.698695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff6955f5-3ec9-4337-89e9-1385a1cfb587', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122e1af70>]}
[0m13:00:03.702307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff6955f5-3ec9-4337-89e9-1385a1cfb587', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b19ca0>]}
[0m13:00:03.702454 [info ] [MainThread]: Found 0 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:00:03.702572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff6955f5-3ec9-4337-89e9-1385a1cfb587', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122ced070>]}
[0m13:00:03.703157 [info ] [MainThread]: 
[0m13:00:03.703284 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m13:00:03.706550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122bc1370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122bc1160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122ce8e80>]}
[0m13:00:03.706672 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:00:14.093725 | 533f52c2-f3f4-4a55-965e-c2208c378dc3 ==============================
[0m13:00:14.093750 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:00:14.094209 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:14.094296 [debug] [MainThread]: Tracking: tracking
[0m13:00:14.102483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a6d0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a6d2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a6d220>]}
[0m13:00:14.122020 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:00:14.122265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '533f52c2-f3f4-4a55-965e-c2208c378dc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a17a00>]}
[0m13:00:14.132399 [debug] [MainThread]: Parsing macros/etc.sql
[0m13:00:14.133697 [debug] [MainThread]: Parsing macros/catalog.sql
[0m13:00:14.137674 [debug] [MainThread]: Parsing macros/adapters.sql
[0m13:00:14.149460 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m13:00:14.150766 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m13:00:14.152164 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m13:00:14.155989 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m13:00:14.157438 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m13:00:14.166610 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m13:00:14.167421 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:14.167602 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:14.167899 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m13:00:14.168402 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:14.168575 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:14.168842 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:14.169139 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:14.169610 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:14.170202 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:14.170445 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:14.170666 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:14.170905 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:14.171129 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:14.171336 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:14.172122 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:14.172377 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:14.172768 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:14.173120 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:14.174504 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m13:00:14.176536 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m13:00:14.177670 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m13:00:14.178512 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m13:00:14.186745 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m13:00:14.194338 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m13:00:14.201543 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m13:00:14.203982 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m13:00:14.205026 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m13:00:14.206004 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m13:00:14.210153 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m13:00:14.218886 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m13:00:14.219641 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m13:00:14.223051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m13:00:14.228414 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m13:00:14.237905 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m13:00:14.240715 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m13:00:14.242394 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m13:00:14.245162 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m13:00:14.245754 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m13:00:14.247398 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m13:00:14.248448 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m13:00:14.251965 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m13:00:14.262298 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m13:00:14.263049 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m13:00:14.264236 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m13:00:14.264967 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m13:00:14.265385 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m13:00:14.265753 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m13:00:14.266063 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m13:00:14.266707 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m13:00:14.269285 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m13:00:14.273672 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:14.274069 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m13:00:14.274641 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m13:00:14.275082 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m13:00:14.275506 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:14.276079 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:14.276442 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:14.276914 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:14.277497 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:14.278660 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:14.279236 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:14.279735 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:14.280221 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m13:00:14.280691 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m13:00:14.281104 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:14.281603 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m13:00:14.282022 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m13:00:14.285203 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:14.285682 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:14.286099 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m13:00:14.286951 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:14.288169 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:14.288755 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:14.289507 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:14.290011 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m13:00:14.291050 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m13:00:14.292657 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m13:00:14.293996 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m13:00:14.301960 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m13:00:14.302960 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:14.309741 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m13:00:14.311899 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m13:00:14.315476 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m13:00:14.320528 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m13:00:14.323983 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m13:00:14.460053 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:00:14.466305 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:00:14.467633 [debug] [MainThread]: 1603: static parser failed on example/source_transformation.sql
[0m13:00:14.469977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b97fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcd850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcd880>]}
[0m13:00:14.470113 [debug] [MainThread]: Flushing usage events
[0m13:00:16.484991 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  expected token ':', got '}'
    line 3
      select * from {{{{ source('something', 'some') }}}}


============================== 2023-01-10 13:00:41.870882 | 41afdb37-5147-4ec3-aa29-4d842d663afb ==============================
[0m13:00:41.870934 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:00:41.871396 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:41.871487 [debug] [MainThread]: Tracking: tracking
[0m13:00:41.878993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130524c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130526d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113052640>]}
[0m13:00:41.898219 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:00:41.898461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '41afdb37-5147-4ec3-aa29-4d842d663afb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113088ca0>]}
[0m13:00:41.908216 [debug] [MainThread]: Parsing macros/etc.sql
[0m13:00:41.909511 [debug] [MainThread]: Parsing macros/catalog.sql
[0m13:00:41.913433 [debug] [MainThread]: Parsing macros/adapters.sql
[0m13:00:41.924620 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m13:00:41.925951 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m13:00:41.927347 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m13:00:41.931475 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m13:00:41.932841 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m13:00:41.942058 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m13:00:41.943079 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:41.943322 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:41.943653 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m13:00:41.944169 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:41.944340 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:41.944616 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:41.944916 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:41.945395 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:41.945976 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:41.946212 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:41.946440 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:41.946687 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:41.946918 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:41.947117 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:41.947861 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:41.948109 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:41.948494 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:41.948767 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:41.950005 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m13:00:41.951858 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m13:00:41.952949 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m13:00:41.953746 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m13:00:41.962119 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m13:00:41.969392 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m13:00:41.976330 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m13:00:41.978685 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m13:00:41.979595 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m13:00:41.980451 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m13:00:41.984506 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m13:00:41.993553 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m13:00:41.994386 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m13:00:41.997667 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m13:00:42.003341 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m13:00:42.013192 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m13:00:42.016089 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m13:00:42.017787 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m13:00:42.020569 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m13:00:42.021283 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m13:00:42.023052 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m13:00:42.024153 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m13:00:42.027935 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m13:00:42.038558 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m13:00:42.039375 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m13:00:42.040627 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m13:00:42.041583 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m13:00:42.042123 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m13:00:42.042545 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m13:00:42.042882 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m13:00:42.043634 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m13:00:42.046339 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m13:00:42.050711 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:42.051115 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m13:00:42.051692 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m13:00:42.052146 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m13:00:42.052591 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:42.053177 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:42.053551 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:42.054047 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:42.054625 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:42.055934 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:42.056565 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:42.057083 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:42.057583 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m13:00:42.058072 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m13:00:42.058528 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:42.059042 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m13:00:42.059468 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m13:00:42.062696 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:42.063183 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:42.063611 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m13:00:42.064460 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:42.065833 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:42.066430 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:42.067167 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:42.067671 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m13:00:42.068687 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m13:00:42.070347 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m13:00:42.071815 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m13:00:42.079917 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m13:00:42.080932 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:42.087933 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m13:00:42.090465 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m13:00:42.094224 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m13:00:42.099506 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m13:00:42.102604 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m13:00:42.245218 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:00:42.252280 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:00:42.253768 [debug] [MainThread]: 1603: static parser failed on example/source_transformation.sql
[0m13:00:42.255413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f994f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132cdcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132cdd60>]}
[0m13:00:42.255584 [debug] [MainThread]: Flushing usage events
[0m13:00:43.653975 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  expected token ':', got '}'
    line 3
      select * from {{{{ source('something', 'some') }}}}


============================== 2023-01-10 13:00:58.151890 | 6eacfa00-3999-47e4-a726-806dc2d22ba4 ==============================
[0m13:00:58.151910 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:00:58.152295 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:00:58.152381 [debug] [MainThread]: Tracking: tracking
[0m13:00:58.160372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e67160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e67370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e672e0>]}
[0m13:00:58.178710 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:00:58.178906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6eacfa00-3999-47e4-a726-806dc2d22ba4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e7edf0>]}
[0m13:00:58.188705 [debug] [MainThread]: Parsing macros/etc.sql
[0m13:00:58.189877 [debug] [MainThread]: Parsing macros/catalog.sql
[0m13:00:58.193625 [debug] [MainThread]: Parsing macros/adapters.sql
[0m13:00:58.205097 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m13:00:58.206449 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m13:00:58.207866 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m13:00:58.211897 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m13:00:58.213235 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m13:00:58.222591 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m13:00:58.223528 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:58.223717 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:58.224013 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m13:00:58.224517 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:58.224694 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:58.224971 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:58.225271 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:58.225741 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:58.226322 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:58.226569 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:58.226791 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:58.227036 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:58.227262 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:58.227454 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:58.228169 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:58.228406 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:58.228776 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:58.229050 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:58.230288 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m13:00:58.232122 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m13:00:58.233196 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m13:00:58.233985 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m13:00:58.242245 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m13:00:58.249554 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m13:00:58.256263 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m13:00:58.258571 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m13:00:58.259412 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m13:00:58.260254 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m13:00:58.264238 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m13:00:58.273060 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m13:00:58.273833 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m13:00:58.277152 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m13:00:58.282420 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m13:00:58.292107 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m13:00:58.294930 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m13:00:58.296616 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m13:00:58.299690 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m13:00:58.300360 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m13:00:58.302007 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m13:00:58.303066 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m13:00:58.306761 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m13:00:58.316993 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m13:00:58.317712 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m13:00:58.318896 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m13:00:58.319635 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m13:00:58.320053 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m13:00:58.320421 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m13:00:58.320747 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m13:00:58.321466 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m13:00:58.324072 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m13:00:58.328394 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:00:58.328772 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m13:00:58.329340 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m13:00:58.329783 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m13:00:58.330210 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:00:58.330783 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:00:58.331149 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:00:58.331639 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:00:58.332203 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:00:58.333339 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:00:58.333915 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:00:58.334404 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:00:58.334884 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m13:00:58.335356 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m13:00:58.335773 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:00:58.336259 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m13:00:58.336676 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m13:00:58.339875 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:00:58.340363 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:00:58.340787 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m13:00:58.341625 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:00:58.342704 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:00:58.343175 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:00:58.343872 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:00:58.344348 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m13:00:58.345334 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m13:00:58.346870 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m13:00:58.348185 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m13:00:58.356041 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m13:00:58.357034 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:00:58.363824 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m13:00:58.366150 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m13:00:58.370003 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m13:00:58.375480 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m13:00:58.378699 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m13:00:58.514865 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:00:58.521197 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:00:58.522554 [debug] [MainThread]: 1603: static parser failed on example/source_transformation.sql
[0m13:00:58.523940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110faafa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdb910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdb940>]}
[0m13:00:58.524078 [debug] [MainThread]: Flushing usage events
[0m13:00:59.780079 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  expected token ':', got '}'
    line 1
      select * from {{{{ source('something', 'some') }}}}


============================== 2023-01-10 13:27:42.323842 | 3514a223-4fb1-40f0-aa19-729406e658c0 ==============================
[0m13:27:42.323879 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:27:42.324285 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:27:42.324391 [debug] [MainThread]: Tracking: tracking
[0m13:27:42.336369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227a7310>]}
[0m13:27:42.356475 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:27:42.356709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227beb50>]}
[0m13:27:42.367855 [debug] [MainThread]: Parsing macros/etc.sql
[0m13:27:42.369169 [debug] [MainThread]: Parsing macros/catalog.sql
[0m13:27:42.373384 [debug] [MainThread]: Parsing macros/adapters.sql
[0m13:27:42.385312 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m13:27:42.386601 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m13:27:42.387987 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m13:27:42.392158 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m13:27:42.393835 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m13:27:42.403576 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m13:27:42.404517 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:27:42.404703 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:27:42.405009 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m13:27:42.405512 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:27:42.405680 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:27:42.405950 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:27:42.406245 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:27:42.406716 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:27:42.407303 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:27:42.407537 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:27:42.407762 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:27:42.408007 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:27:42.408245 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:27:42.408450 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:27:42.409196 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:27:42.409442 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:27:42.409814 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:27:42.410088 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:27:42.411362 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m13:27:42.413472 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m13:27:42.414727 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m13:27:42.415594 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m13:27:42.424073 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m13:27:42.431933 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m13:27:42.439099 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m13:27:42.441666 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m13:27:42.442573 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m13:27:42.443590 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m13:27:42.447944 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m13:27:42.457148 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m13:27:42.458007 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m13:27:42.461424 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m13:27:42.466925 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m13:27:42.476599 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m13:27:42.479579 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m13:27:42.481451 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m13:27:42.484479 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m13:27:42.485175 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m13:27:42.486892 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m13:27:42.488012 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m13:27:42.491835 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m13:27:42.502369 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m13:27:42.503105 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m13:27:42.504310 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m13:27:42.505059 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m13:27:42.505501 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m13:27:42.505899 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m13:27:42.506217 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m13:27:42.506934 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m13:27:42.509694 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m13:27:42.514326 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m13:27:42.514798 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m13:27:42.515376 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m13:27:42.515819 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m13:27:42.516248 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m13:27:42.516834 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m13:27:42.517198 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m13:27:42.517672 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m13:27:42.518253 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m13:27:42.519395 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m13:27:42.519968 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m13:27:42.520460 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m13:27:42.520945 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m13:27:42.521412 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m13:27:42.521827 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m13:27:42.522516 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m13:27:42.523066 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m13:27:42.526596 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m13:27:42.527148 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m13:27:42.527613 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m13:27:42.528501 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m13:27:42.529775 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m13:27:42.530314 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m13:27:42.531030 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m13:27:42.531524 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m13:27:42.532676 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m13:27:42.534479 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m13:27:42.535928 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m13:27:42.543815 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m13:27:42.544832 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m13:27:42.551975 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m13:27:42.554247 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m13:27:42.558253 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m13:27:42.563683 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m13:27:42.566873 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m13:27:42.705874 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:27:42.712715 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:27:42.739333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1229300a0>]}
[0m13:27:42.777461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1224d2040>]}
[0m13:27:42.777693 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:27:42.777839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12294bfd0>]}
[0m13:27:42.778460 [info ] [MainThread]: 
[0m13:27:42.778837 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:27:42.779333 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:27:42.779439 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:27:44.110168 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:27:44.110429 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:27:46.049966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121de4400>]}
[0m13:27:46.050612 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:27:46.050832 [info ] [MainThread]: 
[0m13:27:46.055419 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:27:46.055667 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:27:46.056318 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:27:46.056437 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:27:46.056550 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:27:46.059197 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:27:46.059728 [debug] [Thread-1  ]: finished collecting timing info
[0m13:27:46.059845 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:27:46.090592 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:27:46.091039 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:27:46.091943 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:27:50.585721 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:b983ed64-9a53-4e4f-a25c-d6dffe476e40:EU&page=queryresults
[0m13:27:50.604992 [debug] [Thread-1  ]: finished collecting timing info
[0m13:27:50.605783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122796610>]}
[0m13:27:50.606146 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.55s]
[0m13:27:50.606491 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:27:50.607031 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:27:50.607371 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:27:50.607960 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:27:50.608081 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:27:50.608187 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:27:50.611019 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:27:50.611830 [debug] [Thread-1  ]: finished collecting timing info
[0m13:27:50.611980 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:27:50.638359 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:27:50.639062 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:27:50.640009 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:27:53.294735 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:bcc722bd-0cce-466c-8144-61ddde90351a:EU&page=queryresults
[0m13:27:53.296148 [debug] [Thread-1  ]: finished collecting timing info
[0m13:27:53.296780 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3514a223-4fb1-40f0-aa19-729406e658c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1229c8100>]}
[0m13:27:53.297147 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.69s]
[0m13:27:53.297473 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:27:53.298869 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:27:53.299556 [info ] [MainThread]: 
[0m13:27:53.299821 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.52 seconds (10.52s).
[0m13:27:53.300050 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:27:53.300166 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:27:53.312905 [info ] [MainThread]: 
[0m13:27:53.313177 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:27:53.313387 [info ] [MainThread]: 
[0m13:27:53.313545 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:27:53.313785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121f44b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122791730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227915e0>]}
[0m13:27:53.313974 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:35:26.457858 | a62e7d94-0e7a-46c8-9ba1-828e356e80a5 ==============================
[0m13:35:26.457906 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:35:26.458354 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:35:26.458441 [debug] [MainThread]: Tracking: tracking
[0m13:35:26.468076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119095c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119095e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119095dc0>]}
[0m13:35:26.498621 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:35:26.498914 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/schema.yml
[0m13:35:26.528423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193f60d0>]}
[0m13:35:26.532665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119330dc0>]}
[0m13:35:26.532821 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:35:26.532954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119330f40>]}
[0m13:35:26.533702 [info ] [MainThread]: 
[0m13:35:26.534039 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:35:26.534572 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:35:26.534718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:35:28.012024 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:35:28.012324 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:35:30.162813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d5c4c0>]}
[0m13:35:30.164379 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:35:30.164720 [info ] [MainThread]: 
[0m13:35:30.171217 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:35:30.171632 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:35:30.172570 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:35:30.172750 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:35:30.172917 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:35:30.178722 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:35:30.179242 [debug] [Thread-1  ]: finished collecting timing info
[0m13:35:30.179386 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:35:30.193937 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:35:31.574694 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:35:31.575323 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:35:33.951524 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:8dcae01b-9147-4801-a159-bfe6b40540b0:EU&page=queryresults
[0m13:35:33.964908 [debug] [Thread-1  ]: finished collecting timing info
[0m13:35:33.965571 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194b77c0>]}
[0m13:35:33.965910 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.79s]
[0m13:35:33.966260 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:35:33.966625 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:35:33.966925 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:35:33.967484 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:35:33.967617 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:35:33.967746 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:35:33.970075 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:35:33.970524 [debug] [Thread-1  ]: finished collecting timing info
[0m13:35:33.970669 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:35:33.986502 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:35:33.986929 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:35:33.987817 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:35:36.719653 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:790a0d76-da25-4a4e-a284-fc16547ce51a:EU&page=queryresults
[0m13:35:36.722251 [debug] [Thread-1  ]: finished collecting timing info
[0m13:35:36.723044 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a62e7d94-0e7a-46c8-9ba1-828e356e80a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1199420d0>]}
[0m13:35:36.723325 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.76s]
[0m13:35:36.723514 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:35:36.724308 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:35:36.724628 [info ] [MainThread]: 
[0m13:35:36.724755 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.19 seconds (10.19s).
[0m13:35:36.724858 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:35:36.724919 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:35:36.739275 [info ] [MainThread]: 
[0m13:35:36.739512 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:35:36.739717 [info ] [MainThread]: 
[0m13:35:36.739878 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:35:36.740114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119095d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194dec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1194de190>]}
[0m13:35:36.740300 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:44:03.484434 | a5135315-927c-40cb-a6f0-2f93c5c508db ==============================
[0m13:44:03.484466 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:44:03.485047 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:44:03.485166 [debug] [MainThread]: Tracking: tracking
[0m13:44:03.494062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c2a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c2a370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c2a2e0>]}
[0m13:44:03.526102 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 5 files added, 0 files changed.
[0m13:44:03.526340 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/dimension tables/my_second_dbt_model.sql
[0m13:44:03.526483 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/dimension tables/dimension.yml
[0m13:44:03.526567 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/dimension tables/my_first_dbt_model.sql
[0m13:44:03.526646 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/fact tables/some_fact_model.sql
[0m13:44:03.526744 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/fact tables/fact.yml
[0m13:44:03.526843 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/my_second_dbt_model.sql
[0m13:44:03.526899 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/my_first_dbt_model.sql
[0m13:44:03.534801 [debug] [MainThread]: 1699: static parser successfully parsed example/dimension tables/my_second_dbt_model.sql
[0m13:44:03.542141 [debug] [MainThread]: 1699: static parser successfully parsed example/dimension tables/my_first_dbt_model.sql
[0m13:44:03.543581 [debug] [MainThread]: 1699: static parser successfully parsed example/fact tables/some_fact_model.sql
[0m13:44:03.571017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e360d0>]}
[0m13:44:03.576305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0faf0>]}
[0m13:44:03.576470 [info ] [MainThread]: Found 3 models, 5 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:44:03.576606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0fa00>]}
[0m13:44:03.577482 [info ] [MainThread]: 
[0m13:44:03.577867 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:44:03.578388 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:44:03.578473 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:44:05.853368 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:44:05.853817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:44:07.625703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047dc4f0>]}
[0m13:44:07.626745 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:44:07.627018 [info ] [MainThread]: 
[0m13:44:07.632437 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:44:07.632729 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:44:07.633088 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:44:07.633175 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:44:07.633259 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:44:07.635820 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:44:07.636567 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:07.636749 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:44:07.652669 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:44:08.939770 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:44:08.940508 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:44:11.874468 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:e9dbbdd5-11bf-4cfc-a9a2-b55fe1c2d797:EU&page=queryresults
[0m13:44:11.889768 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:11.890177 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f00cd0>]}
[0m13:44:11.890390 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.26s]
[0m13:44:11.890769 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:44:11.890937 [debug] [Thread-1  ]: Began running node model.dbt_project.some_fact_model
[0m13:44:11.891275 [info ] [Thread-1  ]: 2 of 3 START sql table model dbt_playground.some_fact_model .................... [RUN]
[0m13:44:11.892071 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.some_fact_model"
[0m13:44:11.892236 [debug] [Thread-1  ]: Began compiling node model.dbt_project.some_fact_model
[0m13:44:11.892355 [debug] [Thread-1  ]: Compiling model.dbt_project.some_fact_model
[0m13:44:11.901792 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.some_fact_model"
[0m13:44:11.902443 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:11.902583 [debug] [Thread-1  ]: Began executing node model.dbt_project.some_fact_model
[0m13:44:11.909338 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.some_fact_model"
[0m13:44:11.909885 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:44:11.910859 [debug] [Thread-1  ]: On model.dbt_project.some_fact_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.some_fact_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`some_fact_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:44:16.526329 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:17125e2b-d199-4b7e-ad6b-1648285600ef:EU&page=queryresults
[0m13:44:16.529280 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:16.530120 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f2ff10>]}
[0m13:44:16.530512 [info ] [Thread-1  ]: 2 of 3 OK created sql table model dbt_playground.some_fact_model ............... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.64s]
[0m13:44:16.531046 [debug] [Thread-1  ]: Finished running node model.dbt_project.some_fact_model
[0m13:44:16.531535 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:44:16.531822 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:44:16.532640 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:44:16.532827 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:44:16.532919 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:44:16.539171 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:44:16.539760 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:16.539924 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:44:16.558437 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:44:16.558982 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:44:16.560060 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:44:19.297449 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a897b725-0c72-4076-bd66-9b890c3d66bc:EU&page=queryresults
[0m13:44:19.300737 [debug] [Thread-1  ]: finished collecting timing info
[0m13:44:19.301243 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5135315-927c-40cb-a6f0-2f93c5c508db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f914c0>]}
[0m13:44:19.301498 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.77s]
[0m13:44:19.301763 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:44:19.302692 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:44:19.303104 [info ] [MainThread]: 
[0m13:44:19.303265 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 15.73 seconds (15.73s).
[0m13:44:19.303402 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:44:19.303472 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:44:19.312508 [info ] [MainThread]: 
[0m13:44:19.312714 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:44:19.312881 [info ] [MainThread]: 
[0m13:44:19.313036 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m13:44:19.313296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f2ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f67d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e367c0>]}
[0m13:44:19.313463 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:48:15.603794 | 7f9cf8ad-874c-4ce1-b1c0-0c116434377c ==============================
[0m13:48:15.603826 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:48:15.604244 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:48:15.604343 [debug] [MainThread]: Tracking: tracking
[0m13:48:15.612744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719af70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071ae1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071ae130>]}
[0m13:48:15.645885 [debug] [MainThread]: Partial parsing enabled: 5 files deleted, 4 files added, 0 files changed.
[0m13:48:15.646158 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_first_dbt_model.sql
[0m13:48:15.646325 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/schema.yml
[0m13:48:15.646426 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/source_transformation.sql
[0m13:48:15.646506 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_second_dbt_model.sql
[0m13:48:15.646630 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_second_dbt_model.sql
[0m13:48:15.646685 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_first_dbt_model.sql
[0m13:48:15.646738 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/fact tables/some_fact_model.sql
[0m13:48:15.654908 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:48:15.661762 [debug] [MainThread]: 1603: static parser failed on example/source_transformation.sql
[0m13:48:15.663917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c7e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107466d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107466d60>]}
[0m13:48:15.664093 [debug] [MainThread]: Flushing usage events
[0m13:48:17.334859 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  expected token ':', got '}'
    line 1
      select * from {{{{ source('something', 'some') }}}}


============================== 2023-01-10 13:48:30.377862 | 8cea95b3-62e0-4f34-9e18-fb5ace3b4411 ==============================
[0m13:48:30.377907 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:48:30.378359 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:48:30.378465 [debug] [MainThread]: Tracking: tracking
[0m13:48:30.389536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2af040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2af250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2af1c0>]}
[0m13:48:30.420612 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 3 files added, 0 files changed.
[0m13:48:30.420923 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/schema.yml
[0m13:48:30.421093 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_first_dbt_model.sql
[0m13:48:30.421187 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_second_dbt_model.sql
[0m13:48:30.421290 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/fact tables/some_fact_model.sql
[0m13:48:30.421354 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_second_dbt_model.sql
[0m13:48:30.421409 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_first_dbt_model.sql
[0m13:48:30.428798 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:48:30.435669 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:48:30.459101 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'some_fact_model' in the 'models' section of file 'models/example/fact tables/fact.yml'
[0m13:48:30.460005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b432e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4a5760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4a5850>]}
[0m13:48:30.460163 [debug] [MainThread]: Flushing usage events
[0m13:48:31.749830 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named my_second_dbt_model. Resources and their associated columns may only be described a single time. To fix this, remove the resource entry for my_second_dbt_model in one of these files:
   - models/example/fact tables/fact.yml
  models/example/schema.yml


============================== 2023-01-10 13:49:01.117115 | c73271f4-c9ff-4ae8-8e8b-5418367ae9b8 ==============================
[0m13:49:01.117141 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:49:01.117584 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:49:01.117663 [debug] [MainThread]: Tracking: tracking
[0m13:49:01.126225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba5da60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba5dc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba5dbe0>]}
[0m13:49:01.158110 [debug] [MainThread]: Partial parsing enabled: 5 files deleted, 3 files added, 0 files changed.
[0m13:49:01.158367 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/schema.yml
[0m13:49:01.158464 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_first_dbt_model.sql
[0m13:49:01.158549 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/my_second_dbt_model.sql
[0m13:49:01.158658 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_first_dbt_model.sql
[0m13:49:01.158715 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/dimension tables/my_second_dbt_model.sql
[0m13:49:01.158769 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/fact tables/some_fact_model.sql
[0m13:49:01.166285 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:49:01.173437 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m13:49:01.208905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd6a0d0>]}
[0m13:49:01.213643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc678b0>]}
[0m13:49:01.213813 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:49:01.213943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba7f610>]}
[0m13:49:01.214698 [info ] [MainThread]: 
[0m13:49:01.215064 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:49:01.215570 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:49:01.215763 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:03.137196 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:49:03.137403 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:49:04.474412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5d1550>]}
[0m13:49:04.476197 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:04.476625 [info ] [MainThread]: 
[0m13:49:04.481945 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:49:04.482209 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:49:04.482744 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:49:04.482863 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:49:04.482975 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:49:04.485732 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:49:04.486721 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:04.486882 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:49:04.501577 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:49:06.644409 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:49:06.644995 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:49:09.229497 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d7dc4dc7-db5a-4cb9-b7c5-d0ee18de9ab1:EU&page=queryresults
[0m13:49:09.251065 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:09.251635 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcc47f0>]}
[0m13:49:09.251931 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.77s]
[0m13:49:09.252254 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:49:09.252634 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:49:09.253000 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:49:09.253702 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:49:09.253851 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:49:09.253968 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:49:09.256777 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:49:09.257415 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:09.257578 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:49:09.274543 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:49:09.274988 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:49:09.275761 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:49:12.047154 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:342e4ef2-d563-4da2-9460-db4fd7b5029c:EU&page=queryresults
[0m13:49:12.049425 [debug] [Thread-1  ]: finished collecting timing info
[0m13:49:12.049989 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c73271f4-c9ff-4ae8-8e8b-5418367ae9b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0d0040>]}
[0m13:49:12.050304 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.80s]
[0m13:49:12.050658 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:49:12.051794 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:49:12.052336 [info ] [MainThread]: 
[0m13:49:12.052546 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.84 seconds (10.84s).
[0m13:49:12.052727 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:12.052826 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:49:12.060962 [info ] [MainThread]: 
[0m13:49:12.061216 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:12.061669 [info ] [MainThread]: 
[0m13:49:12.061863 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:49:12.062132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba7da00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc67550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcc4c10>]}
[0m13:49:12.062342 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:52:01.682628 | 1de5b375-6fc6-4ea5-ace3-15ba5947fab1 ==============================
[0m13:52:01.682668 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:52:01.683095 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m13:52:01.683182 [debug] [MainThread]: Tracking: tracking
[0m13:52:01.691099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0fb370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0fb580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0fb4f0>]}
[0m13:52:01.722023 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:52:01.722390 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m13:52:01.729813 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:52:01.756309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1de5b375-6fc6-4ea5-ace3-15ba5947fab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4650d0>]}
[0m13:52:01.760617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1de5b375-6fc6-4ea5-ace3-15ba5947fab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3e7970>]}
[0m13:52:01.760759 [info ] [MainThread]: Found 2 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:52:01.760908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1de5b375-6fc6-4ea5-ace3-15ba5947fab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3e78e0>]}
[0m13:52:01.761686 [info ] [MainThread]: 
[0m13:52:01.762018 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:52:01.762597 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:52:01.762716 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:03.821444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1de5b375-6fc6-4ea5-ace3-15ba5947fab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094715b0>]}
[0m13:52:03.822730 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:52:03.823117 [info ] [MainThread]: 
[0m13:52:03.826997 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:03.827313 [info ] [Thread-1  ]: 1 of 3 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m13:52:03.828124 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:03.828294 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:03.828456 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:03.842936 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:03.844685 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:03.844899 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:03.861947 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:03.862614 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:03.863644 [debug] [Thread-1  ]: On test.dbt_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m13:52:07.259692 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:ee2d1b58-4a0f-49b0-b17e-d7c535657179:EU&page=queryresults
[0m13:52:07.260838 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:07.261918 [info ] [Thread-1  ]: 1 of 3 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 3.43s]
[0m13:52:07.262567 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:07.262821 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:07.263009 [info ] [Thread-1  ]: 2 of 3 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m13:52:07.263840 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:07.264182 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:07.264468 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:07.271466 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:07.273010 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:07.273128 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:07.275772 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:07.276400 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:07.277743 [debug] [Thread-1  ]: On test.dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m13:52:10.783435 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d8213a32-ed86-4e74-956e-79df0aa24e13:EU&page=queryresults
[0m13:52:10.783809 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:10.784153 [info ] [Thread-1  ]: 2 of 3 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 3.52s]
[0m13:52:10.784380 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:10.784528 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:10.784676 [info ] [Thread-1  ]: 3 of 3 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m13:52:10.785063 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:10.785143 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:10.785217 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:10.792366 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:10.793649 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:10.793738 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:10.798641 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:10.799121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:10.799879 [debug] [Thread-1  ]: On test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m13:52:15.769948 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d6d82d26-72ff-4e10-bfa2-a17474f4d8b5:EU&page=queryresults
[0m13:52:15.770423 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:15.770932 [info ] [Thread-1  ]: 3 of 3 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 4.99s]
[0m13:52:15.771260 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:15.772299 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:52:15.772721 [info ] [MainThread]: 
[0m13:52:15.772916 [info ] [MainThread]: Finished running 3 tests in 0 hours 0 minutes and 14.01 seconds (14.01s).
[0m13:52:15.773106 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:52:15.773198 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m13:52:15.783930 [info ] [MainThread]: 
[0m13:52:15.784104 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:52:15.784224 [info ] [MainThread]: 
[0m13:52:15.784330 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m13:52:15.784489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b131160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1cd070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1cd040>]}
[0m13:52:15.784623 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:52:39.782551 | 1ac27e92-3b7c-4ed9-ab77-630b4bc2a3f8 ==============================
[0m13:52:39.782578 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:52:39.783056 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
[0m13:52:39.783143 [debug] [MainThread]: Tracking: tracking
[0m13:52:39.792980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062271f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106227400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106227370>]}
[0m13:52:39.823717 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:52:39.824127 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m13:52:39.832195 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m13:52:39.860232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ac27e92-3b7c-4ed9-ab77-630b4bc2a3f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064760d0>]}
[0m13:52:39.865071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ac27e92-3b7c-4ed9-ab77-630b4bc2a3f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063f8610>]}
[0m13:52:39.865241 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:52:39.865366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ac27e92-3b7c-4ed9-ab77-630b4bc2a3f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063a6df0>]}
[0m13:52:39.866102 [info ] [MainThread]: 
[0m13:52:39.866427 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:52:39.867067 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:52:39.867244 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:52:41.652998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ac27e92-3b7c-4ed9-ab77-630b4bc2a3f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103ac1520>]}
[0m13:52:41.653669 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:52:41.653887 [info ] [MainThread]: 
[0m13:52:41.656458 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:52:41.656656 [info ] [Thread-1  ]: 1 of 4 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m13:52:41.657170 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m13:52:41.657291 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:52:41.657409 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:52:41.669703 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m13:52:41.670329 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:41.670466 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:52:41.686885 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m13:52:41.687419 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:41.688397 [debug] [Thread-1  ]: On test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m13:52:44.402230 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:ef09bde7-c210-47a5-a025-b57328f60074:EU&page=queryresults
[0m13:52:44.402944 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:44.403293 [error] [Thread-1  ]: 1 of 4 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.75s]
[0m13:52:44.403557 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m13:52:44.403710 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:44.403833 [info ] [Thread-1  ]: 2 of 4 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m13:52:44.404910 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:44.405172 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:44.405358 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:44.412033 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:44.412709 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:44.412908 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:44.415779 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m13:52:44.416351 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:44.417744 [debug] [Thread-1  ]: On test.dbt_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m13:52:47.860341 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:4f8c5afd-7d5f-4f36-9997-f86a1b66beab:EU&page=queryresults
[0m13:52:47.861802 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:47.862622 [info ] [Thread-1  ]: 2 of 4 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 3.46s]
[0m13:52:47.863315 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m13:52:47.863589 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:47.863900 [info ] [Thread-1  ]: 3 of 4 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m13:52:47.864611 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:47.864753 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:47.864878 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:47.879215 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:47.879754 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:47.879885 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:47.885333 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"
[0m13:52:47.885737 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:47.886495 [debug] [Thread-1  ]: On test.dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m13:52:51.594750 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:50367e4f-9189-42af-9438-2b35504cdd8a:EU&page=queryresults
[0m13:52:51.596679 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:51.597593 [info ] [Thread-1  ]: 3 of 4 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 3.73s]
[0m13:52:51.598122 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_first_dbt_model_id.16e066b321
[0m13:52:51.598285 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:51.598399 [info ] [Thread-1  ]: 4 of 4 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m13:52:51.599055 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:51.599214 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:51.599334 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:51.605642 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:51.606163 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:51.606289 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:51.609818 [debug] [Thread-1  ]: Writing runtime sql for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m13:52:51.610160 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:52:51.611420 [debug] [Thread-1  ]: On test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m13:52:55.237381 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:f5b6ab1f-00a2-4f4d-9bcf-0a28c93d2f67:EU&page=queryresults
[0m13:52:55.238485 [debug] [Thread-1  ]: finished collecting timing info
[0m13:52:55.239542 [info ] [Thread-1  ]: 4 of 4 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 3.64s]
[0m13:52:55.240086 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m13:52:55.241881 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:52:55.242270 [info ] [MainThread]: 
[0m13:52:55.242431 [info ] [MainThread]: Finished running 4 tests in 0 hours 0 minutes and 15.38 seconds (15.38s).
[0m13:52:55.242609 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:52:55.242684 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m13:52:55.252193 [info ] [MainThread]: 
[0m13:52:55.252396 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:52:55.252542 [info ] [MainThread]: 
[0m13:52:55.252822 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m13:52:55.252984 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m13:52:55.253161 [info ] [MainThread]: 
[0m13:52:55.253339 [info ] [MainThread]:   compiled Code at target/compiled/dbt_project/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m13:52:55.253536 [info ] [MainThread]: 
[0m13:52:55.253709 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m13:52:55.253983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d75b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106393eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063bdf10>]}
[0m13:52:55.254215 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:55:06.370049 | 3c4e98af-c082-4711-bc1b-9d1267af571b ==============================
[0m13:55:06.370080 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:55:06.370490 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:55:06.370567 [debug] [MainThread]: Tracking: tracking
[0m13:55:06.378619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1223e9490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1223e96a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1223e9610>]}
[0m13:55:06.409862 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:55:06.410122 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/source_transformation.sql
[0m13:55:06.417564 [debug] [MainThread]: 1603: static parser failed on example/source_transformation.sql
[0m13:55:06.419404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1224a7d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122581ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122581b50>]}
[0m13:55:06.419553 [debug] [MainThread]: Flushing usage events
[0m13:55:08.173977 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  expected token ':', got '}'
    line 1
      select * from {{{{ source('something', 'some') }}}}


============================== 2023-01-10 13:55:15.914989 | 98de4646-d2c3-4ca6-a80f-f7fff8d5fa25 ==============================
[0m13:55:15.915014 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:55:15.915430 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:55:15.915511 [debug] [MainThread]: Tracking: tracking
[0m13:55:15.924008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076dacd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076daee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076dae50>]}
[0m13:55:15.954697 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m13:55:15.954971 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/source_transformation.sql
[0m13:55:15.962821 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m13:55:15.979806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107965f40>]}
[0m13:55:15.984304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10795ec10>]}
[0m13:55:15.984538 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m13:55:15.984682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10795edc0>]}
[0m13:55:15.985525 [info ] [MainThread]: 
[0m13:55:15.985851 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:55:15.986348 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m13:55:15.986504 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:55:18.123423 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m13:55:18.123704 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:55:19.987420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106291550>]}
[0m13:55:19.988022 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:55:19.988244 [info ] [MainThread]: 
[0m13:55:19.990763 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m13:55:19.990991 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m13:55:19.991585 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m13:55:19.991786 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m13:55:19.991959 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m13:55:19.998638 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m13:55:19.998993 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:19.999083 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m13:55:20.016625 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:55:22.430333 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m13:55:22.430880 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m13:55:24.998210 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a456e39b-d2d4-4d54-aa59-b0de8d335ee7:EU&page=queryresults
[0m13:55:25.013956 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:25.014578 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079821f0>]}
[0m13:55:25.014925 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 5.02s]
[0m13:55:25.015301 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m13:55:25.015452 [debug] [Thread-1  ]: Began running node model.dbt_project.source_transformation
[0m13:55:25.015766 [info ] [Thread-1  ]: 2 of 3 START sql view model dbt_playground.source_transformation ............... [RUN]
[0m13:55:25.016513 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.source_transformation"
[0m13:55:25.016734 [debug] [Thread-1  ]: Began compiling node model.dbt_project.source_transformation
[0m13:55:25.016860 [debug] [Thread-1  ]: Compiling model.dbt_project.source_transformation
[0m13:55:25.019628 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.source_transformation"
[0m13:55:25.020129 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:25.020251 [debug] [Thread-1  ]: Began executing node model.dbt_project.source_transformation
[0m13:55:25.038131 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.source_transformation"
[0m13:55:25.038637 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:55:25.039626 [debug] [Thread-1  ]: On model.dbt_project.source_transformation: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`something`.`some table`
where Department = 'Paper';


[0m13:55:27.193678 [debug] [Thread-1  ]: BigQuery adapter: Unhandled error while running:
/* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`something`.`some table`
where Department = 'Paper';


[0m13:55:27.194183 [debug] [Thread-1  ]: BigQuery adapter: 404 Not found: Dataset y42-playground-a0b345c7:something was not found in location EU

Location: EU
Job ID: 6b3057aa-f585-451b-b225-e44342c3b963

[0m13:55:27.194593 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:27.196523 [debug] [Thread-1  ]: Runtime Error in model source_transformation (models/example/source_transformation.sql)
  404 Not found: Dataset y42-playground-a0b345c7:something was not found in location EU
  
  Location: EU
  Job ID: 6b3057aa-f585-451b-b225-e44342c3b963
  
[0m13:55:27.196936 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e55e20>]}
[0m13:55:27.197398 [error] [Thread-1  ]: 2 of 3 ERROR creating sql view model dbt_playground.source_transformation ...... [[31mERROR[0m in 2.18s]
[0m13:55:27.197901 [debug] [Thread-1  ]: Finished running node model.dbt_project.source_transformation
[0m13:55:27.198119 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m13:55:27.198385 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m13:55:27.199194 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m13:55:27.199366 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m13:55:27.199483 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m13:55:27.202338 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m13:55:27.202887 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:27.203005 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m13:55:27.205667 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m13:55:27.206010 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m13:55:27.207182 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m13:55:29.923196 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:6f8ac1d6-de3b-486f-820e-1b3f86c9bc8d:EU&page=queryresults
[0m13:55:29.924612 [debug] [Thread-1  ]: finished collecting timing info
[0m13:55:29.925231 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98de4646-d2c3-4ca6-a80f-f7fff8d5fa25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abb040>]}
[0m13:55:29.925620 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.73s]
[0m13:55:29.926029 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m13:55:29.927728 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:55:29.928464 [info ] [MainThread]: 
[0m13:55:29.928761 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 13.94 seconds (13.94s).
[0m13:55:29.929001 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:55:29.929149 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m13:55:29.943229 [info ] [MainThread]: 
[0m13:55:29.943454 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m13:55:29.943603 [info ] [MainThread]: 
[0m13:55:29.943721 [error] [MainThread]: [33mRuntime Error in model source_transformation (models/example/source_transformation.sql)[0m
[0m13:55:29.943972 [error] [MainThread]:   404 Not found: Dataset y42-playground-a0b345c7:something was not found in location EU
[0m13:55:29.944124 [error] [MainThread]:   
[0m13:55:29.944232 [error] [MainThread]:   Location: EU
[0m13:55:29.944338 [error] [MainThread]:   Job ID: 6b3057aa-f585-451b-b225-e44342c3b963
[0m13:55:29.944444 [error] [MainThread]:   
[0m13:55:29.944579 [info ] [MainThread]: 
[0m13:55:29.944703 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m13:55:29.944910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076add60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076ad820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e98370>]}
[0m13:55:29.945109 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 13:59:05.721030 | 1b162ed1-ba9f-41d7-8030-2e708aa93489 ==============================
[0m13:59:05.721063 [info ] [MainThread]: Running with dbt=1.3.1
[0m13:59:05.721543 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:59:05.721635 [debug] [MainThread]: Tracking: tracking
[0m13:59:05.732099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b1bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b1bfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b1bf10>]}
[0m13:59:05.763183 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:59:05.763591 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.something.some table
[0m13:59:05.763685 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m13:59:05.771287 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m13:59:05.785251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ceae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ceafa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105caca00>]}
[0m13:59:05.785476 [debug] [MainThread]: Flushing usage events
[0m13:59:09.095246 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  Model 'model.dbt_project.source_transformation' (models/example/source_transformation.sql) depends on a source named 'something.some table' which was not found


============================== 2023-01-10 16:28:10.384786 | c0355639-6df8-4079-bdec-b42e8dcc3b0f ==============================
[0m16:28:10.384812 [info ] [MainThread]: Running with dbt=1.3.1
[0m16:28:10.385436 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:28:10.385519 [debug] [MainThread]: Tracking: tracking
[0m16:28:10.396201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d27460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d27670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d275e0>]}
[0m16:28:10.432730 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:28:10.433066 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.something.some table
[0m16:28:10.433151 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m16:28:10.440958 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m16:28:10.454173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e9de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eaa6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eaa5b0>]}
[0m16:28:10.454371 [debug] [MainThread]: Flushing usage events
[0m16:28:12.036722 [error] [MainThread]: Encountered an error:
Compilation Error in model source_transformation (models/example/source_transformation.sql)
  Model 'model.dbt_project.source_transformation' (models/example/source_transformation.sql) depends on a source named 'something.some table' which was not found


============================== 2023-01-10 16:28:20.641731 | d21c729b-36e4-4e13-82d4-7402e746224a ==============================
[0m16:28:20.641774 [info ] [MainThread]: Running with dbt=1.3.1
[0m16:28:20.642273 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:28:20.642363 [debug] [MainThread]: Tracking: tracking
[0m16:28:20.650703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fe130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fe340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fe2b0>]}
[0m16:28:20.681694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:28:20.681993 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.something.some table
[0m16:28:20.682068 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m16:28:20.682158 [debug] [MainThread]: Partial parsing: updated file: dbt_project://models/example/source_transformation.sql
[0m16:28:20.689326 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m16:28:20.714051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072f60d0>]}
[0m16:28:20.718945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072983a0>]}
[0m16:28:20.719115 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m16:28:20.719259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107298760>]}
[0m16:28:20.720053 [info ] [MainThread]: 
[0m16:28:20.720403 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:28:20.720919 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m16:28:20.721039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:28:22.342061 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m16:28:22.342319 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:28:24.222872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c91550>]}
[0m16:28:24.224100 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:28:24.224373 [info ] [MainThread]: 
[0m16:28:24.229981 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m16:28:24.230392 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m16:28:24.231053 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m16:28:24.231211 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m16:28:24.231356 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m16:28:24.234425 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m16:28:24.235169 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:24.235297 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m16:28:24.267819 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m16:28:24.268297 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:28:24.269045 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m16:28:27.294064 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:dec4a869-22b2-4d8a-a271-e6b6c17f8ec7:EU&page=queryresults
[0m16:28:27.309732 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:27.310469 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073d8fa0>]}
[0m16:28:27.310840 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.08s]
[0m16:28:27.311196 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m16:28:27.311337 [debug] [Thread-1  ]: Began running node model.dbt_project.source_transformation
[0m16:28:27.311519 [info ] [Thread-1  ]: 2 of 3 START sql view model dbt_playground.source_transformation ............... [RUN]
[0m16:28:27.312486 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.source_transformation"
[0m16:28:27.312760 [debug] [Thread-1  ]: Began compiling node model.dbt_project.source_transformation
[0m16:28:27.312959 [debug] [Thread-1  ]: Compiling model.dbt_project.source_transformation
[0m16:28:27.315797 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.source_transformation"
[0m16:28:27.317361 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:27.317534 [debug] [Thread-1  ]: Began executing node model.dbt_project.source_transformation
[0m16:28:27.340473 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.source_transformation"
[0m16:28:27.340859 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:28:27.341743 [debug] [Thread-1  ]: On model.dbt_project.source_transformation: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`
where Department = 'Paper';


[0m16:28:28.540791 [debug] [Thread-1  ]: BigQuery adapter: Unhandled error while running:
/* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`
where Department = 'Paper';


[0m16:28:28.541181 [debug] [Thread-1  ]: BigQuery adapter: 404 Not found: Table y42-playground-a0b345c7:dbt_playground.some table was not found in location EU

Location: EU
Job ID: 63e56d2d-c07d-4bdb-95f4-9f6d88818b16

[0m16:28:28.541471 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:28.542141 [debug] [Thread-1  ]: Runtime Error in model source_transformation (models/example/source_transformation.sql)
  404 Not found: Table y42-playground-a0b345c7:dbt_playground.some table was not found in location EU
  
  Location: EU
  Job ID: 63e56d2d-c07d-4bdb-95f4-9f6d88818b16
  
[0m16:28:28.542388 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c915e0>]}
[0m16:28:28.542788 [error] [Thread-1  ]: 2 of 3 ERROR creating sql view model dbt_playground.source_transformation ...... [[31mERROR[0m in 1.23s]
[0m16:28:28.543170 [debug] [Thread-1  ]: Finished running node model.dbt_project.source_transformation
[0m16:28:28.543332 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m16:28:28.543545 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m16:28:28.544907 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m16:28:28.545158 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m16:28:28.545329 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m16:28:28.555157 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m16:28:28.555770 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:28.555926 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m16:28:28.558786 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m16:28:28.559139 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:28:28.560318 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m16:28:31.514842 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:fc03daa2-0cf6-4e73-a38e-89510cebfe6f:EU&page=queryresults
[0m16:28:31.518307 [debug] [Thread-1  ]: finished collecting timing info
[0m16:28:31.518910 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd21c729b-36e4-4e13-82d4-7402e746224a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ce60a0>]}
[0m16:28:31.519227 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.97s]
[0m16:28:31.519636 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m16:28:31.521129 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:28:31.521644 [info ] [MainThread]: 
[0m16:28:31.521857 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 10.80 seconds (10.80s).
[0m16:28:31.522042 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:28:31.522136 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m16:28:31.528994 [info ] [MainThread]: 
[0m16:28:31.529242 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:28:31.529455 [info ] [MainThread]: 
[0m16:28:31.529657 [error] [MainThread]: [33mRuntime Error in model source_transformation (models/example/source_transformation.sql)[0m
[0m16:28:31.529852 [error] [MainThread]:   404 Not found: Table y42-playground-a0b345c7:dbt_playground.some table was not found in location EU
[0m16:28:31.530024 [error] [MainThread]:   
[0m16:28:31.530248 [error] [MainThread]:   Location: EU
[0m16:28:31.530582 [error] [MainThread]:   Job ID: 63e56d2d-c07d-4bdb-95f4-9f6d88818b16
[0m16:28:31.530836 [error] [MainThread]:   
[0m16:28:31.531011 [info ] [MainThread]: 
[0m16:28:31.531177 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m16:28:31.531404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d30a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071d3070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073c3e50>]}
[0m16:28:31.531583 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 17:15:47.383301 | 5e5fd412-a51f-48bd-8fb6-2b1438a82682 ==============================
[0m17:15:47.383325 [info ] [MainThread]: Running with dbt=1.3.1
[0m17:15:47.383846 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:15:47.383942 [debug] [MainThread]: Tracking: tracking
[0m17:15:47.394775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655aeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106573100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065730a0>]}
[0m17:15:47.431372 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:15:47.431514 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:15:47.435012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066fe0d0>]}
[0m17:15:47.439171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10662f520>]}
[0m17:15:47.439391 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m17:15:47.439555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10662f5b0>]}
[0m17:15:47.440358 [info ] [MainThread]: 
[0m17:15:47.440709 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:15:47.441263 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m17:15:47.441390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:15:49.893424 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m17:15:49.893779 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:15:51.795244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10655aeb0>]}
[0m17:15:51.798479 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:15:51.799257 [info ] [MainThread]: 
[0m17:15:51.810157 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m17:15:51.810572 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m17:15:51.811209 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m17:15:51.811344 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m17:15:51.811487 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m17:15:51.815298 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m17:15:51.815996 [debug] [Thread-1  ]: finished collecting timing info
[0m17:15:51.816109 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m17:15:51.828987 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:15:53.837745 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m17:15:53.838266 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:15:56.240496 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:13eeb10f-9e09-4287-9f3c-741598e0d335:EU&page=queryresults
[0m17:15:56.271564 [debug] [Thread-1  ]: finished collecting timing info
[0m17:15:56.272040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679be80>]}
[0m17:15:56.272282 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.46s]
[0m17:15:56.272545 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m17:15:56.272656 [debug] [Thread-1  ]: Began running node model.dbt_project.source_transformation
[0m17:15:56.272772 [info ] [Thread-1  ]: 2 of 3 START sql view model dbt_playground.source_transformation ............... [RUN]
[0m17:15:56.273105 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.source_transformation"
[0m17:15:56.273258 [debug] [Thread-1  ]: Began compiling node model.dbt_project.source_transformation
[0m17:15:56.273416 [debug] [Thread-1  ]: Compiling model.dbt_project.source_transformation
[0m17:15:56.275752 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.source_transformation"
[0m17:15:56.277286 [debug] [Thread-1  ]: finished collecting timing info
[0m17:15:56.277437 [debug] [Thread-1  ]: Began executing node model.dbt_project.source_transformation
[0m17:15:56.293412 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.source_transformation"
[0m17:15:56.293955 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:15:56.294959 [debug] [Thread-1  ]: On model.dbt_project.source_transformation: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`
where Department = 'Paper';


[0m17:15:58.239620 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:f8fb6342-4631-43a2-8227-8200261d4a28:EU&page=queryresults
[0m17:15:58.241124 [debug] [Thread-1  ]: finished collecting timing info
[0m17:15:58.241659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bad00>]}
[0m17:15:58.242057 [info ] [Thread-1  ]: 2 of 3 OK created sql view model dbt_playground.source_transformation .......... [[32mCREATE VIEW (0 processed)[0m in 1.97s]
[0m17:15:58.242463 [debug] [Thread-1  ]: Finished running node model.dbt_project.source_transformation
[0m17:15:58.242619 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m17:15:58.242772 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m17:15:58.243227 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m17:15:58.243342 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m17:15:58.243464 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m17:15:58.256833 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m17:15:58.258314 [debug] [Thread-1  ]: finished collecting timing info
[0m17:15:58.258636 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m17:15:58.263199 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m17:15:58.264015 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:15:58.265488 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m17:16:01.330596 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:51df68a0-ac8f-478d-93f0-561a7874eba1:EU&page=queryresults
[0m17:16:01.332178 [debug] [Thread-1  ]: finished collecting timing info
[0m17:16:01.332810 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5fd412-a51f-48bd-8fb6-2b1438a82682', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066fe190>]}
[0m17:16:01.333185 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.09s]
[0m17:16:01.333516 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m17:16:01.335153 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:16:01.335977 [info ] [MainThread]: 
[0m17:16:01.336268 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 13.90 seconds (13.90s).
[0m17:16:01.336522 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:16:01.336654 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m17:16:01.349904 [info ] [MainThread]: 
[0m17:16:01.350106 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:16:01.350272 [info ] [MainThread]: 
[0m17:16:01.350397 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m17:16:01.350574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10678f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066c7ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f1910>]}
[0m17:16:01.350771 [debug] [MainThread]: Flushing usage events


============================== 2023-01-10 20:07:21.920794 | bf8b8979-ef14-43c2-89f6-2818e1e02d7c ==============================
[0m20:07:21.920814 [info ] [MainThread]: Running with dbt=1.3.1
[0m20:07:21.921200 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m20:07:21.921290 [debug] [MainThread]: Tracking: tracking
[0m20:07:21.932490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc99af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc99d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc99c70>]}
[0m20:07:21.968498 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 1 files changed.
[0m20:07:21.968743 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m20:07:21.968963 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.dbt_playground.some table
[0m20:07:21.969030 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m20:07:21.969098 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/source_transformation.sql
[0m20:07:21.976777 [debug] [MainThread]: 1699: static parser successfully parsed example/some folder/my_frst_dbt_model.sql
[0m20:07:21.983369 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m20:07:22.003727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cee40d0>]}
[0m20:07:22.008099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce1aca0>]}
[0m20:07:22.008246 [info ] [MainThread]: Found 3 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m20:07:22.008384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccbf610>]}
[0m20:07:22.009047 [info ] [MainThread]: 
[0m20:07:22.009356 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m20:07:22.009824 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m20:07:22.009943 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:07:24.269316 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m20:07:24.269815 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:07:25.292916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084a0580>]}
[0m20:07:25.293979 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:07:25.294248 [info ] [MainThread]: 
[0m20:07:25.300735 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m20:07:25.301057 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m20:07:25.301637 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m20:07:25.301775 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m20:07:25.301920 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m20:07:25.305321 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m20:07:25.305853 [debug] [Thread-1  ]: finished collecting timing info
[0m20:07:25.305970 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m20:07:25.338220 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m20:07:25.338700 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:07:25.339609 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m20:07:29.589079 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:486dbca6-2907-4593-8484-2c828917fb68:EU&page=queryresults
[0m20:07:29.603589 [debug] [Thread-1  ]: finished collecting timing info
[0m20:07:29.604008 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf65c70>]}
[0m20:07:29.604237 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.30s]
[0m20:07:29.604488 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m20:07:29.604962 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m20:07:29.605320 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m20:07:29.605895 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m20:07:29.606021 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m20:07:29.606132 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m20:07:29.608766 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m20:07:29.609243 [debug] [Thread-1  ]: finished collecting timing info
[0m20:07:29.609368 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m20:07:29.636182 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m20:07:29.636670 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m20:07:29.637685 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m20:07:32.617703 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:1496b671-4689-4f50-ae95-4aa1784233e0:EU&page=queryresults
[0m20:07:32.620126 [debug] [Thread-1  ]: finished collecting timing info
[0m20:07:32.620864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf8b8979-ef14-43c2-89f6-2818e1e02d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf96cd0>]}
[0m20:07:32.621246 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.02s]
[0m20:07:32.621644 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m20:07:32.622621 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m20:07:32.623035 [info ] [MainThread]: 
[0m20:07:32.623236 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 10.61 seconds (10.61s).
[0m20:07:32.623408 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:07:32.623499 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m20:07:32.634513 [info ] [MainThread]: 
[0m20:07:32.634744 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:07:32.634944 [info ] [MainThread]: 
[0m20:07:32.635250 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:07:32.635615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cee4700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cee4610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cee4400>]}
[0m20:07:32.635827 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 08:45:28.744084 | 15ee2221-7680-4305-846e-5daf1bebd790 ==============================
[0m08:45:28.744111 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:45:28.744686 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:45:28.744764 [debug] [MainThread]: Tracking: tracking
[0m08:45:28.755582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130233d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130235e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113023550>]}
[0m08:45:28.791242 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:45:28.791500 [debug] [MainThread]: Partial parsing: updated file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m08:45:28.798995 [debug] [MainThread]: 1699: static parser successfully parsed example/some folder/my_frst_dbt_model.sql
[0m08:45:28.815175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131db0d0>]}
[0m08:45:28.819763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131205b0>]}
[0m08:45:28.819920 [info ] [MainThread]: Found 3 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:45:28.820045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11317af40>]}
[0m08:45:28.820731 [info ] [MainThread]: 
[0m08:45:28.821048 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:45:28.821584 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m08:45:28.821717 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:45:30.991261 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:45:30.991669 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:45:33.049601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11071d580>]}
[0m08:45:33.051096 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:45:33.051431 [info ] [MainThread]: 
[0m08:45:33.056322 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:45:33.056654 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m08:45:33.057237 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:45:33.057373 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:45:33.057504 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:45:33.065149 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:45:33.065817 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:33.065947 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:45:33.099753 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m08:45:33.100211 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:45:33.101247 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:45:38.229714 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:2de404bb-b25d-4d93-b75e-f6df83ae0ad3:EU&page=queryresults
[0m08:45:38.246769 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:38.247344 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113044c70>]}
[0m08:45:38.247639 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 5.19s]
[0m08:45:38.247975 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:45:38.248121 [debug] [Thread-1  ]: Began running node model.dbt_project.my_frst_dbt_model
[0m08:45:38.248282 [info ] [Thread-1  ]: 2 of 3 START sql table model dbt_playground.my_frst_dbt_model .................. [RUN]
[0m08:45:38.249078 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_frst_dbt_model"
[0m08:45:38.249324 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_frst_dbt_model
[0m08:45:38.249508 [debug] [Thread-1  ]: Compiling model.dbt_project.my_frst_dbt_model
[0m08:45:38.252262 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_frst_dbt_model"
[0m08:45:38.252831 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:38.252957 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_frst_dbt_model
[0m08:45:38.255596 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_frst_dbt_model"
[0m08:45:38.256053 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:45:38.257269 [debug] [Thread-1  ]: On model.dbt_project.my_frst_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_frst_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_frst_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:45:43.141868 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d05d403c-0052-4a32-91f4-30eb680b4c03:EU&page=queryresults
[0m08:45:43.145322 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:43.146282 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113395a00>]}
[0m08:45:43.146813 [info ] [Thread-1  ]: 2 of 3 OK created sql table model dbt_playground.my_frst_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.90s]
[0m08:45:43.147143 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_frst_dbt_model
[0m08:45:43.147260 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:45:43.147388 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m08:45:43.147853 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:45:43.147948 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:45:43.148028 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:45:43.151505 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:45:43.151922 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:43.152010 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:45:43.171419 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m08:45:43.171861 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:45:43.172812 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m08:45:45.545163 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:ce944c4c-eeac-43e6-a8d4-613ed92b6482:EU&page=queryresults
[0m08:45:45.546981 [debug] [Thread-1  ]: finished collecting timing info
[0m08:45:45.547613 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ee2221-7680-4305-846e-5daf1bebd790', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11485dfa0>]}
[0m08:45:45.548017 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.40s]
[0m08:45:45.548431 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:45:45.549956 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:45:45.550675 [info ] [MainThread]: 
[0m08:45:45.550927 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 16.73 seconds (16.73s).
[0m08:45:45.551136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:45:45.551245 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m08:45:45.569792 [info ] [MainThread]: 
[0m08:45:45.570057 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:45:45.570241 [info ] [MainThread]: 
[0m08:45:45.570394 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:45:45.570606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113386f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113041220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114878190>]}
[0m08:45:45.570779 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 08:46:06.247273 | 9980ac76-d896-46ef-b619-ce2849000429 ==============================
[0m08:46:06.247294 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:46:06.247647 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:46:06.247735 [debug] [MainThread]: Tracking: tracking
[0m08:46:06.256626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6c100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b6c280>]}
[0m08:46:06.286920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:46:06.287174 [debug] [MainThread]: Partial parsing: updated file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m08:46:06.294635 [debug] [MainThread]: 1699: static parser successfully parsed example/some folder/my_frst_dbt_model.sql
[0m08:46:06.311119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d3bf40>]}
[0m08:46:06.315017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c65df0>]}
[0m08:46:06.315169 [info ] [MainThread]: Found 3 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:46:06.315315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cbfc70>]}
[0m08:46:06.316016 [info ] [MainThread]: 
[0m08:46:06.316326 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:46:06.316883 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m08:46:06.317020 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:46:08.398190 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:46:08.398678 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:46:09.812971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b86400>]}
[0m08:46:09.813979 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:46:09.814261 [info ] [MainThread]: 
[0m08:46:09.818147 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:46:09.818496 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m08:46:09.819170 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:46:09.819300 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:46:09.819413 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:46:09.826762 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:46:09.827253 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:09.827382 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:46:09.844395 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:46:11.428410 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m08:46:11.429024 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:46:13.903163 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:26d10dd2-9b3b-4f7e-beb2-84a4baad6ab8:EU&page=queryresults
[0m08:46:13.922133 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:13.922661 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108206f40>]}
[0m08:46:13.922940 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.10s]
[0m08:46:13.923246 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:46:13.923381 [debug] [Thread-1  ]: Began running node model.dbt_project.my_frst_dbt_model
[0m08:46:13.923794 [info ] [Thread-1  ]: 2 of 3 START sql table model dbt_playground.my_frst_dbt_model .................. [RUN]
[0m08:46:13.924400 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_frst_dbt_model"
[0m08:46:13.924517 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_frst_dbt_model
[0m08:46:13.924616 [debug] [Thread-1  ]: Compiling model.dbt_project.my_frst_dbt_model
[0m08:46:13.926863 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_frst_dbt_model"
[0m08:46:13.927287 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:13.927386 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_frst_dbt_model
[0m08:46:13.928733 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:46:15.959005 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_frst_dbt_model"
[0m08:46:15.960088 [debug] [Thread-1  ]: On model.dbt_project.my_frst_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_frst_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_frst_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:46:19.413018 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:4935c44b-a4e5-4a2d-a859-36612a5538ec:EU&page=queryresults
[0m08:46:19.416941 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:19.417794 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10826fb80>]}
[0m08:46:19.418228 [info ] [Thread-1  ]: 2 of 3 OK created sql table model dbt_playground.my_frst_dbt_model ............. [[32mCREATE TABLE (3.0 rows, 0 processed)[0m in 5.49s]
[0m08:46:19.418679 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_frst_dbt_model
[0m08:46:19.418928 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:46:19.419195 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m08:46:19.419690 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:46:19.419793 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:46:19.419888 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:46:19.422718 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:46:19.423180 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:19.423301 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:46:19.442088 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m08:46:19.442654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:46:19.443725 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m08:46:22.506676 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:7b92a367-d0da-4789-a98b-03d8ebff982e:EU&page=queryresults
[0m08:46:22.508661 [debug] [Thread-1  ]: finished collecting timing info
[0m08:46:22.509155 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9980ac76-d896-46ef-b619-ce2849000429', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082a4e80>]}
[0m08:46:22.509451 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.09s]
[0m08:46:22.509772 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:46:22.511336 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:46:22.512175 [info ] [MainThread]: 
[0m08:46:22.512464 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 16.20 seconds (16.20s).
[0m08:46:22.512712 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:46:22.512839 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m08:46:22.534189 [info ] [MainThread]: 
[0m08:46:22.534433 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:46:22.534621 [info ] [MainThread]: 
[0m08:46:22.534820 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:46:22.535110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c0d430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b862b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082cd310>]}
[0m08:46:22.535299 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 08:47:30.488365 | 5f945afb-2e99-4c5b-a670-7b85c0d1ddbd ==============================
[0m08:47:30.488399 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:47:30.488780 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:47:30.488861 [debug] [MainThread]: Tracking: tracking
[0m08:47:30.496912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c5c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c5cbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c5cb50>]}
[0m08:47:30.526394 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:47:30.526526 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:47:30.529737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105df50d0>]}
[0m08:47:30.533586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d277f0>]}
[0m08:47:30.533724 [info ] [MainThread]: Found 3 models, 3 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:47:30.533852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c7f5e0>]}
[0m08:47:30.534568 [info ] [MainThread]: 
[0m08:47:30.534910 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:47:30.535474 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m08:47:30.535620 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:47:32.619001 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:47:32.619536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:47:34.541693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046dc520>]}
[0m08:47:34.542583 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:47:34.542826 [info ] [MainThread]: 
[0m08:47:34.547867 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:47:34.548180 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m08:47:34.548767 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:47:34.548903 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:47:34.549048 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:47:34.552965 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:47:34.553767 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:34.553925 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:47:34.568605 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:47:36.517875 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m08:47:36.518524 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:47:39.105308 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:2c55a774-7bfb-4ab7-8c93-5ed218b9d5ce:EU&page=queryresults
[0m08:47:39.122203 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:39.122811 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e63af0>]}
[0m08:47:39.123117 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.57s]
[0m08:47:39.123441 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:47:39.123581 [debug] [Thread-1  ]: Began running node model.dbt_project.my_frst_dbt_model
[0m08:47:39.123972 [info ] [Thread-1  ]: 2 of 3 START sql table model dbt_playground.my_frst_dbt_model .................. [RUN]
[0m08:47:39.124661 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_frst_dbt_model"
[0m08:47:39.124796 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_frst_dbt_model
[0m08:47:39.124903 [debug] [Thread-1  ]: Compiling model.dbt_project.my_frst_dbt_model
[0m08:47:39.127624 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_frst_dbt_model"
[0m08:47:39.128089 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:39.128219 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_frst_dbt_model
[0m08:47:39.129773 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:47:41.053575 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_frst_dbt_model"
[0m08:47:41.054404 [debug] [Thread-1  ]: On model.dbt_project.my_frst_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_frst_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_frst_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:47:43.796737 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:0fae4cb1-b754-4d7a-9a87-5f14cdc8e9b6:EU&page=queryresults
[0m08:47:43.800140 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:43.800999 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e636d0>]}
[0m08:47:43.801381 [info ] [Thread-1  ]: 2 of 3 OK created sql table model dbt_playground.my_frst_dbt_model ............. [[32mCREATE TABLE (3.0 rows, 0 processed)[0m in 4.68s]
[0m08:47:43.801720 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_frst_dbt_model
[0m08:47:43.801867 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:47:43.802126 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m08:47:43.802669 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:47:43.802764 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:47:43.802846 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:47:43.812883 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:47:43.813427 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:43.813578 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:47:43.837121 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m08:47:43.837634 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:47:43.838655 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m08:47:46.892709 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:bdbe9427-79e9-41f6-ba50-85d26c2733ee:EU&page=queryresults
[0m08:47:46.894705 [debug] [Thread-1  ]: finished collecting timing info
[0m08:47:46.895523 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f945afb-2e99-4c5b-a670-7b85c0d1ddbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ec2820>]}
[0m08:47:46.895978 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.09s]
[0m08:47:46.896354 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:47:46.897622 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:47:46.898103 [info ] [MainThread]: 
[0m08:47:46.898284 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 16.36 seconds (16.36s).
[0m08:47:46.898445 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:47:46.898540 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m08:47:46.908789 [info ] [MainThread]: 
[0m08:47:46.909022 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:47:46.909243 [info ] [MainThread]: 
[0m08:47:46.909408 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:47:46.909661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c86190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dc0e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e76a60>]}
[0m08:47:46.909854 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 08:48:37.613229 | ae093825-a493-45c1-b19f-c7ea2ac28502 ==============================
[0m08:48:37.613258 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:48:37.613634 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:48:37.613713 [debug] [MainThread]: Tracking: tracking
[0m08:48:37.620672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ebc190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ebc3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ebc310>]}
[0m08:48:37.650329 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m08:48:37.650678 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m08:48:37.650785 [debug] [MainThread]: Partial parsing: updated file: dbt_project://models/example/my_first_dbt_model.sql
[0m08:48:37.650898 [debug] [MainThread]: Partial parsing: updated file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m08:48:37.658440 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m08:48:37.664981 [debug] [MainThread]: 1699: static parser successfully parsed example/some folder/my_frst_dbt_model.sql
[0m08:48:37.680098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050ee0d0>]}
[0m08:48:37.683871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe1cd0>]}
[0m08:48:37.684018 [info ] [MainThread]: Found 3 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:48:37.684150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe1ca0>]}
[0m08:48:37.684995 [info ] [MainThread]: 
[0m08:48:37.685404 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:48:37.685921 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m08:48:37.686030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:48:39.828032 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:48:39.828470 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:48:41.165660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10506ae50>]}
[0m08:48:41.166698 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:48:41.167062 [info ] [MainThread]: 
[0m08:48:41.170867 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:48:41.171105 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m08:48:41.171618 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:48:41.171735 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:48:41.171846 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:48:41.175047 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:48:41.175750 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:41.175882 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:48:41.190665 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:48:43.127563 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m08:48:43.128141 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:48:45.955066 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:cd71a281-48d4-47f3-bfc0-404b27ef6a5b:EU&page=queryresults
[0m08:48:45.972650 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:45.973103 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051370a0>]}
[0m08:48:45.973362 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.80s]
[0m08:48:45.973616 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:48:45.973722 [debug] [Thread-1  ]: Began running node model.dbt_project.my_frst_dbt_model
[0m08:48:45.973841 [info ] [Thread-1  ]: 2 of 3 START sql table model dbt_playground.my_frst_dbt_model .................. [RUN]
[0m08:48:45.974464 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_frst_dbt_model"
[0m08:48:45.974580 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_frst_dbt_model
[0m08:48:45.974671 [debug] [Thread-1  ]: Compiling model.dbt_project.my_frst_dbt_model
[0m08:48:45.976644 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_frst_dbt_model"
[0m08:48:45.977001 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:45.977086 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_frst_dbt_model
[0m08:48:45.978663 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:48:47.883081 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_frst_dbt_model"
[0m08:48:47.884106 [debug] [Thread-1  ]: On model.dbt_project.my_frst_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_frst_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_frst_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id
    union all
    select 3 as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:48:50.654994 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:13ade8e0-2f56-4c47-af1a-f09dc9a9c76a:EU&page=queryresults
[0m08:48:50.661478 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:50.661845 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105209cd0>]}
[0m08:48:50.662047 [info ] [Thread-1  ]: 2 of 3 OK created sql table model dbt_playground.my_frst_dbt_model ............. [[32mCREATE TABLE (3.0 rows, 0 processed)[0m in 4.69s]
[0m08:48:50.662262 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_frst_dbt_model
[0m08:48:50.662349 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:48:50.662450 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m08:48:50.662742 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:48:50.662814 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:48:50.662935 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:48:50.667842 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:48:50.668201 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:50.668290 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:48:50.679844 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m08:48:50.680228 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:48:50.681002 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m08:48:53.598811 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:be24f25b-ae59-4af8-a587-2bbf34345ba3:EU&page=queryresults
[0m08:48:53.610130 [debug] [Thread-1  ]: finished collecting timing info
[0m08:48:53.612159 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ae093825-a493-45c1-b19f-c7ea2ac28502', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105224c40>]}
[0m08:48:53.613122 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.95s]
[0m08:48:53.614058 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:48:53.616895 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:48:53.617541 [info ] [MainThread]: 
[0m08:48:53.617788 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 15.93 seconds (15.93s).
[0m08:48:53.617973 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:48:53.618078 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m08:48:53.625148 [info ] [MainThread]: 
[0m08:48:53.625379 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:48:53.625585 [info ] [MainThread]: 
[0m08:48:53.625756 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:48:53.626006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f7d160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105041b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10513aeb0>]}
[0m08:48:53.626204 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 08:53:11.339771 | 43531990-9d48-4e59-a117-6879a8a467fd ==============================
[0m08:53:11.339794 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:53:11.340178 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m08:53:11.340288 [debug] [MainThread]: Tracking: tracking
[0m08:53:11.348397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c3160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c3370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c32e0>]}
[0m08:53:11.378269 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:53:11.378427 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:53:11.381794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43531990-9d48-4e59-a117-6879a8a467fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a77bdc0>]}
[0m08:53:11.385886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43531990-9d48-4e59-a117-6879a8a467fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a58ed60>]}
[0m08:53:11.386066 [info ] [MainThread]: Found 3 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:53:11.386200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43531990-9d48-4e59-a117-6879a8a467fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a58eee0>]}
[0m08:53:11.386965 [info ] [MainThread]: 
[0m08:53:11.387315 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:53:11.387786 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:53:11.387894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:53:12.857535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43531990-9d48-4e59-a117-6879a8a467fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4f03a0>]}
[0m08:53:12.865144 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:53:12.865456 [info ] [MainThread]: 
[0m08:53:12.869580 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:53:12.870100 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:53:12.870231 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:53:12.870351 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:53:12.873279 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:53:12.873770 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.873901 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:53:12.874022 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.874505 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:53:12.874642 [debug] [Thread-1  ]: Began running node model.dbt_project.my_frst_dbt_model
[0m08:53:12.875015 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_frst_dbt_model"
[0m08:53:12.875121 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_frst_dbt_model
[0m08:53:12.875219 [debug] [Thread-1  ]: Compiling model.dbt_project.my_frst_dbt_model
[0m08:53:12.877579 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_frst_dbt_model"
[0m08:53:12.878110 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.878293 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_frst_dbt_model
[0m08:53:12.878411 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.878936 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_frst_dbt_model
[0m08:53:12.879074 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:53:12.879457 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:53:12.879536 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:53:12.879607 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:53:12.881681 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:53:12.882028 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.882136 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:53:12.882230 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.882650 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:53:12.883052 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:53:12.883432 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m08:53:12.883531 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:53:12.883617 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:53:12.893320 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m08:53:12.894094 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.894215 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:53:12.894303 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.894693 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:53:12.894801 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:53:12.895129 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m08:53:12.895209 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:53:12.895281 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:53:12.900055 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m08:53:12.900504 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.900620 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:53:12.900708 [debug] [Thread-1  ]: finished collecting timing info
[0m08:53:12.901090 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:53:12.901699 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:53:12.901849 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m08:53:12.906591 [info ] [MainThread]: Done.
[0m08:53:12.908675 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m08:53:12.908799 [info ] [MainThread]: Building catalog
[0m08:53:12.909121 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:53:14.880122 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m08:53:14.890376 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:53:14.891278 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m08:53:19.612304 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d40153de-bfd3-454f-bc5f-87a1aa9899a4:EU&page=queryresults
[0m08:53:19.638746 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m08:53:19.639102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c3160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a98e640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a98e550>]}
[0m08:53:19.639321 [debug] [MainThread]: Flushing usage events
[0m08:53:21.462453 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m08:53:21.463748 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-11 08:53:54.109089 | 47be5d40-030d-4417-9245-ae5b0cfa4a5e ==============================
[0m08:53:54.109108 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:53:54.109478 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:53:54.109549 [debug] [MainThread]: Tracking: tracking
[0m08:53:54.117414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dea460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dea670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dea5e0>]}
[0m08:53:54.147284 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m08:53:54.147500 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/some folder/my_first_dbt_model.sql
[0m08:53:54.147566 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m08:53:54.155095 [debug] [MainThread]: 1699: static parser successfully parsed example/some folder/my_first_dbt_model.sql
[0m08:53:54.161046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f476d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f9ddf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f9deb0>]}
[0m08:53:54.161191 [debug] [MainThread]: Flushing usage events
[0m08:53:55.577448 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "my_first_dbt_model".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("my_first_dbt_model").
  
  To fix this, change the name of one of these resources:
  - model.dbt_project.my_first_dbt_model (models/example/some folder/my_first_dbt_model.sql)
  - model.dbt_project.my_first_dbt_model (models/example/my_first_dbt_model.sql)


============================== 2023-01-11 08:54:25.357949 | 62b01d35-369a-4b14-a258-040ed097bef9 ==============================
[0m08:54:25.357984 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:54:25.358396 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m08:54:25.358487 [debug] [MainThread]: Tracking: tracking
[0m08:54:25.365728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf96fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfae1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfae160>]}
[0m08:54:25.395559 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m08:54:25.395729 [debug] [MainThread]: Partial parsing: deleted file: dbt_project://models/example/some folder/my_frst_dbt_model.sql
[0m08:54:25.406432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62b01d35-369a-4b14-a258-040ed097bef9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c14a0d0>]}
[0m08:54:25.410785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62b01d35-369a-4b14-a258-040ed097bef9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0a04f0>]}
[0m08:54:25.410948 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:54:25.411086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62b01d35-369a-4b14-a258-040ed097bef9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf96fd0>]}
[0m08:54:25.411818 [info ] [MainThread]: 
[0m08:54:25.412151 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:54:25.412636 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:54:25.412767 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:27.194872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62b01d35-369a-4b14-a258-040ed097bef9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0fdee0>]}
[0m08:54:27.196755 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:54:27.197274 [info ] [MainThread]: 
[0m08:54:27.200912 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:54:27.201513 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:54:27.201669 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:54:27.201813 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:54:27.205001 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:54:27.205525 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.205667 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:54:27.205802 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.206303 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:54:27.206670 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:54:27.207056 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:54:27.207163 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:54:27.207261 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:54:27.209795 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:54:27.210276 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.210410 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:54:27.210522 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.211014 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:54:27.211383 [debug] [Thread-1  ]: Began running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:54:27.211873 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m08:54:27.211994 [debug] [Thread-1  ]: Began compiling node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:54:27.212102 [debug] [Thread-1  ]: Compiling test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:54:27.223874 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.not_null_my_second_dbt_model_id.151b76d778"
[0m08:54:27.224268 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.224376 [debug] [Thread-1  ]: Began executing node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:54:27.224472 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.224880 [debug] [Thread-1  ]: Finished running node test.dbt_project.not_null_my_second_dbt_model_id.151b76d778
[0m08:54:27.224999 [debug] [Thread-1  ]: Began running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:54:27.225364 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m08:54:27.225488 [debug] [Thread-1  ]: Began compiling node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:54:27.225590 [debug] [Thread-1  ]: Compiling test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:54:27.230514 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m08:54:27.230763 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.230855 [debug] [Thread-1  ]: Began executing node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:54:27.230936 [debug] [Thread-1  ]: finished collecting timing info
[0m08:54:27.231277 [debug] [Thread-1  ]: Finished running node test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493
[0m08:54:27.231699 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:54:27.231779 [debug] [MainThread]: Connection 'test.dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m08:54:27.239685 [info ] [MainThread]: Done.
[0m08:54:27.240566 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m08:54:27.240640 [info ] [MainThread]: Building catalog
[0m08:54:27.240867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:54:29.125231 [debug] [ThreadPool]: Acquiring new bigquery connection "y42-playground-a0b345c7.information_schema"
[0m08:54:29.141246 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:29.142545 [debug] [ThreadPool]: On y42-playground-a0b345c7.information_schema: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "connection_name": "y42-playground-a0b345c7.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `y42-playground-a0b345c7`.`dbt_playground`.__TABLES__
        where (upper(dataset_id) = upper('dbt_playground'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `y42-playground-a0b345c7`.`dbt_playground`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m08:54:33.728717 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:65eb85df-4139-40f2-a9ef-83e1094ac9b3:EU&page=queryresults
[0m08:54:33.742366 [info ] [MainThread]: Catalog written to /Users/mitra/Documents/GitHub/dbt_project/target/catalog.json
[0m08:54:33.742683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf96fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1fd760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c05e070>]}
[0m08:54:33.742888 [debug] [MainThread]: Flushing usage events
[0m08:54:35.069151 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m08:54:35.070003 [debug] [MainThread]: Connection 'y42-playground-a0b345c7.information_schema' was properly closed.


============================== 2023-01-11 08:55:39.125728 | 03212edc-d0be-4ee7-8786-ffdd746edfc9 ==============================
[0m08:55:39.125763 [info ] [MainThread]: Running with dbt=1.3.1
[0m08:55:39.126181 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:55:39.126281 [debug] [MainThread]: Tracking: tracking
[0m08:55:39.134518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10796a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10796a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10796a430>]}
[0m08:55:39.163394 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:55:39.163524 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:55:39.166661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107af30d0>]}
[0m08:55:39.170636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a21c10>]}
[0m08:55:39.170789 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:55:39.171128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a21c40>]}
[0m08:55:39.172015 [info ] [MainThread]: 
[0m08:55:39.172360 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:55:39.173009 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m08:55:39.173208 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:55:41.082870 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m08:55:41.083277 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:55:42.856741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10651c550>]}
[0m08:55:42.857412 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:55:42.857667 [info ] [MainThread]: 
[0m08:55:42.861399 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m08:55:42.861745 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m08:55:42.862483 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m08:55:42.862691 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m08:55:42.862828 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m08:55:42.865880 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m08:55:42.866440 [debug] [Thread-1  ]: finished collecting timing info
[0m08:55:42.866566 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m08:55:42.881840 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:55:44.706703 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m08:55:44.707321 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m08:55:47.666097 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:4e04fd3c-abc2-4b77-a0a5-2032edecb383:EU&page=queryresults
[0m08:55:47.677400 [debug] [Thread-1  ]: finished collecting timing info
[0m08:55:47.677763 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b57d90>]}
[0m08:55:47.677961 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.82s]
[0m08:55:47.678176 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m08:55:47.678483 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m08:55:47.678632 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m08:55:47.678953 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m08:55:47.679064 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m08:55:47.679164 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m08:55:47.680901 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m08:55:47.681244 [debug] [Thread-1  ]: finished collecting timing info
[0m08:55:47.681324 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m08:55:47.696179 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m08:55:47.696480 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m08:55:47.697194 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m08:55:50.559545 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:c6aee982-b80c-46a8-812f-4c957da94e54:EU&page=queryresults
[0m08:55:50.561301 [debug] [Thread-1  ]: finished collecting timing info
[0m08:55:50.561903 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03212edc-d0be-4ee7-8786-ffdd746edfc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c807f0>]}
[0m08:55:50.562273 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.88s]
[0m08:55:50.562642 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m08:55:50.563841 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:55:50.564426 [info ] [MainThread]: 
[0m08:55:50.564649 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.39 seconds (11.39s).
[0m08:55:50.564844 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:55:50.564938 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m08:55:50.578827 [info ] [MainThread]: 
[0m08:55:50.579072 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:55:50.579279 [info ] [MainThread]: 
[0m08:55:50.579441 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m08:55:50.579668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107987b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a21c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107af3190>]}
[0m08:55:50.579846 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 09:13:54.565517 | 407e913b-6999-49cf-8e1f-c984867e3b11 ==============================
[0m09:13:54.565542 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:13:54.566083 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:13:54.566169 [debug] [MainThread]: Tracking: tracking
[0m09:13:54.573568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094d6ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094d6eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094d6e20>]}
[0m09:13:54.594649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ff520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10963cac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10963cb80>]}
[0m09:13:54.594836 [debug] [MainThread]: Flushing usage events
[0m09:13:56.201430 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_project: example/schema.yml - Runtime Error
    Syntax error near line 24
    ------------------------------
    21 | 
    22 | sources:
    23 |   - name: dbt_playground
    24 |   description: something
    25 |   tables: 
    26 |     - name: some table
    27 |     - name: some table
    
    Raw Error:
    ------------------------------
    while parsing a block collection
      in "<unicode string>", line 23, column 3
    did not find expected '-' indicator
      in "<unicode string>", line 24, column 3


============================== 2023-01-11 09:14:17.166145 | f1cd8756-5007-4a50-ac51-5eaf150b9e7b ==============================
[0m09:14:17.166179 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:14:17.166588 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:14:17.166677 [debug] [MainThread]: Tracking: tracking
[0m09:14:17.174013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848c520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848c490>]}
[0m09:14:17.205556 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:14:17.205830 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m09:14:17.213613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108703160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10872bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873db20>]}
[0m09:14:17.213821 [debug] [MainThread]: Flushing usage events
[0m09:14:18.618316 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "dbt_playground_some table".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("dbt_playground", "some table").
  
  To fix this, change the name of one of these resources:
  - source.dbt_project.dbt_playground.some table (models/example/schema.yml)
  - source.dbt_project.dbt_playground.some table (models/example/schema.yml)


============================== 2023-01-11 09:14:29.971785 | 7819e415-23aa-4136-8372-4ef789ac0b16 ==============================
[0m09:14:29.971805 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:14:29.972171 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:14:29.972252 [debug] [MainThread]: Tracking: tracking
[0m09:14:29.981295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199ad30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199af40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199aeb0>]}
[0m09:14:30.011280 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:14:30.011574 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m09:14:30.030487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b740d0>]}
[0m09:14:30.034463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111afcfa0>]}
[0m09:14:30.034601 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 2 sources, 0 exposures, 0 metrics
[0m09:14:30.034726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111afce50>]}
[0m09:14:30.035421 [info ] [MainThread]: 
[0m09:14:30.035732 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:14:30.036167 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m09:14:30.036251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:14:32.490866 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m09:14:32.491329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:14:34.450681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196dfd0>]}
[0m09:14:34.451677 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:14:34.451938 [info ] [MainThread]: 
[0m09:14:34.457256 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m09:14:34.457597 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m09:14:34.458252 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m09:14:34.458403 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m09:14:34.458552 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m09:14:34.461650 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m09:14:34.462735 [debug] [Thread-1  ]: finished collecting timing info
[0m09:14:34.462921 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m09:14:34.482855 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:14:36.375591 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m09:14:36.376153 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m09:14:39.047567 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:dca53562-c40a-40b0-892a-3e1eaeecfb0e:EU&page=queryresults
[0m09:14:39.064443 [debug] [Thread-1  ]: finished collecting timing info
[0m09:14:39.065026 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c24250>]}
[0m09:14:39.065332 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.61s]
[0m09:14:39.065654 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m09:14:39.066190 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m09:14:39.066418 [info ] [Thread-1  ]: 2 of 2 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m09:14:39.066940 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m09:14:39.067063 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m09:14:39.067174 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m09:14:39.069664 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m09:14:39.070124 [debug] [Thread-1  ]: finished collecting timing info
[0m09:14:39.070246 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m09:14:39.087064 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m09:14:39.087597 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:14:39.088547 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m09:14:41.931610 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:499e0398-eb2f-4280-b5b9-aaf5850a034b:EU&page=queryresults
[0m09:14:41.933333 [debug] [Thread-1  ]: finished collecting timing info
[0m09:14:41.933877 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7819e415-23aa-4136-8372-4ef789ac0b16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ca0f10>]}
[0m09:14:41.934188 [info ] [Thread-1  ]: 2 of 2 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.87s]
[0m09:14:41.934529 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m09:14:41.935719 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:14:41.936173 [info ] [MainThread]: 
[0m09:14:41.936355 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 11.90 seconds (11.90s).
[0m09:14:41.936525 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:14:41.936620 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m09:14:41.946910 [info ] [MainThread]: 
[0m09:14:41.947094 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:14:41.947243 [info ] [MainThread]: 
[0m09:14:41.947362 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:14:41.947533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a5d6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119a7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b74820>]}
[0m09:14:41.947673 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 09:52:09.992397 | 1e405a8b-aea0-4506-a5fc-afb9115706b8 ==============================
[0m09:52:09.992420 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:52:09.992981 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:52:09.993073 [debug] [MainThread]: Tracking: tracking
[0m09:52:10.005689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a0e280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a0e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a0e400>]}
[0m09:52:10.122791 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m09:52:10.123007 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/test/my_first_dbt_model.sql
[0m09:52:10.132314 [debug] [MainThread]: 1699: static parser successfully parsed example/test/my_first_dbt_model.sql
[0m09:52:10.138702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106add910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bd2e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bd2f10>]}
[0m09:52:10.138887 [debug] [MainThread]: Flushing usage events
[0m09:52:11.665763 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "my_first_dbt_model".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("my_first_dbt_model").
  
  To fix this, change the name of one of these resources:
  - model.dbt_project.my_first_dbt_model (models/example/test/my_first_dbt_model.sql)
  - model.dbt_project.my_first_dbt_model (models/example/my_first_dbt_model.sql)


============================== 2023-01-11 09:54:30.967142 | cddd1a1d-6204-4672-807b-f102038573e4 ==============================
[0m09:54:30.967172 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:54:30.967691 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:54:30.967798 [debug] [MainThread]: Tracking: tracking
[0m09:54:30.978497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a85e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a8550>]}
[0m09:54:31.074736 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m09:54:31.074970 [debug] [MainThread]: Partial parsing: added file: dbt_project://models/example/some_table_trans.sql
[0m09:54:31.075141 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.dbt_playground.some table
[0m09:54:31.075200 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.dbt_playground.some table 1
[0m09:54:31.075260 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m09:54:31.083332 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m09:54:31.141046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136a1fa0>]}
[0m09:54:31.146299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362e820>]}
[0m09:54:31.146497 [info ] [MainThread]: Found 3 models, 2 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m09:54:31.146645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362eca0>]}
[0m09:54:31.147421 [info ] [MainThread]: 
[0m09:54:31.147773 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:54:31.148401 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m09:54:31.148563 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:54:33.924137 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m09:54:33.924556 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:54:35.947705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f5d580>]}
[0m09:54:35.948144 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:54:35.948293 [info ] [MainThread]: 
[0m09:54:35.951845 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m09:54:35.952028 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m09:54:35.952397 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m09:54:35.952485 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m09:54:35.952567 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m09:54:35.954376 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m09:54:36.005354 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:36.005511 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m09:54:36.015396 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:54:38.038985 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m09:54:38.095522 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m09:54:40.707334 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:0218d376-1358-4fcd-a773-d3b95d5694de:EU&page=queryresults
[0m09:54:40.721241 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:40.721624 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11376f760>]}
[0m09:54:40.721825 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.77s]
[0m09:54:40.722029 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m09:54:40.722113 [debug] [Thread-1  ]: Began running node model.dbt_project.some_table_trans
[0m09:54:40.722391 [info ] [Thread-1  ]: 2 of 3 START sql view model dbt_playground.some_table_trans .................... [RUN]
[0m09:54:40.722866 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.some_table_trans"
[0m09:54:40.722968 [debug] [Thread-1  ]: Began compiling node model.dbt_project.some_table_trans
[0m09:54:40.723045 [debug] [Thread-1  ]: Compiling model.dbt_project.some_table_trans
[0m09:54:40.724780 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.some_table_trans"
[0m09:54:40.725195 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:40.725288 [debug] [Thread-1  ]: Began executing node model.dbt_project.some_table_trans
[0m09:54:40.803628 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.some_table_trans"
[0m09:54:40.804085 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:54:40.804902 [debug] [Thread-1  ]: On model.dbt_project.some_table_trans: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.some_table_trans"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`some_table_trans`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`;


[0m09:54:43.738841 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:e77b87b8-39c3-45f5-a8dc-b3c7cdee47fb:EU&page=queryresults
[0m09:54:43.741647 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:43.742564 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113601f70>]}
[0m09:54:43.743024 [info ] [Thread-1  ]: 2 of 3 OK created sql view model dbt_playground.some_table_trans ............... [[32mCREATE VIEW (0 processed)[0m in 3.02s]
[0m09:54:43.743509 [debug] [Thread-1  ]: Finished running node model.dbt_project.some_table_trans
[0m09:54:43.743736 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m09:54:43.744098 [info ] [Thread-1  ]: 3 of 3 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m09:54:43.744757 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m09:54:43.744883 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m09:54:43.744994 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m09:54:43.749312 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m09:54:43.812869 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:43.813092 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m09:54:43.817138 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m09:54:43.817573 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m09:54:43.818512 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m09:54:47.082299 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:a9d8ec71-745c-49e1-b545-9b8e72562169:EU&page=queryresults
[0m09:54:47.083610 [debug] [Thread-1  ]: finished collecting timing info
[0m09:54:47.084009 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cddd1a1d-6204-4672-807b-f102038573e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11365ffa0>]}
[0m09:54:47.084261 [info ] [Thread-1  ]: 3 of 3 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 3.34s]
[0m09:54:47.084531 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m09:54:47.085430 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:54:47.085796 [info ] [MainThread]: 
[0m09:54:47.085948 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 15.94 seconds (15.94s).
[0m09:54:47.086072 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:54:47.086143 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m09:54:47.153027 [info ] [MainThread]: 
[0m09:54:47.153308 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:54:47.153587 [info ] [MainThread]: 
[0m09:54:47.153761 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m09:54:47.153991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11362ec40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113567160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113567130>]}
[0m09:54:47.154166 [debug] [MainThread]: Flushing usage events


============================== 2023-01-11 09:55:24.178314 | 95eab186-b9b4-40bd-8b53-267b996ad0ca ==============================
[0m09:55:24.178364 [info ] [MainThread]: Running with dbt=1.3.1
[0m09:55:24.178806 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:55:24.178881 [debug] [MainThread]: Tracking: tracking
[0m09:55:24.188005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6a340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6a4c0>]}
[0m09:55:24.283082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:55:24.283475 [debug] [MainThread]: Partial parsing: deleted source source.dbt_project.dbt_playground.some table
[0m09:55:24.283550 [debug] [MainThread]: Partial parsing: update schema file: dbt_project://models/example/schema.yml
[0m09:55:24.291506 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m09:55:24.307289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afd7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afd1ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b033790>]}
[0m09:55:24.307555 [debug] [MainThread]: Flushing usage events
[0m09:55:25.625193 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "dbt_playground_some table".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("dbt_playground", "some table").
  
  To fix this, change the name of one of these resources:
  - source.dbt_project.dbt_playground.some table (models/example/schema.yml)
  - source.dbt_project.dbt_playground.some table (models/example/schema.yml)


============================== 2023-01-11 14:29:02.913251 | cb835f24-8da2-4edd-98c8-d4289fcd88e3 ==============================
[0m14:29:02.913268 [info ] [MainThread]: Running with dbt=1.3.1
[0m14:29:02.913915 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:29:02.914005 [debug] [MainThread]: Tracking: tracking
[0m14:29:02.925565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f96be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f96df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f96d60>]}
[0m14:29:02.950040 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:29:02.950340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cb835f24-8da2-4edd-98c8-d4289fcd88e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118f5a7c0>]}
[0m14:29:02.967900 [debug] [MainThread]: Parsing macros/etc.sql
[0m14:29:02.969235 [debug] [MainThread]: Parsing macros/catalog.sql
[0m14:29:02.973172 [debug] [MainThread]: Parsing macros/adapters.sql
[0m14:29:02.984641 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m14:29:02.985953 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m14:29:02.987358 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m14:29:02.991256 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m14:29:02.992610 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m14:29:03.001982 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m14:29:03.002869 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:03.003054 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:03.003366 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m14:29:03.003876 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:03.004043 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:03.004315 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:03.004611 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:03.005083 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:03.005664 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:03.005898 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:03.006121 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:03.006362 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:03.006627 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:03.006858 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:03.007599 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:03.007851 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:03.008242 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:03.008538 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:03.009832 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m14:29:03.011731 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m14:29:03.012836 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m14:29:03.013643 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m14:29:03.022268 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m14:29:03.029864 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m14:29:03.036748 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m14:29:03.039081 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m14:29:03.039958 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m14:29:03.040844 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m14:29:03.045091 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m14:29:03.054126 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m14:29:03.054930 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m14:29:03.058485 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m14:29:03.064044 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m14:29:03.074000 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m14:29:03.076864 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m14:29:03.078971 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m14:29:03.081754 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m14:29:03.082361 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m14:29:03.084000 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m14:29:03.085065 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m14:29:03.088874 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m14:29:03.099310 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m14:29:03.100165 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m14:29:03.101419 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m14:29:03.102179 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m14:29:03.102606 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m14:29:03.102989 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m14:29:03.103307 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m14:29:03.103962 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m14:29:03.106632 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m14:29:03.111039 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:03.111436 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m14:29:03.112016 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m14:29:03.112466 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m14:29:03.112907 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:03.113508 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:03.113889 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:03.114365 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:03.114943 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:03.116121 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:03.116703 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:03.117299 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:03.117866 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m14:29:03.118352 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m14:29:03.118784 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:03.119289 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m14:29:03.119701 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m14:29:03.122865 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:03.123357 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:03.123785 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m14:29:03.124645 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:03.125726 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:03.126192 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:03.126938 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:03.127641 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m14:29:03.128718 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m14:29:03.130312 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m14:29:03.131719 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m14:29:03.139513 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m14:29:03.140486 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:03.147550 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m14:29:03.149731 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m14:29:03.153438 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m14:29:03.158443 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m14:29:03.161605 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m14:29:03.301573 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m14:29:03.308210 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m14:29:03.309647 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m14:29:03.310987 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m14:29:03.325201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1199755e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198099a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11998b8b0>]}
[0m14:29:03.325397 [debug] [MainThread]: Flushing usage events
[0m14:29:04.434914 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "dbt_playground_some table".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("dbt_playground", "some table").
  
  To fix this, change the name of one of these resources:
  - source.dbt_project.dbt_playground.some table (sources/source.yml)
  - source.dbt_project.dbt_playground.some table (sources/source.yml)


============================== 2023-01-11 14:29:19.371224 | 404a14ff-22d4-422e-9196-4512d66805fa ==============================
[0m14:29:19.371247 [info ] [MainThread]: Running with dbt=1.3.1
[0m14:29:19.374663 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:29:19.374926 [debug] [MainThread]: Tracking: tracking
[0m14:29:19.383235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b6b310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b6b520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b6b490>]}
[0m14:29:19.412547 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:29:19.412792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '404a14ff-22d4-422e-9196-4512d66805fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b89be0>]}
[0m14:29:19.423999 [debug] [MainThread]: Parsing macros/etc.sql
[0m14:29:19.425306 [debug] [MainThread]: Parsing macros/catalog.sql
[0m14:29:19.429280 [debug] [MainThread]: Parsing macros/adapters.sql
[0m14:29:19.440865 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m14:29:19.442340 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m14:29:19.443795 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m14:29:19.447854 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m14:29:19.449386 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m14:29:19.458892 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m14:29:19.459769 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:19.459950 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:19.460257 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m14:29:19.460769 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:19.460938 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:19.461209 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:19.461523 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:19.462004 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:19.462597 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:19.462831 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:19.463063 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:19.463311 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:19.463541 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:19.463737 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:19.464466 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:19.464710 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:19.465084 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:19.465356 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:19.466616 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m14:29:19.468535 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m14:29:19.469636 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m14:29:19.470439 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m14:29:19.478943 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m14:29:19.486656 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m14:29:19.493442 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m14:29:19.495890 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m14:29:19.496765 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m14:29:19.497637 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m14:29:19.501833 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m14:29:19.510977 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m14:29:19.511884 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m14:29:19.515340 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m14:29:19.520997 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m14:29:19.530778 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m14:29:19.533616 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m14:29:19.535344 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m14:29:19.538170 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m14:29:19.538789 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m14:29:19.540466 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m14:29:19.541564 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m14:29:19.545280 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m14:29:19.555684 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m14:29:19.556418 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m14:29:19.557625 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m14:29:19.558369 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m14:29:19.558818 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m14:29:19.559215 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m14:29:19.559533 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m14:29:19.560190 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m14:29:19.562826 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m14:29:19.567206 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:19.567607 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m14:29:19.568194 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m14:29:19.568645 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m14:29:19.569088 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:19.569676 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:19.570051 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:19.570533 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:19.571170 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:19.572445 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:19.573069 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:19.573594 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:19.574115 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m14:29:19.574612 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m14:29:19.575066 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:19.575581 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m14:29:19.576005 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m14:29:19.579349 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:19.579982 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:19.580481 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m14:29:19.581384 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:19.582492 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:19.582977 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:19.583730 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:19.584267 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m14:29:19.585282 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m14:29:19.586876 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m14:29:19.588227 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m14:29:19.596125 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m14:29:19.597117 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:19.604504 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m14:29:19.606758 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m14:29:19.610458 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m14:29:19.615514 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m14:29:19.618697 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m14:29:19.756216 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m14:29:19.762717 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m14:29:19.764097 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m14:29:19.765546 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m14:29:19.780150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bf8910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bd92e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d47fa0>]}
[0m14:29:19.780348 [debug] [MainThread]: Flushing usage events
[0m14:29:20.817059 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "dbt_playground_some table".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("dbt_playground", "some table").
  
  To fix this, change the name of one of these resources:
  - source.dbt_project.dbt_playground.some table (sources/source.yml)
  - source.dbt_project.dbt_playground.some table (sources/source.yml)


============================== 2023-01-11 14:29:39.726629 | 14f72bb8-9a70-4c73-aa30-1a853504ab34 ==============================
[0m14:29:39.726680 [info ] [MainThread]: Running with dbt=1.3.1
[0m14:29:39.727138 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:29:39.727239 [debug] [MainThread]: Tracking: tracking
[0m14:29:39.734414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121967190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1219673a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121967310>]}
[0m14:29:39.755183 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:29:39.755387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '14f72bb8-9a70-4c73-aa30-1a853504ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1218f79d0>]}
[0m14:29:39.765913 [debug] [MainThread]: Parsing macros/etc.sql
[0m14:29:39.767221 [debug] [MainThread]: Parsing macros/catalog.sql
[0m14:29:39.771455 [debug] [MainThread]: Parsing macros/adapters.sql
[0m14:29:39.783001 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m14:29:39.784349 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m14:29:39.785774 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m14:29:39.789705 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m14:29:39.791052 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m14:29:39.800413 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m14:29:39.801296 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:39.801628 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:39.801996 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m14:29:39.802613 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:39.802825 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:39.803127 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:39.803468 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:39.803978 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:39.804607 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:39.804851 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:39.805091 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:39.805356 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:39.805602 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:39.805808 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:39.806570 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:39.806815 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:39.807204 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:39.807492 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:39.808907 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m14:29:39.810896 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m14:29:39.812031 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m14:29:39.812857 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m14:29:39.821556 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m14:29:39.828885 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m14:29:39.835939 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m14:29:39.838391 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m14:29:39.839379 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m14:29:39.840409 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m14:29:39.844512 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m14:29:39.853280 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m14:29:39.854020 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m14:29:39.857354 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m14:29:39.863232 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m14:29:39.873141 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m14:29:39.876119 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m14:29:39.878152 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m14:29:39.881204 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m14:29:39.881917 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m14:29:39.883700 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m14:29:39.884837 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m14:29:39.888667 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m14:29:39.899400 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m14:29:39.900201 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m14:29:39.901412 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m14:29:39.902173 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m14:29:39.902601 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m14:29:39.902973 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m14:29:39.903292 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m14:29:39.903953 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m14:29:39.906603 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m14:29:39.911274 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:39.911777 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m14:29:39.912387 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m14:29:39.912855 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m14:29:39.913306 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:39.913906 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:39.914293 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:39.914961 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:39.915620 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:39.916806 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:39.917392 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:39.917900 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:39.918395 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m14:29:39.918867 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m14:29:39.919288 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:39.920016 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m14:29:39.920557 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m14:29:39.923927 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:39.924484 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:39.924946 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m14:29:39.925885 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:39.927002 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:39.927481 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:39.928187 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:39.928672 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m14:29:39.929835 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m14:29:39.931606 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m14:29:39.933102 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m14:29:39.941520 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m14:29:39.942599 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:39.949611 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m14:29:39.952232 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m14:29:39.955991 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m14:29:39.961400 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m14:29:39.964746 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m14:29:40.106740 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m14:29:40.113605 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m14:29:40.114995 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m14:29:40.116716 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m14:29:40.129720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d35b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1219dcdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1219d5b80>]}
[0m14:29:40.129886 [debug] [MainThread]: Flushing usage events
[0m14:29:41.140856 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named my_first_dbt_model. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for my_first_dbt_model in this file:
   - models/example/schema.yml
  


============================== 2023-01-11 14:29:54.407267 | 2c0d4d6b-60b1-46a6-8ed7-f4153a849c8d ==============================
[0m14:29:54.407292 [info ] [MainThread]: Running with dbt=1.3.1
[0m14:29:54.407707 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:29:54.407851 [debug] [MainThread]: Tracking: tracking
[0m14:29:54.417646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116a2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11116a430>]}
[0m14:29:54.439214 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:29:54.439460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c0d4d6b-60b1-46a6-8ed7-f4153a849c8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111189b80>]}
[0m14:29:54.449964 [debug] [MainThread]: Parsing macros/etc.sql
[0m14:29:54.451306 [debug] [MainThread]: Parsing macros/catalog.sql
[0m14:29:54.455561 [debug] [MainThread]: Parsing macros/adapters.sql
[0m14:29:54.467276 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m14:29:54.468609 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m14:29:54.470036 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m14:29:54.474237 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m14:29:54.475716 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m14:29:54.485081 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m14:29:54.486033 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:54.486225 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:54.486541 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m14:29:54.487070 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:54.487251 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:54.487510 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:54.487823 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:54.488290 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:54.488876 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:54.489107 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:54.489339 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:54.489582 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:54.489808 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:54.490005 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:54.490755 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:54.491002 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:54.491398 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:54.491694 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:54.492974 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m14:29:54.494869 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m14:29:54.496094 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m14:29:54.496989 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m14:29:54.505602 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m14:29:54.513074 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m14:29:54.519822 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m14:29:54.522108 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m14:29:54.522993 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m14:29:54.523855 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m14:29:54.528105 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m14:29:54.537619 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m14:29:54.538598 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m14:29:54.542106 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m14:29:54.547867 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m14:29:54.558015 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m14:29:54.560925 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m14:29:54.562627 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m14:29:54.565434 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m14:29:54.566057 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m14:29:54.567902 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m14:29:54.569177 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m14:29:54.572952 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m14:29:54.584039 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m14:29:54.584921 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m14:29:54.586134 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m14:29:54.586876 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m14:29:54.587299 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m14:29:54.587861 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m14:29:54.588233 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m14:29:54.588927 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m14:29:54.591717 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m14:29:54.596234 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:29:54.596643 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m14:29:54.597268 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m14:29:54.597739 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m14:29:54.598179 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:29:54.598795 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:29:54.599269 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:29:54.599906 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:29:54.600558 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:29:54.601747 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:29:54.602376 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:29:54.602901 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:29:54.603416 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m14:29:54.603899 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m14:29:54.604326 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:29:54.604842 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m14:29:54.605268 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m14:29:54.608608 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:29:54.609143 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:29:54.609586 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m14:29:54.610453 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:29:54.611569 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:29:54.612053 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:29:54.612761 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:29:54.613261 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m14:29:54.614276 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m14:29:54.615867 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m14:29:54.617342 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m14:29:54.625457 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m14:29:54.626518 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:29:54.633550 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m14:29:54.635960 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m14:29:54.639790 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m14:29:54.645124 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m14:29:54.648482 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m14:29:54.786842 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m14:29:54.793288 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m14:29:54.794648 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m14:29:54.795936 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m14:29:54.813427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111e1a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111eee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111459f70>]}
[0m14:29:54.813608 [debug] [MainThread]: Flushing usage events
[0m14:29:55.843147 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named my_first_dbt_model. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for my_first_dbt_model in this file:
   - models/example/schema.yml
  


============================== 2023-01-11 14:30:30.532610 | 3c4ab0ea-0d1c-46af-b597-85dd952ca458 ==============================
[0m14:30:30.532664 [info ] [MainThread]: Running with dbt=1.3.1
[0m14:30:30.533342 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/mitra/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:30:30.533428 [debug] [MainThread]: Tracking: tracking
[0m14:30:30.541597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b455ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b455eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b455e20>]}
[0m14:30:30.562411 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:30:30.562636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b41b370>]}
[0m14:30:30.573712 [debug] [MainThread]: Parsing macros/etc.sql
[0m14:30:30.575147 [debug] [MainThread]: Parsing macros/catalog.sql
[0m14:30:30.579120 [debug] [MainThread]: Parsing macros/adapters.sql
[0m14:30:30.591112 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m14:30:30.592497 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m14:30:30.593917 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m14:30:30.598118 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m14:30:30.599789 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m14:30:30.609478 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m14:30:30.610400 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:30:30.610590 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:30:30.610897 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m14:30:30.611402 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:30:30.611569 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:30:30.611824 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:30:30.612124 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:30:30.612594 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:30:30.613190 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:30:30.613420 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:30:30.613646 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:30:30.613889 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:30:30.614117 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:30:30.614312 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:30:30.615044 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:30:30.615291 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:30:30.615662 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:30:30.615931 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:30:30.617415 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m14:30:30.619534 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m14:30:30.620672 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m14:30:30.621490 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m14:30:30.630504 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m14:30:30.638144 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m14:30:30.645143 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m14:30:30.647520 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m14:30:30.648399 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m14:30:30.649271 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m14:30:30.653598 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m14:30:30.662574 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m14:30:30.663336 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m14:30:30.666713 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m14:30:30.672087 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m14:30:30.681879 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m14:30:30.684849 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m14:30:30.686603 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m14:30:30.689453 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m14:30:30.690097 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m14:30:30.691796 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m14:30:30.692900 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m14:30:30.696511 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m14:30:30.706968 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m14:30:30.707753 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m14:30:30.709019 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m14:30:30.709802 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m14:30:30.710233 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m14:30:30.710612 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m14:30:30.710931 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m14:30:30.711594 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m14:30:30.714219 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m14:30:30.718591 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m14:30:30.718985 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m14:30:30.719566 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m14:30:30.720017 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m14:30:30.720453 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m14:30:30.721039 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m14:30:30.721413 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m14:30:30.721897 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m14:30:30.722479 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m14:30:30.723754 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m14:30:30.724521 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m14:30:30.725071 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m14:30:30.725594 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m14:30:30.726090 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m14:30:30.726528 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m14:30:30.727036 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m14:30:30.727466 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m14:30:30.730655 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m14:30:30.731139 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m14:30:30.731566 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m14:30:30.732422 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m14:30:30.733488 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m14:30:30.734104 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m14:30:30.734947 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m14:30:30.735460 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m14:30:30.736517 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m14:30:30.738112 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m14:30:30.739464 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m14:30:30.747247 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m14:30:30.748219 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m14:30:30.755209 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m14:30:30.757486 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m14:30:30.761196 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m14:30:30.766256 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m14:30:30.769432 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m14:30:30.907898 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m14:30:30.914726 [debug] [MainThread]: 1699: static parser successfully parsed example/some_table_trans.sql
[0m14:30:30.916272 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m14:30:30.917725 [debug] [MainThread]: 1699: static parser successfully parsed example/source_transformation.sql
[0m14:30:31.000501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b41b760>]}
[0m14:30:31.005494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b41b760>]}
[0m14:30:31.005629 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m14:30:31.005741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6ebaf0>]}
[0m14:30:31.006392 [info ] [MainThread]: 
[0m14:30:31.006701 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m14:30:31.007363 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7"
[0m14:30:31.007517 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:33.352555 [debug] [ThreadPool]: Acquiring new bigquery connection "list_y42-playground-a0b345c7_dbt_playground"
[0m14:30:33.352792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:30:35.128150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a21d580>]}
[0m14:30:35.128756 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:35.128967 [info ] [MainThread]: 
[0m14:30:35.134326 [debug] [Thread-1  ]: Began running node model.dbt_project.my_first_dbt_model
[0m14:30:35.134594 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_playground.my_first_dbt_model ................. [RUN]
[0m14:30:35.135169 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_first_dbt_model"
[0m14:30:35.135291 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_first_dbt_model
[0m14:30:35.135398 [debug] [Thread-1  ]: Compiling model.dbt_project.my_first_dbt_model
[0m14:30:35.138340 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_first_dbt_model"
[0m14:30:35.138879 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:35.139001 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_first_dbt_model
[0m14:30:35.172095 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_first_dbt_model"
[0m14:30:35.173063 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:30:35.173961 [debug] [Thread-1  ]: On model.dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_first_dbt_model"} */

  
    

    create or replace table `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m14:30:38.940187 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:34fc717d-a293-4523-87a6-b913e1bcfe7f:EU&page=queryresults
[0m14:30:38.954733 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:38.955329 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7ab700>]}
[0m14:30:38.955644 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_playground.my_first_dbt_model ............ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.82s]
[0m14:30:38.955982 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_first_dbt_model
[0m14:30:38.956129 [debug] [Thread-1  ]: Began running node model.dbt_project.some_table_trans
[0m14:30:38.956289 [info ] [Thread-1  ]: 2 of 4 START sql view model dbt_playground.some_table_trans .................... [RUN]
[0m14:30:38.956771 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.some_table_trans"
[0m14:30:38.956902 [debug] [Thread-1  ]: Began compiling node model.dbt_project.some_table_trans
[0m14:30:38.957011 [debug] [Thread-1  ]: Compiling model.dbt_project.some_table_trans
[0m14:30:38.959754 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.some_table_trans"
[0m14:30:38.961003 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:38.961125 [debug] [Thread-1  ]: Began executing node model.dbt_project.some_table_trans
[0m14:30:38.989856 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.some_table_trans"
[0m14:30:38.990385 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:30:38.991339 [debug] [Thread-1  ]: On model.dbt_project.some_table_trans: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.some_table_trans"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`some_table_trans`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`;


[0m14:30:42.028857 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:f260d6f1-b5f6-47b1-9c38-117439265a94:EU&page=queryresults
[0m14:30:42.030236 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:42.030807 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b996fd0>]}
[0m14:30:42.031136 [info ] [Thread-1  ]: 2 of 4 OK created sql view model dbt_playground.some_table_trans ............... [[32mCREATE VIEW (0 processed)[0m in 3.07s]
[0m14:30:42.031441 [debug] [Thread-1  ]: Finished running node model.dbt_project.some_table_trans
[0m14:30:42.031572 [debug] [Thread-1  ]: Began running node model.dbt_project.source_transformation
[0m14:30:42.031717 [info ] [Thread-1  ]: 3 of 4 START sql view model dbt_playground.source_transformation ............... [RUN]
[0m14:30:42.032201 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.source_transformation"
[0m14:30:42.032406 [debug] [Thread-1  ]: Began compiling node model.dbt_project.source_transformation
[0m14:30:42.032536 [debug] [Thread-1  ]: Compiling model.dbt_project.source_transformation
[0m14:30:42.037966 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.source_transformation"
[0m14:30:42.040205 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:42.040396 [debug] [Thread-1  ]: Began executing node model.dbt_project.source_transformation
[0m14:30:42.045571 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.source_transformation"
[0m14:30:42.046205 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:30:42.047406 [debug] [Thread-1  ]: On model.dbt_project.source_transformation: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.source_transformation"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`source_transformation`
  OPTIONS()
  as select * from `y42-playground-a0b345c7`.`dbt_playground`.`some table`
where Department = 'Paper';


[0m14:30:44.402910 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:f47615a1-3085-4eff-b2aa-f8921dc314e1:EU&page=queryresults
[0m14:30:44.404185 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:44.404677 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7958b0>]}
[0m14:30:44.404967 [info ] [Thread-1  ]: 3 of 4 OK created sql view model dbt_playground.source_transformation .......... [[32mCREATE VIEW (0 processed)[0m in 2.37s]
[0m14:30:44.405286 [debug] [Thread-1  ]: Finished running node model.dbt_project.source_transformation
[0m14:30:44.405426 [debug] [Thread-1  ]: Began running node model.dbt_project.my_second_dbt_model
[0m14:30:44.405583 [info ] [Thread-1  ]: 4 of 4 START sql view model dbt_playground.my_second_dbt_model ................. [RUN]
[0m14:30:44.406175 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_project.my_second_dbt_model"
[0m14:30:44.406300 [debug] [Thread-1  ]: Began compiling node model.dbt_project.my_second_dbt_model
[0m14:30:44.406394 [debug] [Thread-1  ]: Compiling model.dbt_project.my_second_dbt_model
[0m14:30:44.411991 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_project.my_second_dbt_model"
[0m14:30:44.412475 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:44.412582 [debug] [Thread-1  ]: Began executing node model.dbt_project.my_second_dbt_model
[0m14:30:44.414922 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_project.my_second_dbt_model"
[0m14:30:44.415317 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:30:44.416490 [debug] [Thread-1  ]: On model.dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.1", "profile_name": "dbt_project", "target_name": "dev", "node_id": "model.dbt_project.my_second_dbt_model"} */


  create or replace view `y42-playground-a0b345c7`.`dbt_playground`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `y42-playground-a0b345c7`.`dbt_playground`.`my_first_dbt_model`
where id = 1;


[0m14:30:47.214005 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=y42-playground-a0b345c7&j=bq:d7663d87-c958-40c3-9f2e-59f1e69ab536:EU&page=queryresults
[0m14:30:47.215299 [debug] [Thread-1  ]: finished collecting timing info
[0m14:30:47.215842 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3c4ab0ea-0d1c-46af-b597-85dd952ca458', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9c3f10>]}
[0m14:30:47.216183 [info ] [Thread-1  ]: 4 of 4 OK created sql view model dbt_playground.my_second_dbt_model ............ [[32mCREATE VIEW (0 processed)[0m in 2.81s]
[0m14:30:47.216455 [debug] [Thread-1  ]: Finished running node model.dbt_project.my_second_dbt_model
[0m14:30:47.217690 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m14:30:47.218122 [info ] [MainThread]: 
[0m14:30:47.218300 [info ] [MainThread]: Finished running 1 table model, 3 view models in 0 hours 0 minutes and 16.21 seconds (16.21s).
[0m14:30:47.218443 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:47.218513 [debug] [MainThread]: Connection 'model.dbt_project.my_second_dbt_model' was properly closed.
[0m14:30:47.224287 [info ] [MainThread]: 
[0m14:30:47.224489 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:30:47.224674 [info ] [MainThread]: 
[0m14:30:47.224823 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m14:30:47.225047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b41b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4685e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6198e0>]}
[0m14:30:47.225228 [debug] [MainThread]: Flushing usage events
